{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558de29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import unicodedata\n",
    "from docx import Document\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import os\n",
    "from win32com import client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c96e775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffChapter 1\\n',\n",
       " '1 מלכי] b. Pesaḥim 87a מלךI\\n',\n",
       " '2 לֵךְ] b. Pesaḥimms 87a, S.Eli.Z 9 (187) >I\\n',\n",
       " '3 לו] b. Pesaḥim 87b >I III IV\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6 עוד1] b. Pesaḥimmss 87b >I III IV \\n',\n",
       " 'לו] b. Pesaḥimmss 87b יי אליוI\\n',\n",
       " '7 אלהיהם] 4QXIId אלהים֯ (!)[1]\\n',\n",
       " '8 ותהר] b. Pesaḥimmss 87b + עודI\\n',\n",
       " '9 ויאמר] b. Pesaḥimmss 87b + יי אליוI | b. Pesaḥimms 87b + יי\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 2\\n',\n",
       " '1 יֵאָמֵר] 4QXIId יומ[ר[2]\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4 ריבו2] 4QXIIg ר֯[י]ב֗\\n',\n",
       " 'מ(פניה)] 4QXIId מבי[ן[3] \\n',\n",
       " '5 כמדבר ושתה] 4QXIIg (pm) >[4]  \\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8 שך] b. R.haŠana 23b, LamR Buber 1 (40b) סךIII IV\\n',\n",
       " 'וגדרתי את גדרה] 4QpHosa > (lem)[5]\\n',\n",
       " '9\\n',\n",
       " '10 (הרביתי) לה] 4QpHosa > (lem)\\n',\n",
       " 'וזהב] 4QpHosa (pm) + [..] (lem)\\n',\n",
       " '11 לכסות] 4QpHosa מלכסות (lem)[6]I\\n',\n",
       " '12\\n',\n",
       " '13 מועדה] 4QpHosa מועדיה (lem)[7]\\n',\n",
       " '14 אתנה המה] 4QpHosa אתנם הם (lem)[8]\\n',\n",
       " '15 ופקדתי – ותעד] 4QXIIg [↔][9]\\n',\n",
       " '16 והלכתיה – לבה] 4QXIIg [↔][10]\\n',\n",
       " '17\\n',\n",
       " '18 תקראי1] b. Pesaḥimmss 87a, b. Ketubbotms 71b, CantZ 1:1(3b), PesiqtaRms 44 (183a) + ליI III \\n',\n",
       " 'לי] b. Pesaḥimms 87a, b. Ketubbotmss 71b >III IV\\n',\n",
       " '19\\n',\n",
       " '20\\n',\n",
       " '21\\n',\n",
       " '22 את] AḇotRN A 37 (55b), DeutRms ‘eqev 3:7 (106b) כי אניI III IV\\n',\n",
       " '23 אענה1] SifreDeut 306 (333:9), PesiqtaR 22 (114b) >I\\n',\n",
       " '24\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 3\\n',\n",
       " '1–2 ישראל–בחמשה] 4QXIIg [↔][11]\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4 \\n',\n",
       " '5 אחר] y. Beraḵotms 2:4 5a (18:36), b. Megillamss 18a, Tanḥuma leḵ leḵa 15 (65), Tanḥuma Buber leḵ leḵa 19 (38b), MidrašSammss 13:4 (47:36), MidrašPs 24:2 (102a) ואחרI III\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 4\\n',\n",
       " '1 בני ישראל] SifreDeutmss 41 (85:1) בית ישראל | SifreDeutmss 41 (85:1) בית יעקב\\n',\n",
       " '2 ורצֹח] MeḵiltaRImss baḥodeš 8 (234:2), b. Qiddušinmss 13a, b. Šeḇu‘otmss 39a, LamZ 1:23 (31b), LamZ 1:31 (34a), LamZ B 18 (41a), Tanḥumams naśo 4 (676), S.Eli.R. 14 (64) רצוחIV \\n',\n",
       " 'ודמים] b. Giṭṭinmss 57b, b. Qiddušinmss 13a, PesiqtaRKms 15:7 (259:2) דמיםIII\\n',\n",
       " '3 יושב] 4QXIIc יוש]ב֗י, b. Qiddušinmss 13a, b. Šeḇu‘otms 39a, Tanḥumams vayyešeḇ 2 (146) יושביI III IV | b. Qiddušinmss 13a יושביה\\n',\n",
       " '3–4 השדה–יוכח] 4QXIIc [↔][12]I\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6 הדעת1] SifreDeutms 41 (85:5), b. Soṭamss 49a, MidrašPsms 8:4 (39a) דעתIII\\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10 ואכלו] y. Yeḇamot 6:5 7c (859:24), b. Yeḇamotmss 61b, S.Eli.Z 16 (9) אכלוIII \\n',\n",
       " '11 ויין] y. Ketubbot 5:13 30b (985:48), b. Yomamss 76b, b. Giṭṭinmss 68a, LamRmss 1:47 (17d), LamR Bubermss 1:16 (43b), PirqeREmss 46 (236), MidrašPsms 78:12 (176b) ייןIII\\n',\n",
       " '12 התעה] b. Sukkamss 52b התעםI \\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '15 ואל (תעלו)] 4QXIIc אל֗\\n',\n",
       " '16 סרר] CDa I14  כן סרר(cit) \\n',\n",
       " '17\\n',\n",
       " '18 מגניה] 4QXIIc (pm) מגנה \\n',\n",
       " '19\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 5\\n',\n",
       " '1\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6 יהוה] b. Yeḇamotmss 102b, PesiqtaRK appendix 7 (471:15), Tanḥuma ha’azinu 4 (938) pr דברIII IV\\n',\n",
       " '7\\n',\n",
       " '8 \\n',\n",
       " '9\\n',\n",
       " '10 עליהם אשפוך] CDa VIII3 אשר תשפוך עליהם (cit)[13]\\n',\n",
       " 'כמים] CDa VIII3 > (cit)\\n',\n",
       " 'עברתי] CDa VIII3 העברה (cit), CDb XIX16 עברה (cit)\\n',\n",
       " '11 הלך] CDa IV19הלכו  (cit?)[14]  \\n',\n",
       " '12\\n',\n",
       " '13\\n',\n",
       " '14 אני אני – מציל] 4QpHosb > (lem)[15]\\n',\n",
       " '15 אלך] SifreZ.Num 12:9 (276:17), b. R.haŠanamss 31a, LamRms petiḥta 24 (6d), LamR Buberms petiḥta 24 (13a), Tanḥumams beḥuqqotay 3 (636 x2), MidrašPs 10:2 (47a) אלכהIV \\n',\n",
       " 'אשובה] SifreZ.Num 12:9 (276:17), y. Beraḵotms 4:5 8c (40:45), b. R.haŠanamss 31a (x2), PesiqtaRK 13:11 (235:14), LamRms petiḥta 24 (6d), LamR Buberms petiḥta 24 (13a), LamR Buberms petiḥta 25 (15b), Tanḥuma beḥuqqotay 3 (636 x3; ketiḇ), Tanḥuma Buberms beḥuqqotay 5 (56a), MidrašPs 10:2 (47a), S.Eli.R. 19 (110) ואשובהI III IV | y. Beraḵotms 4:5 8c (40:45) ואשובI\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 6\\n',\n",
       " '1\\n',\n",
       " '2 ביום] b. R.haŠanamss 31a, b. Sanhedrinmss 97a, GenRmss 56:1 (595:1, 6), GenRms 91:7 (1130:1), PirqeREmss 50 (246), S.Eli.R. 6 (29) וביוםI\\n',\n",
       " '3 ונדעה] y. Beraḵot 5:1 9a (43:28), 5:2 9a (44:48), b. Beraḵotmss 6b, b. Ta‘anitmss 4a, MidrašḤad 226:82 נדעהI\\n',\n",
       " 'נרדפה] y. Beraḵotms 5:2 9a (44:48), b. Beraḵotmss 6b, b. Ta‘anitms 4a ונרדפהI\\n',\n",
       " 'כמלקוש] b. Ta‘anitmss 4a וכמלקושI III IV | DeutR 7:6 (114a), DeutR Liebermann ki taḇo 6 (110) ובמלקוש \\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9–10 כי–שעריריה] 4QXIIg [↔][16]\\n',\n",
       " '9 וכחכי] 4Qpap pIsac (4Q163) 23ii14a (sm?) כיֿחכה (cit?)[17]\\n',\n",
       " 'כי] 4QpHosb וא֗שר (lem) \\n',\n",
       " '10\\n',\n",
       " '11 לָךְ] 4QpHosb לכה (lem)\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 7\\n',\n",
       " '1\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4\\n',\n",
       " '5 מלכנו] MeḵiltaRI pisḥa 14 (49:6), y. ‘A.Zara 1:1 39b (1375:21, 31) מלכינוI III IV\\n',\n",
       " '6\\n',\n",
       " '7 אין] LevRmss 36:3 (843:2), DeutR 2:19 (102c), 5:9 (110d), DeutR Liebermann šofeṭim 9 (99)ואין I III IV\\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10\\n',\n",
       " '11\\n',\n",
       " '12\\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '15\\n',\n",
       " '16 רמיה] 4QXIIg ה֯ר֯ומיה[18]\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 8\\n',\n",
       " '1\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6 שבבים יהיה] 4QpHosb שו[בבי]ם֯ היה (lem)I\\n',\n",
       " '7 וסופתה] 4QpHosb סופות (lem) \\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10 שרים] b. B.Batra 8a, PesiqtaRKms 6:3 (118:5) ושריםI III IV\\n',\n",
       " '11\\n',\n",
       " '12 לו] b. Giṭṭinmss 60b (x2), Tanḥumams vayyera 5 (76), Tanḥuma Buber vayyera 6 (44b) לך | b. Giṭṭinms 60b (x2) לכם\\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 9\\n',\n",
       " '1 כעמים] b. Giṭṭinmss 7a בעמים\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10 ישראל] SifreDeutms 313 (355:6), b. Beraḵotmss 56b, GenRmss 29:3 (269:2), Tanḥumams naśo 11 (683), Tanḥuma Buber leḵ leḵa 21 (39a), naśo 19 (17b) (את) אבותיכם\\n',\n",
       " 'שקוצים כאהבם] 4QXIIg [↔][19]\\n',\n",
       " '11\\n',\n",
       " '12\\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '15\\n',\n",
       " '16\\n',\n",
       " '17\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 10\\n',\n",
       " '1–2 הרבה–עתה] 4QXIIg [↔][20]\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8 ונשמדו] 4QXIIg (pm) ונ]שמד \\n',\n",
       " '9\\n',\n",
       " '10\\n',\n",
       " '11 ואפרים] GenR 48:13 (490:3), GenRmss 53:3 (556:6), AḇotRNms A 23 (38b), CantZ 1:1 (2b), Tanḥuma Buber vayyera 31 (53a), PesiqtaR 33 (157a) אפריםI \\n',\n",
       " '12 קצרו] b. Sukkamss 49b, b. B.Qammamss 17a, b. ‘A.Zaramss 5b וקצרוI III IV \\n',\n",
       " 'וירה] 4QXIIg וֿיֿרוֿ[21]\\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '15\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 11\\n',\n",
       " '1\\n',\n",
       " '2\\n',\n",
       " '3 זרועתיו] MeḵiltaRImss vayyehi 4 (101:10), LamRms 2:2 (20a), LamR Buberms 2:1 (48b), Tanḥumams vayyeḥi 6 (190), PesiqtaR 3 (12a) זרועותיI III\\n',\n",
       " '4 ואהיה] b. Šabbatmss 89b, GenRmss 86:1 (1051:1,3,7) ואהי\\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8 עלי] 4QXIIg ע֯ל֗ \\n',\n",
       " '9 לא2] MidrašPsms 6:3 (30b), S.Eli.Z 10 (191) ולאIII IV \\n',\n",
       " 'ולא2] SifreDeutms 306 (330:5), b. Ta‘anitmss 5a, 11b לאIII IV\\n',\n",
       " '10 אחרי] 4QXIIg א]חריו\\n',\n",
       " 'יהוה] 4QXIIg (pm) > \\n',\n",
       " 'ילכו כאריה] 4QXIIg יל֗ך וכא֗ר֯[יה \\n',\n",
       " '11 כצפור] 4QXIIg כ֯צ֗פרים\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 12\\n',\n",
       " '1 עִם אל ועִם] DeutR 11:10 (120a) עַם אל ועַם I (herm)\\n',\n",
       " '2\\n',\n",
       " '3 כדרכיו כמעלליו] 4QXIIg כדרכי]ו וכמע֗[לליו, LevRms 27:6 (634:6) כדרכיו וכמעלליו\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10 מארץ] 4QXIIg pr ה]מ֯עלכה (!)[22]I\\n',\n",
       " '11\\n',\n",
       " '12\\n',\n",
       " '13\\n',\n",
       " '14\\n',\n",
       " '15\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 13\\n',\n",
       " '1 נשא] LevRmss 12:5 (264:7) נשיאI\\n',\n",
       " '2\\n',\n",
       " '3\\n',\n",
       " '4 אלהיך] 4QXIIc + ב֗צר שמים [↔ ו]א֯נוכי העלותיכה[23]I \\n',\n",
       " '5\\n',\n",
       " '6\\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9\\n',\n",
       " '10 אשר] 4QXIIc ]כ֗]א֯ש֯ר֯ \\n',\n",
       " '11\\n',\n",
       " '12\\n',\n",
       " '13\\n',\n",
       " '14 ממות] b. Pesaḥimmss 87b, b. Yeḇamotmss 17a וממותI III \\n',\n",
       " 'דבריך] CantZ 1:3 (5a), Tanḥuma ṣav 2 (494 x2), Tanḥuma Buber ṣav 4 (8a x2), MidrašPs 140:1 (265b) דברךI III IV\\n',\n",
       " '15 בין] MeḵiltaRImss bešalaḥ 4 (103:13), b. Giṭṭinms 31b, PirqeREmss 52 (251) בןI III IV \\n',\n",
       " 'יפריא] PirqeREmss 52 (251) יפרידI (herm)\\n',\n",
       " 'ויבוש] 4QXIIc ו֯יבש[24]\\n',\n",
       " 'הוא2] b. Giṭṭinmss 31b והואI III\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Chapter 14\\n',\n",
       " '1\\n',\n",
       " '2\\n',\n",
       " '3 עמכם] 4QXIIc (sm) עמכמכ֯ה֯ (?)[25] \\n',\n",
       " 'יהוה] b. Yomams 86b, PesiqtaRKms 24:19 (377:7), Tanḥumams ṣav 6 (497) + אלהיכםI \\n',\n",
       " 'אמרו] PesiqtaRK 24:19 (377:7) ואמרוIII IV\\n',\n",
       " '5 משובתם] SifreDeutms 342 (391:8), b. Yomamss 86b, S.Eli.Z 22 (38,40) משובות(י)כםI \\n',\n",
       " 'ממנו] b. Yomams 86b (pm) מהםI\\n',\n",
       " '6 ויך] 4QXIIc יכ[26] \\n',\n",
       " '7\\n',\n",
       " '8\\n',\n",
       " '9 ואשורנו] CantRms 1:17 (13c), CantR 7:8 (37c) לא אשורנו (herm)\\n',\n",
       " '10 בם1] b. Nazirmss 23a (x2), b. Horayotms 10b, PesiqtaRKmss 2:2 (18:1) בהIV\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '________________\\n',\n",
       " '[1]\\n',\n",
       " ' Leon Levy Plate 410, Fragment 1, B-362685\\n',\n",
       " '[2] orיומ[רו  following Neuman, Linguistic Variants, 67–68, 143 to express impersonal construction (Muraoka, STDJ, 200–201) \\n',\n",
       " '[3] parall seq מבין (שדיה)\\n',\n",
       " '[4]  כמדברappears to be written past the left margin\\n',\n",
       " '[5] note that v9a (ורדפה – תמצא) is neither cited nor commented upon in 4QpHosa, similarly app 514\\n',\n",
       " '[6] see Qimron, DSD 2 (1995) 323–325\\n',\n",
       " '[7] pl also in comm: פשרו: אשר | [את המו]ע֗דות יוליכו במועדי הגואים\\n',\n",
       " '[8] p linguistic variant\\n',\n",
       " '[9] lacuna shorter than x\\n',\n",
       " '[10] lacuna shorter than x\\n',\n",
       " '[11] lacuna shorter than x\\n',\n",
       " '[12] lacuna longer than x\\n',\n",
       " '[13] cf 4QDa (olim Db; 4Q266) 3iv1 ביום אשר [תשפוך עליהם העברה]\\n',\n",
       " '[14] pers (3pl) agrees with בוני החי֗ץ (pl) in comm, but may also fit אפרים (collective noun) in unquoted part of lem   \\n',\n",
       " '[15] similarly app 28\\n',\n",
       " '[16] lacuna shorter than x\\n',\n",
       " '[17] or pm, cf Strugnell, RQ 7.2 [26] (1970) 193;  כיֿחכהp orthographic variant 7 כוחכהI, cf CDa I9 וכימגששים, 4Q128 149 כיא[זר]ח֯ (pm); p כוֿחכהI\\n',\n",
       " '[18] p ptc, cf Jer 429 Ps 789 (for x as ptc see Qimron, FS Licht, 266 n. 10); p phon\\n',\n",
       " '[19] lacuna longer than x\\n',\n",
       " '[20] lacuna shorter than x\\n',\n",
       " '[21] note comm מוריהם֯ in 4QpHosb 5–62 \\n',\n",
       " '[22] see Tigchelaar, VT 56.4 (2006) 558–560 \\n',\n",
       " '[23] see Fuller, RB 98.3 (1991) 343–357; p graph ב֗צר # יוצר, \\n',\n",
       " '[24] \\\\יבש; for חרב//יבש cf Jer 5136 Nah 14, cf also Isa 195 || Job 1411 \\n',\n",
       " '[25] reading of supralinear correction is uncertain \\n',\n",
       " '[26] cf Qimron, Grammar, 371–373']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('01 Hosea App II Final.doc.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    txt = file\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## render apparatus 3 ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new logic\n",
    "#1. split into lemma and app_entry. process each separately\n",
    "# lemma: split into number range and lemma range. \n",
    "#numbers include \\d+'-', lemmas need to include potential k\\q attribute, and word number.\n",
    "# app_entry: splits into mss., reading, comments, cross-reference.\n",
    "# \n",
    "#to do: \n",
    "#1. get_verse, if verse is empty. same for get_witness (if its inside a comma)\n",
    "#2. QA: \"איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\" (when split on comma allow for witness completion)\n",
    "# maybe run a post_processing function that will add .. if needed to the sigla, and the verse and witness if their missing.\n",
    "# get chapter of verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4a021fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled_results\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_and_display_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 34\u001b[0m, in \u001b[0;36mcompile_and_display_entries\u001b[1;34m(entries)\u001b[0m\n\u001b[0;32m     32\u001b[0m updated_witnesses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m witness \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWitnesses\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mwitness\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m last_witness_second_group:\n\u001b[0;32m     35\u001b[0m         updated_witnesses\u001b[38;5;241m.\u001b[39mappend((witness[\u001b[38;5;241m0\u001b[39m], last_witness_second_group, witness[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "##### \n",
    "def compile_and_display_entries(entries):\n",
    "    previous_verse = None\n",
    "    current_chapter = None\n",
    "    compiled_results = []\n",
    "    \n",
    "    for entry in entries:\n",
    "        chapter_match = re.search(r'Chapter (\\d+)', entry)\n",
    "        if chapter_match:\n",
    "            current_chapter = chapter_match.group(1)\n",
    "            continue\n",
    "        elif entry.strip() and not entry.strip().isdigit():\n",
    "            clean_entry = entry.strip()\n",
    "            lemma_dict, decoded_entries, used_verse = process_full_entry(clean_entry, current_chapter, previous_verse)\n",
    "            previous_verse = used_verse\n",
    "\n",
    "            # Combine the lemma_dict and decoded_entries for display\n",
    "            entry_result = {\n",
    "                #'Chapter': current_chapter,\n",
    "                'Entry': clean_entry,\n",
    "                'Lemma Info': lemma_dict,\n",
    "                'Decoded Entries': []\n",
    "            }\n",
    "            last_witness_second_group = None\n",
    "            for i, decoded_entries_list in enumerate(decoded_entries):\n",
    "                for j, decoded_entry in enumerate(decoded_entries_list):\n",
    "                    variant_type = \"Variant\" if j == 0 else \"Related Variant\"\n",
    "                    variant_dict = {'Type': variant_type, 'Details': []}\n",
    "                    for item in decoded_entry:\n",
    "                        if isinstance(item, dict) and 'Witnesses' in item:\n",
    "                            # Update witnesses with last non-empty second group if needed\n",
    "                            updated_witnesses = []\n",
    "                            for witness in item['Witnesses']:\n",
    "                                if witness[1] == '' and last_witness_second_group:\n",
    "                                    updated_witnesses.append((witness[0], last_witness_second_group, witness[2]))\n",
    "                                else:\n",
    "                                    updated_witnesses.append(witness)\n",
    "                                    if witness[1]:\n",
    "                                        last_witness_second_group = witness[1]\n",
    "                            # Apply post-processing to witnesses\n",
    "                            item['Witnesses'] = post_process_witnesses(updated_witnesses)\n",
    "                        variant_dict['Details'].append(item)\n",
    "                    entry_result['Decoded Entries'].append(variant_dict)\n",
    "            compiled_results.append(entry_result)\n",
    "\n",
    "    # Display the results in a structured format\n",
    "    for result in compiled_results:\n",
    "        print(f\"Entry:\")\n",
    "        print(f\"{result['Entry']}\")\n",
    "        print(\"Lemma Info:\")\n",
    "        for key, value in result['Lemma Info'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Decoded Entries:\")\n",
    "        for variant in result['Decoded Entries']:\n",
    "            print(f\"  {variant['Type']}:\")\n",
    "            for detail in variant['Details']:\n",
    "                if isinstance(detail, dict):\n",
    "                    for key, value in detail.items():\n",
    "                        print(f\"    {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"    {detail}\")\n",
    "        print(\"-\" * 50)  # Separator line\n",
    "    \n",
    "    return compiled_results\n",
    "\n",
    "# Example usage\n",
    "test = compile_and_display_entries(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52bfaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_footnotes(text):\n",
    "    \"\"\"\n",
    "    Extracts footnotes from the text, denoted by numbers in square brackets.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to extract footnotes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the cleaned text (without footnotes) and a list of footnotes.\n",
    "    \"\"\"\n",
    "    # Regex to match footnotes in the format [number]\n",
    "    footnote_pattern = re.compile(r'\\[(\\d+)\\]')\n",
    "    \n",
    "    # Find all footnotes\n",
    "    footnotes = footnote_pattern.findall(text)\n",
    "    \n",
    "    # Remove footnotes from the text\n",
    "    cleaned_text = footnote_pattern.sub('', text)\n",
    "    \n",
    "    return cleaned_text, footnotes\n",
    "\n",
    "def split_full_entry(text):\n",
    "    \"\"\"\n",
    "    Splits a full entry into lemma and part_entry based on the first occurrence of ']'.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full entry text to be split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the lemma and part_entry.\n",
    "               If the split is not possible, returns the entire text as lemma and an empty string as part_entry.\n",
    "    \"\"\"\n",
    "    sliced_entry = text.split(sep=']', maxsplit=1)\n",
    "    if len(sliced_entry) == 2:\n",
    "        lemma, part_entry = sliced_entry\n",
    "    else:\n",
    "        lemma, part_entry = text, \"\"\n",
    "    return lemma, part_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be4749c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manuscript_witnesses(text):\n",
    "    \"\"\"\n",
    "    Extracts manuscript witnesses (\"ms\" or \"mss\") from the text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which to extract manuscript witnesses.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of manuscript witnesses.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'\\b(ms|mss)\\b', re.IGNORECASE)\n",
    "    manuscript_witnesses = pattern.findall(text)\n",
    "    \n",
    "    # Clean the text by removing manuscript witnesses\n",
    "    cleaned_text = pattern.sub('', text)\n",
    "    \n",
    "    return manuscript_witnesses\n",
    "\n",
    "# Adjust other functions to integrate the manuscript extraction\n",
    "def process_entry(entry):\n",
    "    \"\"\"\n",
    "    Processes a textual entry to extract witnesses, readings, and footnotes.\n",
    "\n",
    "    Args:\n",
    "        entry (str): The entry text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing processed witnesses, readings, footnotes, and manuscript witnesses.\n",
    "    \"\"\"\n",
    "    # Extract and remove footnotes\n",
    "    clean_entry, footnotes = extract_footnotes(entry)\n",
    "    \n",
    "    # Existing cross-reference extraction\n",
    "    clean_entry, cross_references = extract_cross_references(clean_entry)\n",
    "    \n",
    "    # Split entry into witnesses and readings\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    \n",
    "    # Initialize the results\n",
    "    result = []\n",
    "    \n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses, manuscript_witnesses = parse_witnesses(split_entry[0])\n",
    "        witnesses_result = {'Witnesses': witnesses, 'Manuscript Witnesses': manuscript_witnesses}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses, manuscript_witnesses = parse_witnesses(split_entry)\n",
    "        witnesses_result = {'Witnesses': witnesses, 'Manuscript Witnesses': manuscript_witnesses}\n",
    "        reading = ''\n",
    "    \n",
    "    result.append(witnesses_result)\n",
    "    result.append({\"Rdg\": reading})\n",
    "    \n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    if footnotes:\n",
    "        result.append({\"Footnotes\": footnotes})\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def process_comma_entry(entry):\n",
    "    \"\"\"\n",
    "    Processes a comma-separated textual entry to extract witnesses, readings, footnotes, and manuscript witnesses.\n",
    "\n",
    "    Args:\n",
    "        entry (str): The entry text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing processed witnesses, readings, footnotes, and manuscript witnesses.\n",
    "    \"\"\"\n",
    "    # Extract and remove footnotes\n",
    "    clean_entry, footnotes = extract_footnotes(entry)\n",
    "    \n",
    "    # Existing cross-reference extraction\n",
    "    clean_entry, cross_references = extract_cross_references(clean_entry)\n",
    "    \n",
    "    # Split entry into witnesses and readings\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    \n",
    "    # Initialize the results\n",
    "    result = []\n",
    "    \n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses, manuscript_witnesses = parse_comma_witnesses(split_entry[0])\n",
    "        witnesses_result = {'Witnesses': witnesses, 'Manuscript Witnesses': manuscript_witnesses}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses, manuscript_witnesses = parse_comma_witnesses(split_entry)\n",
    "        witnesses_result = {'Witnesses': witnesses, 'Manuscript Witnesses': manuscript_witnesses}\n",
    "        reading = ''\n",
    "    \n",
    "    result.append(witnesses_result)\n",
    "    result.append({\"Rdg\": reading})\n",
    "    \n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    if footnotes:\n",
    "        result.append({\"Footnotes\": footnotes})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50458a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cadb22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing functions, including chapter information from Appartus 3\n",
    "def process_full_entry(text, chapter, previous_verse=None):\n",
    "    lemma, part_entry = split_full_entry(text)\n",
    "    lemma_dict = lemma_verse_processor(lemma, chapter)\n",
    "    \n",
    "    # Use the previous verse if the current verse list is empty\n",
    "    if not lemma_dict['verses'] and previous_verse is not None:\n",
    "        lemma_dict['verses'] = previous_verse\n",
    "        \n",
    "\n",
    "    # Split part_entry by '|'\n",
    "    if '|' in part_entry:\n",
    "        entry_parts = part_entry.split('|')\n",
    "    else:\n",
    "        entry_parts = [part_entry]\n",
    "\n",
    "    # Initialize a list to hold all processed parts\n",
    "    processed_parts = []\n",
    "\n",
    "    # Process each part separately\n",
    "    for part in entry_parts:\n",
    "        # Split part by ',' not inside parentheses\n",
    "        sub_parts = split_on_comma_not_in_parentheses(part)\n",
    "\n",
    "        # Process each sub-part using process_comma_entry\n",
    "        processed_sub_parts = [process_comma_entry(sub_part) for sub_part in sub_parts]\n",
    "\n",
    "        # Concatenate processed sub-parts for each part\n",
    "        processed_parts.append(processed_sub_parts)\n",
    "\n",
    "    # Combine processed parts. Assuming you want them as a nested list\n",
    "    decoded_entries = processed_parts\n",
    "\n",
    "    # Return the lemma_dict and decoded_entries, along with the verses used for this entry\n",
    "    return lemma_dict, decoded_entries, lemma_dict['verses']\n",
    "\n",
    "def split_on_comma_not_in_parentheses(part):\n",
    "    \"\"\"\n",
    "    Splits the string on ',' not inside parentheses.\n",
    "    \"\"\"\n",
    "    sub_parts = []\n",
    "    current_part = []\n",
    "    paren_depth = 0  # Track depth of parentheses\n",
    "\n",
    "    for char in part:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0:\n",
    "            # At a top-level comma, split here\n",
    "            sub_parts.append(''.join(current_part))\n",
    "            current_part = []\n",
    "            continue\n",
    "\n",
    "        current_part.append(char)\n",
    "\n",
    "    # Add the last part if there's any\n",
    "    if current_part:\n",
    "        sub_parts.append(''.join(current_part))\n",
    "\n",
    "    return sub_parts\n",
    "\n",
    "def split_full_entry(text):\n",
    "    sliced_entry = text.split(sep=']')\n",
    "    if len(sliced_entry) == 2:\n",
    "        lemma, entry = sliced_entry\n",
    "    #         print(f\"lemma: {lemma}\")\n",
    "    #         print(f\"entry: {entry}\")\n",
    "        return lemma, entry\n",
    "    else:\n",
    "        print(sliced_entry)\n",
    "        return sliced_entry\n",
    "\n",
    "# def lemma_verse_processor(text, chapter):\n",
    "#     # Simplified approach: first split into digits and lemmas\n",
    "#     # Regex to match the verse numbers at the beginning\n",
    "#     verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "#     # Extract verses\n",
    "#     verses_match = re.match(verse_regex, text)\n",
    "#     verses = list(map(int, verses_match.group(1).split('–'))) if verses_match else []\n",
    "    \n",
    "#     # Isolate lemmas part by removing the verses\n",
    "#     lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "#     return {\n",
    "#         'chapter': chapter,\n",
    "#         'verses': verses,\n",
    "#         'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "#     }\n",
    "\n",
    "def lemma_verse_processor(text, chapter):\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    if verses_match:\n",
    "        verse_range = verses_match.group(1).split('–')\n",
    "        if len(verse_range) == 2 and verse_range[0] != verse_range[1]:\n",
    "            verses = {'from': int(verse_range[0]), 'to': int(verse_range[1])}\n",
    "        else:\n",
    "            verses = int(verse_range[0])\n",
    "    else:\n",
    "        verses = None\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    return {\n",
    "        'chapter': chapter,\n",
    "        'verses': verses,\n",
    "        'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(k|q)?\\s*([^\\d\\s]+)(\\d?\\,?\\d?)'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "\n",
    "    # Split lemma if there are separate lemmas with \"/\"\n",
    "    split_lemmas = re.split(r'\\s*/\\s*', lemma) if '/' in lemma else [lemma]\n",
    "    \n",
    "    processed_lemmas = []\n",
    "    for split_lemma in split_lemmas:\n",
    "        processed = process_individual_lemma(split_lemma)\n",
    "        processed_lemmas.extend(processed)\n",
    "    \n",
    "    return processed_lemmas\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "    for match in matches:\n",
    "        prefix, word, number = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if prefix: lemma_dict[prefix] = True\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas\n",
    "\n",
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def extract_cross_references(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    # add an extration of footnotes [\\d]\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def parse_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d.]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def post_process_witnesses(witnesses):\n",
    "    # Define the set of specific values for \"x\"\n",
    "    specific_values = {\"G-B Eb \", \"G-B Kb \", \"G-B Msr \"}  # Replace with the actual values\n",
    "\n",
    "    # Iterate over the witnesses, except for the last one\n",
    "    for i in range(len(witnesses) - 1):\n",
    "        z, y, x = witnesses[i]\n",
    "\n",
    "        # Check if \"x\" is one of the specific values\n",
    "        if x in specific_values:\n",
    "            # Remove \"x\" from the current tuple and prepend it to the \"z\" of the next witness\n",
    "            witnesses[i] = (z, y, '')\n",
    "            next_z, next_y, next_x = witnesses[i + 1]\n",
    "            witnesses[i + 1] = (x + next_z, next_y, next_x)\n",
    "\n",
    "    # Remove the first tuple if it becomes empty\n",
    "    if witnesses and witnesses[0] == ('', '', ''):\n",
    "        witnesses.pop(0)\n",
    "\n",
    "    return witnesses\n",
    "\n",
    "def parse_comma_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d*)?\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~\\.]*)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]*\\s?)[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def witness_reading_splitter(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>~.]*\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>~])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Rdg\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    # here also add the same segment just for \"footnote\" instead of \n",
    "    return result\n",
    "\n",
    "def process_comma_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Rdg\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "715948c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "811ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample entries\n",
    "full_entries = [\n",
    "    \"Chapter 1\",\n",
    "    \"8 k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\",\n",
    "    \"8 שָׂך] 30 (pm) 93 (pm) 150 (pm) סךII IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))\",\n",
    "    \"6 עוד1] 30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\",\n",
    "    \"6 הדעת1] 93 (pm) 150 (pm) דעתII\",\n",
    "    \"14 זעקו] 30 (pm) יזעקו | 150 (pm) >\",\n",
    "    \"10 k שעריריה / q שערוריה] 30 (pm) 89 (pm) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) שערורהIV\",\n",
    "    \"2 ללבבם] 96 (pm) ללבם | 30 93 150 (pm) בלבבםI\",\n",
    "    \"12 עליהם] 96 (pm) להם\",\n",
    "    \"איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\",\n",
    "    \"7 נדמֶה] 93 נדמָה | 30 (pm) + אפרים\",\n",
    "    \"10 ואסרם] 96 (pm) יאשרם.. | 150  ..על\",\n",
    "    \"8 רֻחמה] 30 לח..\",\n",
    "    \"והצגתיה] 93 (pm) + כיום ערומה והצגתיה \",\n",
    "    \"4 דברו] 150 דברים\",\n",
    "    \"7–8 ילכו ינקותיו – כיין לבנון] 30 > \",\n",
    "    \"3 כי1] 150 + לא (non voc)\",\n",
    "    \"וכְמריו] 93 G-B Msr 34 כֹ\",\n",
    "    \"6 בָשנה] G-B Msr 34 בָשְנָה ל ומדׄ מיש ביה בֹשְנָה\",\n",
    "    \"k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\",\n",
    "    \"10 לה] 93 (non voc) 96 150 (non voc) + את\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process lemma:\n",
    "#split into digits and lemmas. then process each separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "b18607da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'verses': [10], 'lemmas': [{'lemma': 'ואסרם'}]},\n",
       " [[({'Witnesses': [('', '96', 'pm')]},\n",
       "    {'Reading': {'Reading': 'יאשרם '}},\n",
       "    {'Cross References': []})],\n",
       "  [({'Witnesses': [('', '150', '')]},\n",
       "    {'Reading': {'Reading': 'על'}},\n",
       "    {'Cross References': []})]])"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[process_full_entry(example) for example in full_entries][-1]#[0]['verses']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "b8c31720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old function, didnt take the splitting into commas consideration\n",
    "# def process_full_entry(text):\n",
    "#     lemma, part_entry = split_full_entry(text)\n",
    "#     lemma_dict = lemma_verse_processor(lemma)\n",
    "# #     if len(lemma_dict['verses'])==0: #get verse from previous entry\n",
    "# #         lemma_dict['verses'] = \n",
    "        \n",
    "#     #entry_units = split_entry_units # splits on | and ,\n",
    "#     #for entry in entry_units:\n",
    "#     decoded_entry = process_entry(part_entry)\n",
    "#     return lemma_dict, decoded_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "4b9188ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def remove_and_list_roman_numerals(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "    split_entry = split_string(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "        if len(split_entry)==2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else: #there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry)}\n",
    "        reading = ''\n",
    "    return witnesses, {\"Reading\":reading}, {\"Cross References\":cross_references}\n",
    "\n",
    "\n",
    "# for entry in sample_texts:\n",
    "#     print(f\"entry: {entry}\")\n",
    "#     clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "#     split_entry = split_string(clean_entry)\n",
    "#     if type(split_entry) is tuple:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry[0])}\n",
    "#         reading = parse_reading_entry(split_entry[1])\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#         print(f\"reading: {reading}\")\n",
    "#     else:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry)}\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#     print(f\"references: {cross_references}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "cd41862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"96 (non voc)\",\n",
    "    \"30 (pm) 93 (pm) 150 (pm) + סךII IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))\",\n",
    "    \"93 (non voc) 96 150 (non voc) + את\",\n",
    "    \"30 (pm) >\",\n",
    "    \"30 + לי (non voc)I II\",\n",
    "    \"30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\",\n",
    "    \"93 (pm) ביהושעIV (similarly PesiqtaR 33 (153b))\",\n",
    "    \"96 >I II IV\",\n",
    "    \"130 k\",\n",
    "    \"G-B Msr 34 k ממני / q ממנוIV\",\n",
    "    \"93 כד..\",\n",
    "    \"150 ..דברים\",\n",
    "    \"G-B Eb 94 ותָעָד (understood as \\עוד (rather than \\עדי))\",\n",
    "    \"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "a0ae7422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Witnesses': [('', '93', 'pm')]},\n",
       " {'Reading': {'Reading': 'ביהושע ',\n",
       "   'Comment': '(similarly PesiqtaR 33 (153b))'}},\n",
       " {'Cross References': ['IV']})"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_entry(sample_texts[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "2a94af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'}"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_entry, cross_references = remove_and_list_roman_numerals(sample_texts[6])\n",
    "split_entry = split_string(clean_entry)\n",
    "if type(split_entry) is tuple:\n",
    "    witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "    if len(split_entry)==2:\n",
    "        reading = parse_reading_entry(split_entry[1])\n",
    "    else: #there are 3 groups:\n",
    "        reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "\n",
    "reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "08fa1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', '30', 'pm'), ('', '93', ''), ('', '150', 'pm')]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "# \"96 (non voc)\",\n",
    "# \"30 (pm) 93 (pm) 150 (pm)\n",
    "test_witness = \"30 (pm) 93 150 (pm)\"\n",
    "custom_split_string(test_witness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "fbefcdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['96 (non voc)', ('30 (pm) 93 (pm) 150 (pm) ', '+ סך', 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'), ('93 (non voc) 96 150 (non voc) ', '+ את', ''), ('30 (pm) ', '>', ''), ('30 ', '+ לי', ' (non voc)I II'), ('30 (pm) ', '>', 'I II IV (similarly b. Pesaḥim 87bmss)'), ('93 (pm)', ' ביהושע', 'IV (similarly PesiqtaR 33 (153b))'), ('96 ', '>', 'I II IV'), ('130', ' k', ''), ('G-B Msr 34', ' k', ' ממני / q ממנוIV'), ('93', ' כד', '..'), ('150 ..', 'דברים', ''), ('G-B Eb 94', ' ותָעָד', ' (understood as \\\\עוד (rather than \\\\עדי))'), ('30 89 (sm) 93 (pm) 150 (non voc) ', '+ כי', 'I II IV')]\n"
     ]
    }
   ],
   "source": [
    "#try parsing single entry app, splitting into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "processed_sample = [split_string(text) for text in sample_texts]\n",
    "\n",
    "print(processed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "473068c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Reading': 'סך ',\n",
       "  'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'},\n",
       " {'Sigla': '+', 'Reading': 'את'},\n",
       " {'Sigla': '>'},\n",
       " {'Sigla': '+', 'Reading': 'לי ', 'Comment': '(non voc)'},\n",
       " {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'},\n",
       " {'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'},\n",
       " {},\n",
       " {'Reading': 'k'},\n",
       " {'Reading': 'k ממני / q ממנו'},\n",
       " {'Reading': 'כד..'},\n",
       " {'Reading': '..דברים'},\n",
       " {'Reading': 'נַחֵם ',\n",
       "  'Comment': '(taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)'},\n",
       " {'Reading': 'חכֵם ', 'Comment': '(!)'}]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for parsing the reading+comment (assumes witnesses and cross references have been removed)\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "# Process the sample reading texts with the refined function\n",
    "parse_reading_entry = [parse_reading_entry(text) for text in sample_reading_texts]\n",
    "\n",
    "parse_reading_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "94a5de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [{'witnesses': '30 (pm) 93 (pm) 150 (pm)', 'reading': '+ סך', 'comments': 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}], [{'witnesses': '93 (non voc) 96 150 (non voc)', 'reading': '+ את', 'comments': ''}], [], [{'witnesses': '30', 'reading': '+ לי', 'comments': '(non voc)I II'}], [], [{'witnesses': '93 (pm)', 'reading': 'ביהושע', 'comments': 'IV (similarly PesiqtaR 33 (153b))'}], [], [], [{'witnesses': 'G-B Msr 34 k', 'reading': 'ממני', 'comments': '/ q ממנוIV'}], [{'witnesses': '93', 'reading': 'כד', 'comments': '..'}], [{'witnesses': '150 ..', 'reading': 'דברים', 'comments': ''}], [{'witnesses': 'G-B Eb 94', 'reading': 'ותָעָד', 'comments': '(understood as \\\\עוד (rather than \\\\עדי))'}], [{'witnesses': '30 89 (sm) 93 (pm) 150 (non voc)', 'reading': '+ כי', 'comments': 'I II IV'}]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_string_processor(input_string, regex_pattern):\n",
    "    # Helper function to apply regex and extract groups\n",
    "    def apply_regex_and_extract(text):\n",
    "        matches = re.finditer(regex_pattern, text)\n",
    "        results = []\n",
    "        for match in matches:\n",
    "            results.append({\n",
    "                'witnesses': match.group(1).strip(),\n",
    "                'reading': match.group(2).strip(),\n",
    "                'comments': match.group(3).strip() if match.group(3) else ''\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    # Process splits with \"|\", then \",\"\n",
    "    def process_splits(text, delimiter):\n",
    "        parts = text.split(delimiter)\n",
    "        processed_parts = []\n",
    "        for part in parts:\n",
    "            # Apply regex to each part\n",
    "            processed = apply_regex_and_extract(part)\n",
    "            if processed:\n",
    "                processed_parts.extend(processed)\n",
    "        return processed_parts\n",
    "\n",
    "    # Start processing\n",
    "    processed_result = process_splits(input_string, '|')  # Start with the highest level of split\n",
    "\n",
    "    return processed_result\n",
    "\n",
    "# Custom regex pattern as provided\n",
    "custom_regex = r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$'\n",
    "\n",
    "# Test with the provided sample input\n",
    "sample_input = \"G-B msr. 30 (pm) G-A 89 (sm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) + שערורהIV II (bla bla (f)) | 150 >\"\n",
    "processed_sample = [custom_string_processor(text, custom_regex) for text in sample_texts]\n",
    "\n",
    "\n",
    "print(processed_sample)\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "# text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "# split_parts = split_string(text)\n",
    "# if split_parts:\n",
    "#     print(\"witnesses:\", split_parts[0])\n",
    "#     print(\"reading:\", split_parts[1])\n",
    "#     print(\"After dividers:\", split_parts[2])\n",
    "# else:\n",
    "#     print(\"No dividers found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5b4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_apparatus_entry(entry):\n",
    "    \"\"\"Parse an apparatus entry into lemma(s) and content.\"\"\"\n",
    "    parts = entry.split(']')\n",
    "    lemmas_contents = []\n",
    "    for part in parts:\n",
    "        if part.strip():\n",
    "            lemma, content = part.split('[', 1) if '[' in part else (part, '')\n",
    "            lemmas_contents.append((lemma.strip(), content.strip()))\n",
    "    return lemmas_contents\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    \"\"\"Create a TEI document from apparatus lines.\"\"\"\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    NSMAP = {\"tei\": TEI_NAMESPACE}\n",
    "    \n",
    "    tei_root = ET.Element(TEI+\"TEI\", nsmap=NSMAP)\n",
    "    tei_header = ET.SubElement(tei_root, TEI+\"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI+\"text\")\n",
    "    body = ET.SubElement(text, TEI+\"body\")\n",
    "    current_chapter = None\n",
    "    last_verse = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1]\n",
    "            current_chapter = ET.SubElement(body, TEI+\"div\", type=\"chapter\", n=chapter_number)\n",
    "            last_verse = None\n",
    "            continue\n",
    "        # Use regex to check if the line starts with a verse number and capture it\n",
    "        match = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "        if match:\n",
    "            verse_number, entry = match.groups()\n",
    "            last_verse = verse_number\n",
    "        else:\n",
    "            entry = line\n",
    "            verse_number = last_verse\n",
    "        \n",
    "        if current_chapter is not None and verse_number:\n",
    "            lemmas_contents = parse_apparatus_entry(entry)\n",
    "            for lemma, content in lemmas_contents:\n",
    "                app = ET.SubElement(current_chapter, TEI+\"app\")\n",
    "                lem = ET.SubElement(app, TEI+\"lem\", n=verse_number)\n",
    "                lem.text = lemma\n",
    "                if content:\n",
    "                    rdg = ET.SubElement(app, TEI+\"rdg\")\n",
    "                    rdg.text = content\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    \"\"\"Save the TEI XML tree to a file.\"\"\"\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caaa3e86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line does not conform to expected format: ﻿App III: Hosea\n",
      "Line does not conform to expected format: יחזקיה] 30 93 (pm) 96 יחזקיהו\n",
      "Line does not conform to expected format: ירבעם בן] 30 + נבט (non voc)\n",
      "Line does not conform to expected format: לו] 96 >I  II IV\n",
      "Line does not conform to expected format: ממלכוּת] 96 ממלכוֹת\n",
      "Line does not conform to expected format: יזרעאל] 150 ישראל (parall; but 150-Tg: יזרעאל)\n",
      "Line does not conform to expected format: כי] 93 (pm) + את\n",
      "Line does not conform to expected format: אוסיף] 150 (pm) >\n",
      "Line does not conform to expected format: את] 93 (pm) >\n",
      "Line does not conform to expected format: בסוסים] 96 ובסוסיםI IV\n",
      "Line does not conform to expected format: אשר2] 96 + לא\n",
      "Line does not conform to expected format: אחד] 30 (pm) 150 (pm) >\n",
      "Line does not conform to expected format: והצגתיה] 93 (pm) + כיום ערומה והצגתיה\n",
      "Line does not conform to expected format: ושתִּה] 150 (pm) ושמתיה\n",
      "Line does not conform to expected format: כי] 150 (non voc) + כי\n",
      "Line does not conform to expected format: שכְחה] 150 (pm) שכחת\n",
      "Line does not conform to expected format: מפתיה] 89 מְפַּתֶיהָ\n",
      "Line does not conform to expected format: המדבר] 96 המדברה (similarly SifreDeut 313 (356:6), RuthR 5:6)\n",
      "Line does not conform to expected format: תקראי1] 150 (pm) תקראו | 30 + לי (non voc)I II\n",
      "Line does not conform to expected format: לי] G-B Eb 54 (pm) >II\n",
      "Line does not conform to expected format: עוד] 30 (pm?) >\n",
      "Line does not conform to expected format: את] 30 89 (sm) 93 (pm) אניI II IV\n",
      "Line does not conform to expected format: לא] 96 ולאI\n",
      "Line does not conform to expected format: תזני] 93 (pm) תתי (Caused by ligature ז+נ)\n",
      "Line does not conform to expected format: אליך] 93 (pm) אלהיך\n",
      "Line does not conform to expected format: וגם] 30 (pm) וכל\n",
      "Line does not conform to expected format: אתה] 96 (pm) את\n",
      "Line does not conform to expected format: k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\n",
      "Line does not conform to expected format: ותשכח] 150 (pm) תשכחי\n",
      "Line does not conform to expected format: נפשו] 89 (pm) 96 (pm) 150 (pm) נפשםI IV\n",
      "Line does not conform to expected format: עליו] 96 + ודמו (non voc)\n",
      "Line does not conform to expected format: דרכיו] 30 (pm) כדרכיו\n",
      "Line does not conform to expected format: הזנו] 150 (pm) והזנו\n",
      "Line does not conform to expected format: כי] 96 >\n",
      "Line does not conform to expected format: צלה] 93 (pm) יגלה\n",
      "Line does not conform to expected format: וכלותיכם] 150 (pm) + כי\n",
      "Line does not conform to expected format: הזֹנות] 93 (pm) זנות\n",
      "Line does not conform to expected format: יְפָרדו] 93 96 יִפָּרדו\n",
      "Line does not conform to expected format: ואל1] 150 (pm) אלI IV\n",
      "Line does not conform to expected format: ואַל3] 30 ואֵל\n",
      "Line does not conform to expected format: אהבו] 93 (pm) אתם\n",
      "Line does not conform to expected format: קלון] 150 (pm) קלו\n",
      "Line does not conform to expected format: מגניה] 96 (pm) מקלון\n",
      "Line does not conform to expected format: מִזִּבְחותם] 30 93 150 מִזְבְּחתםI IV | 96 מִזְבְחותם\n",
      "Line does not conform to expected format: אל] 93 (pm) + אלI IV\n",
      "Line does not conform to expected format: בקרבם] 96 (pm) בקרבכם\n",
      "Line does not conform to expected format: עמם] 93 (pm) עמכם\n",
      "Line does not conform to expected format: את] 93 + דבר (non voc)II IV\n",
      "Line does not conform to expected format: עתה] 93 (pm) ועתה\n",
      "Line does not conform to expected format: את] 30 (pm) >\n",
      "Line does not conform to expected format: בית] 150 בין (similarly b. R.HaŠanams 32b)\n",
      "Line does not conform to expected format: אחריך] 93 (pm) >\n",
      "Line does not conform to expected format: גבול] 93 + עולם (non voc) (cf גבול עולם Prov 2228 2310)\n",
      "Line does not conform to expected format: וְכָרקב] 93 96 וּכְרקב\n",
      "Line does not conform to expected format: וישלח] 93 מ..\n",
      "Line does not conform to expected format: מיֹמים] 30 (pm?) >\n",
      "Line does not conform to expected format: כמלקוש] 150 (pm) ומלקושI II IV\n",
      "Line does not conform to expected format: מה2] 30 93 150 (pm) ומהI\n",
      "Line does not conform to expected format: לְךָ2] 96 לָךְ | 30 (pm) + אפרים\n",
      "Line does not conform to expected format: וחסדכם] 93 150 חסדכםI\n",
      "Line does not conform to expected format: הֹלך] 96 והולךI\n",
      "Line does not conform to expected format: חבר] 93 (pm) וחבר\n",
      "Line does not conform to expected format: שׁם] 96 שׂם\n",
      "Line does not conform to expected format: וגנב] 30 וכגנב\n",
      "Line does not conform to expected format: פשט] 93 (pm) ופשטI (similarly S.Eli.R 22 (125))\n",
      "Line does not conform to expected format: בחוץ] 96 (pm) בחרץ\n",
      "Line does not conform to expected format: מעיר] 96 (sm) עיר\n",
      "Line does not conform to expected format: מלוש] 150 (pm) בלוש\n",
      "Line does not conform to expected format: שרים] 30 (pm) >\n",
      "Line does not conform to expected format: ידו את] 30 ~\n",
      "Line does not conform to expected format: אֹפֵהֶם] 93 (pm) אפריםI\n",
      "Line does not conform to expected format: לב] 89 (pm) לבי\n",
      "Line does not conform to expected format: איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\n",
      "Line does not conform to expected format: פשעוּ] 96 פשעִי\n",
      "Line does not conform to expected format: ואנכי] 150 (pm) ואניIV\n",
      "Line does not conform to expected format: דברו] 93 (pm) >\n",
      "Line does not conform to expected format: בלבם] 93 (pm) בלבבםIV\n",
      "Line does not conform to expected format: יתגוררו] 93 (pm) >\n",
      "Line does not conform to expected format: על היו] 150 (pm) ~\n",
      "Line does not conform to expected format: זוֹ] 96 זוּ\n",
      "Line does not conform to expected format: עברו] 96 (pm) עבר\n",
      "Line does not conform to expected format: תורָתי] 89 (pm) תורֹתי\n",
      "Line does not conform to expected format: בו] 96 בֹה\n",
      "Line does not conform to expected format: שרים] 96 150 ושריםI II IV\n",
      "Line does not conform to expected format: אפרים] 30 (pm) ישראל\n",
      "Line does not conform to expected format: לו] 93 (pm) לי\n",
      "Line does not conform to expected format: k רבו / q רבי] 30 89 93 96 q, 150 (pm) רובו\n",
      "Line does not conform to expected format: יהוה] 150 (pm) ויהוהI IV\n",
      "Line does not conform to expected format: עתה] 150 (pm) ועתה\n",
      "Line does not conform to expected format: חטֹאותם] 89 93 96 150 (pm) חטאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: המה] 150 (pm) והמהIV\n",
      "Line does not conform to expected format: הרבה] 30 (pm) + מזבחות\n",
      "Line does not conform to expected format: ואכלה] 150 (pm) + כל\n",
      "Line does not conform to expected format: ארמנתיה] 93 (pm) ארמנותיו\n",
      "Line does not conform to expected format: בית] 93 (pm) >\n",
      "Line does not conform to expected format: לכספם] 150 לנפשם\n",
      "Line does not conform to expected format: אויל] 96 (pm) >\n",
      "Line does not conform to expected format: רֹב] 96 רַב\n",
      "Line does not conform to expected format: עונְךָ] 96 עונֵךְ\n",
      "Line does not conform to expected format: ורבה] 150 (pm) רבהIV\n",
      "Line does not conform to expected format: נביא] 96 (pm) הנביא\n",
      "Line does not conform to expected format: יקוֹש] 93 96 יקוּש\n",
      "Line does not conform to expected format: חטאותם] 89 93 150 (pm) חטֹאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: וַינזרו] 30 וְינזרו\n",
      "Line does not conform to expected format: ויהיו] 96 (pm) ויהי\n",
      "Line does not conform to expected format: רחם] 96 (pm) מרחם\n",
      "Line does not conform to expected format: מביתי] 93 (pm) מביתIV\n",
      "Line does not conform to expected format: ילדון] 93 (pm) ילזון\n",
      "Line does not conform to expected format: לו] 150 >\n",
      "Line does not conform to expected format: למזבחות] 93 (pm) למזבח\n",
      "Line does not conform to expected format: יָרֵאנו] 30 יַרְאֵנו\n",
      "Line does not conform to expected format: כרֹת] 96 (pm) וכרותI\n",
      "Line does not conform to expected format: ופרח] 150 (pm) ופתח\n",
      "Line does not conform to expected format: וכְמריו] G-B Msr 34 כֹ\n",
      "Line does not conform to expected format: יגילו] 150 (sm) יגלו\n",
      "Line does not conform to expected format: על] 93 (pm) ועל\n",
      "Line does not conform to expected format: ממנו] 96 (pm) ממני\n",
      "Line does not conform to expected format: מלכהּ] 93 (pm) מלכם\n",
      "Line does not conform to expected format: מים] 93 (pm) המים\n",
      "Line does not conform to expected format: כַּסונו] 89 כִּסונו (?)\n",
      "Line does not conform to expected format: חטאתָ] 93 (sm) 96 (sm) חטא (ת non voc)\n",
      "Line does not conform to expected format: עלוה] 89 (sm) עולהI\n",
      "Line does not conform to expected format: k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\n",
      "Line does not conform to expected format: ועת] 150 (pm) עת\n",
      "Line does not conform to expected format: לדרוש] 96 >\n",
      "Line does not conform to expected format: את] 30 (pm) >, 96 (non voc)\n",
      "Line does not conform to expected format: יהוה] 93 (pm) יהודה\n",
      "Line does not conform to expected format: ויֹרה] 93 (pm) G-B Eb 16 יורה\n",
      "Line does not conform to expected format: שלמן] 96 שלומך\n",
      "Line does not conform to expected format: ארבֵאל] 93 ארבְּאֵל\n",
      "Line does not conform to expected format: ולפסִלים] 96 לפסילים\n",
      "Line does not conform to expected format: רפאתים] 96 (pm) רפאתיו\n",
      "Line does not conform to expected format: לחֵיהם] 30 93 לחָיֵיהם\n",
      "Line does not conform to expected format: ממֹעצותיהם] 96 (pm) ממעֲוצותיהם\n",
      "Line does not conform to expected format: למשובתי] 30 (pm) למשבתוI\n",
      "Line does not conform to expected format: ולא2] 93 (sm) 150 (pm) לאII IV\n",
      "Line does not conform to expected format: ושֹׁד] 93 (pm) >\n",
      "Line does not conform to expected format: וברית] 96 (pm) ובריית\n",
      "Line does not conform to expected format: ישיב] 30 (pm) 150 (pm) אשיבI\n",
      "Line does not conform to expected format: בגלגל] 150 (pm) ובגלגל\n",
      "Line does not conform to expected format: זבחו] 93 (pm) >\n",
      "Line does not conform to expected format: גם מזבחותם] 96 >\n",
      "Line does not conform to expected format: ויושיעֲך] 96 (pm) ויושיעוך\n",
      "Line does not conform to expected format: לי] 96 לנו\n",
      "Line does not conform to expected format: הוא] 93 (pm) 150 (pm) והואIV\n",
      "Line does not conform to expected format: לא1] 93 ולא\n",
      "Line does not conform to expected format: דבריך] 30 93 (pm) 96 דברךI II IV\n",
      "Line does not conform to expected format: נֹחם] G-B Msr 34 נַחֵם (taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)\n",
      "Line does not conform to expected format: ויבוש] 93 (pm) תיבש\n",
      "Line does not conform to expected format: הוא2] 93 (pm) 96 150 (pm) והואI II\n",
      "Line does not conform to expected format: אמרו] 30 (pm) 93 (pm) 96 150 (pm) ואמרוII IV\n",
      "Line does not conform to expected format: כל] 89 (pm) בלI\n",
      "Line does not conform to expected format: וצדקים] 96 צדיקים\n",
      "Line does not conform to expected format: ‏App III: Hosea\n",
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    \n",
    "    tei_root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    tei_header = ET.SubElement(tei_root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    current_chapter = None\n",
    "    last_verse_number = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1].strip()\n",
    "            current_chapter = ET.SubElement(body, TEI + \"div\", type=\"chapter\", n=chapter_number)\n",
    "        else:\n",
    "            # Attempt to extract verse number and lemma content\n",
    "            parts = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "            if parts:\n",
    "                verse_number, remainder = parts.groups()\n",
    "                last_verse_number = verse_number  # Update last verse number with current\n",
    "                \n",
    "                # Further split to separate lemma from variants, if present\n",
    "                lemma_section, variants_section = remainder.split(']', 1) if ']' in remainder else (remainder, \"\")\n",
    "                lemma_section = lemma_section.strip()\n",
    "                variants_section = variants_section.strip()\n",
    "\n",
    "                if current_chapter is not None and verse_number:\n",
    "                    # Create an apparatus entry for the lemma\n",
    "                    app = ET.SubElement(current_chapter, TEI + \"app\")\n",
    "                    lem = ET.SubElement(app, TEI + \"lem\", n=verse_number)\n",
    "                    lem.text = lemma_section\n",
    "                    \n",
    "                    # Add variant readings if present\n",
    "                    if variants_section:\n",
    "                        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "                        rdg.text = variants_section\n",
    "            else:\n",
    "                print(f\"Line does not conform to expected format: {line}\")\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808c9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    app = ET.Element(TEI + \"app\")\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, TEI + \"lem\")\n",
    "    lem.text = lemma_text.strip()\n",
    "    \n",
    "    # Extract comments\n",
    "    comments = re.findall(r'\\((.*?)\\)', rest)\n",
    "    for comment in comments:\n",
    "        note = ET.SubElement(app, TEI + \"note\")\n",
    "        note.text = comment\n",
    "    \n",
    "    # Remove comments from rest for further processing\n",
    "    rest = re.sub(r'\\(.*?\\)', '', rest).strip()\n",
    "    \n",
    "    # Extract and process witnesses and cross-references\n",
    "    if rest:\n",
    "        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "        witnesses, _, variant_reading = rest.partition(' ')\n",
    "        if witnesses:\n",
    "            rdg.set('wit', witnesses.strip())\n",
    "        if variant_reading:\n",
    "            rdg.text = variant_reading.strip()\n",
    "        \n",
    "        # Extract cross-references, assuming they are indicated by Roman numerals at the start\n",
    "        cross_refs = re.findall(r'\\bI{1,3}V?|\\bIV', rest)\n",
    "        for ref in cross_refs:\n",
    "            ref_element = ET.SubElement(rdg, TEI + \"ref\")\n",
    "            ref_element.set('target', '#' + ref)  # Assuming target IDs are prefixed with '#'\n",
    "            ref_element.text = \"See apparatus entry \" + ref\n",
    "    \n",
    "    return app\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    div = ET.SubElement(body, TEI + \"div\")\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI)\n",
    "            div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a6244acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "witnesses: G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) \n",
      "reading: > שערורה\n",
      "After dividers: IV (bla bla (f))\n"
     ]
    }
   ],
   "source": [
    "#split entry into witnesses, reading, and comments \n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "split_parts = split_string(text)\n",
    "if split_parts:\n",
    "    print(\"witnesses:\", split_parts[0])\n",
    "    print(\"reading:\", split_parts[1])\n",
    "    print(\"After dividers:\", split_parts[2])\n",
    "else:\n",
    "    print(\"No dividers found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "70cc4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('G-B msr. ', '30', 'pm'), ('G-A ', '89', 'pm?'), ('', '150', 'non voc'), ('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('MS-G ', '150', 'pm')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "25936b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\n",
      "Numerals found: ['II', 'IV']\n"
     ]
    }
   ],
   "source": [
    "#parse comments\n",
    "import re\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# Example usage\n",
    "text = \"II IV (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\"\n",
    "result_text, numerals_found = remove_and_list_roman_numerals(text)\n",
    "print(\"Modified text:\", result_text.strip())\n",
    "print(\"Numerals found:\", numerals_found)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d33f9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entry(entry):\n",
    "    split_parts = split_string(entry)\n",
    "    if split_parts is None:\n",
    "        return None\n",
    "    \n",
    "    witnesses, reading, comments = split_parts\n",
    "\n",
    "    structured_entry = {\n",
    "        'witnesses': [],\n",
    "        'reading': reading,\n",
    "        'comments': '',\n",
    "        'cross_references': []\n",
    "    }\n",
    "\n",
    "    for part in custom_split_string(witnesses):\n",
    "        # Assuming part[1] contains the witness number and part[0], part[2], part[3] contain additional info\n",
    "        witness_info = {\n",
    "            'n': part[1],\n",
    "            'text': f\"{part[0]}{part[1]} {part[2].strip()}{part[3]}\"\n",
    "        }\n",
    "        structured_entry['witnesses'].append(witness_info)\n",
    "\n",
    "    comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "    structured_entry['comments'] = comments_text\n",
    "    structured_entry['cross_references'] = numerals_found\n",
    "\n",
    "    return structured_entry\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    TEI_ns = {'tei': TEI}  # Define the namespace dictionary if needed\n",
    "    app = ET.Element(f\"{{{TEI}}}app\")  # Using namespace in the tag\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, f\"{{{TEI}}}lem\")\n",
    "    lem.text = lemma_text.strip('[] ')\n",
    "\n",
    "    structured_entry = process_entry(rest)\n",
    "    if not structured_entry:\n",
    "        return None\n",
    "\n",
    "    for witness in structured_entry['witnesses']:\n",
    "        wit_element = ET.SubElement(app, f\"{{{TEI}}}wit\", {'n': witness['n']})\n",
    "        wit_element.text = witness['text']\n",
    "    \n",
    "    rdg_element = ET.SubElement(app, f\"{{{TEI}}}rdg\")\n",
    "    rdg_element.text = structured_entry['reading']\n",
    "\n",
    "    if structured_entry['comments']:\n",
    "        comment_element = ET.SubElement(app, f\"{{{TEI}}}note\")\n",
    "        comment_element.text = structured_entry['comments']\n",
    "\n",
    "    for ref in structured_entry['cross_references']:\n",
    "        ref_element = ET.SubElement(app, f\"{{{TEI}}}ref\")\n",
    "        ref_element.text = ref\n",
    "\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8e18d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    ET.register_namespace('', TEI_NAMESPACE)  # Register the default namespace\n",
    "\n",
    "    # Create the root element without redundantly specifying the xmlns attribute\n",
    "    root = ET.Element(\"{%s}TEI\" % TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, \"{%s}teiHeader\" % TEI_NAMESPACE)\n",
    "    text = ET.SubElement(root, \"{%s}text\" % TEI_NAMESPACE)\n",
    "    body = ET.SubElement(text, \"{%s}body\" % TEI_NAMESPACE)\n",
    "    div = ET.SubElement(body, \"{%s}div\" % TEI_NAMESPACE)\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI_NAMESPACE)\n",
    "            if entry is not None:  # Ensure entry creation was successful\n",
    "                div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a4a220d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'witnesses': [{'n': '30', 'text': 'G-B msr. 30 (pm) '}, {'n': '89', 'text': 'G-A 89 (pm?) '}, {'n': '150', 'text': '150 (non voc) k'}, {'n': '30', 'text': ' 30 (sm) '}, {'n': '89', 'text': '89 (sm) '}, {'n': '93', 'text': '93 (sm) '}, {'n': '96', 'text': '96 '}, {'n': '150', 'text': '150 (pm) q'}, {'n': '93', 'text': ' 93 (pm) '}], 'reading': '> שערורה', 'comments': '  (bla bla (f))', 'cross_references': ['IV', 'II']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def custom_split_string(text):\n",
    "    pattern = re.compile(r'([^,\\d]*?)?(\\d+)\\s?(\\([^\\)]+\\)?)?([\\skq]*)?', re.DOTALL|re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# def process_entry(entry):\n",
    "#     split_parts = split_string(entry)\n",
    "#     if split_parts is None:\n",
    "#         return \"Unable to process entry: No valid dividers found.\"\n",
    "    \n",
    "#     witnesses, reading, comments = split_parts\n",
    "\n",
    "#     witness_entries = []\n",
    "#     for part in custom_split_string(witnesses):\n",
    "#         witness_entry = f'<witness n=\"{part[1]}\">{part[0]}{part[1]} {part[2].strip()}{part[3]}</witness>'\n",
    "#         witness_entries.append(witness_entry)\n",
    "#     witnesses_tagged = \"\\n\".join(witness_entries)\n",
    "\n",
    "#     reading_tagged = f'<reading>{reading}</reading>'\n",
    "\n",
    "#     comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "#     comments_tagged = f'<comment>{comments_text}</comment>'\n",
    "#     cross_references = \"\\n\".join([f'<ref>{numeral}</ref>' for numeral in numerals_found])\n",
    "\n",
    "#     # Combine all parts, placing cross_references outside the comment\n",
    "#     tei_entry = f\"{witnesses_tagged}\\n{reading_tagged}\\n{comments_tagged}\\n{cross_references}\"\n",
    "#     return tei_entry\n",
    "\n",
    "# Example usage\n",
    "entry =\"G-B msr. 30 (pm) G-A 89 (pm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV II (bla bla (f))\"\n",
    "processed_entry = process_entry(entry)\n",
    "print(processed_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[' ', '\"', '$', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', 'E', 'I', 'T', '_', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', '֑', '֔', '֕', '֖', '֗', '֙', '֛', '֜', '֞', '֣', '֤', '֥', '֨', '֩', 'ְ', 'ֱ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ֽ', '׀', 'ׁ', 'ׂ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b04929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'ואמאסאך', 'k': True}, {'lemma': 'ואמאסך', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q  '}\n",
      "    Cross References: ['IV']\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'אמסך'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'שָׂך'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'סך  ', 'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}\n",
      "    Cross References: ['II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עוד', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'}\n",
      "    Cross References: ['I', 'II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'הדעת', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'דעת'}\n",
      "    Cross References: ['II']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [14]\n",
      "  lemmas: [{'lemma': 'זעקו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Reading': 'יזעקו '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'שעריריה', 'k': True}, {'lemma': 'שערוריה', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '89', 'pm'), ('', '150', 'sm')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'שערורה'}\n",
      "    Cross References: ['IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [2]\n",
      "  lemmas: [{'lemma': 'ללבבם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'ללבם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'בלבבם'}\n",
      "    Cross References: ['I']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'עליהם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'להם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'איסירם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '89', '')]\n",
      "    Reading: {'Reading': 'איסרם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'אייסרם'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '96', 'sm')]\n",
      "    Reading: {'Reading': 'אייסירים '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'אסירים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7]\n",
      "  lemmas: [{'lemma': 'נדמֶה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', '')]\n",
      "    Reading: {'Reading': 'נדמָה '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'אפרים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'ואסרם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'יאשרם.. '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', ' ')]\n",
      "    Reading: {'Sigla': '..', 'Reading': 'על'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'רֻחמה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'לח..'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'והצגתיה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'כיום ערומה והצגתיה '}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [4]\n",
      "  lemmas: [{'lemma': 'דברו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Reading': 'דברים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7, 8]\n",
      "  lemmas: {'from': [{'lemma': 'ילכו'}, {'lemma': 'ינקותיו'}], 'to': [{'lemma': 'כיין'}, {'lemma': 'לבנון'}]}\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'כי', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'לא ', 'Comment': '(non voc)'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'וכְמריו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'G-B Msr '), ('', '34', '')]\n",
      "    Reading: {'Reading': 'כֹ'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'בָשנה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '', 'G-B Msr '), ('', '34', '')]\n",
      "    Reading: {'Reading': 'בָשְנָה ל ומדׄ מיש ביה בֹשְנָה'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עינתם', 'k': True}, {'lemma': 'עונֹתם', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '89', 'G-B Eb '), ('', '16', '')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', ''), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'עונותם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'לה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'non voc'), ('', '96', ''), ('', '150', 'non voc')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'את'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#old function. didnt handle the \"E-G misr\" etc.\n",
    "def compile_and_display_entries(entries):\n",
    "    previous_verse = None\n",
    "    compiled_results = []\n",
    "\n",
    "    for entry in entries:\n",
    "        lemma_dict, decoded_entries, used_verse = process_full_entry(entry, previous_verse)\n",
    "        previous_verse = used_verse\n",
    "\n",
    "        # Combine the lemma_dict and decoded_entries for display\n",
    "        entry_result = {\n",
    "            'Lemma': lemma_dict,\n",
    "            'Decoded Entries': decoded_entries\n",
    "        }\n",
    "        compiled_results.append(entry_result)\n",
    "\n",
    "    # Display the results in a structured format\n",
    "    for result in compiled_results:\n",
    "        print(\"Lemma:\")\n",
    "        for key, value in result['Lemma'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Decoded Entries:\")\n",
    "        last_witness_second_group = None\n",
    "        for i, decoded_entries_list in enumerate(result['Decoded Entries']):\n",
    "            for j, decoded_entry in enumerate(decoded_entries_list):\n",
    "                variant_type = \"Variant\" if j == 0 else \"Related Variant\"\n",
    "                print(f\"  {variant_type}:\")\n",
    "                for item in decoded_entry:\n",
    "                    if isinstance(item, dict) and 'Witnesses' in item:\n",
    "                        # Update witnesses with last non-empty second group if needed\n",
    "                        updated_witnesses = []\n",
    "                        for witness in item['Witnesses']:\n",
    "                            if witness[1] == '' and last_witness_second_group:\n",
    "                                updated_witnesses.append((witness[0], last_witness_second_group, witness[2]))\n",
    "                            else:\n",
    "                                updated_witnesses.append(witness)\n",
    "                                if witness[1]:\n",
    "                                    last_witness_second_group = witness[1]\n",
    "                        item['Witnesses'] = updated_witnesses\n",
    "                    if isinstance(item, dict):\n",
    "                        for key, value in item.items():\n",
    "                            print(f\"    {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"    {item}\")\n",
    "        print(\"-\" * 50)  # Separator line\n",
    "\n",
    "# Example usage\n",
    "compile_and_display_entries(full_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5fad16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'ואמאסאך', 'k': True}, {'lemma': 'ואמאסך', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q  '}\n",
      "    Cross References: ['IV']\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'אמסך'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'שָׂך'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'סך  ', 'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}\n",
      "    Cross References: ['II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עוד', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'}\n",
      "    Cross References: ['I', 'II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'הדעת', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'דעת'}\n",
      "    Cross References: ['II']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [14]\n",
      "  lemmas: [{'lemma': 'זעקו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Reading': 'יזעקו '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'שעריריה', 'k': True}, {'lemma': 'שערוריה', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '89', 'pm'), ('', '150', 'sm')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'שערורה'}\n",
      "    Cross References: ['IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [2]\n",
      "  lemmas: [{'lemma': 'ללבבם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'ללבם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'בלבבם'}\n",
      "    Cross References: ['I']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'עליהם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'להם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'איסירם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '89', '')]\n",
      "    Reading: {'Reading': 'איסרם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'אייסרם'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '96', 'sm')]\n",
      "    Reading: {'Reading': 'אייסירים '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'אסירים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7]\n",
      "  lemmas: [{'lemma': 'נדמֶה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', '')]\n",
      "    Reading: {'Reading': 'נדמָה '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'אפרים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'ואסרם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'יאשרם.. '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', ' ')]\n",
      "    Reading: {'Sigla': '..', 'Reading': 'על'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'רֻחמה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'לח..'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'והצגתיה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'כיום ערומה והצגתיה '}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [4]\n",
      "  lemmas: [{'lemma': 'דברו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Reading': 'דברים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7, 8]\n",
      "  lemmas: {'from': [{'lemma': 'ילכו'}, {'lemma': 'ינקותיו'}], 'to': [{'lemma': 'כיין'}, {'lemma': 'לבנון'}]}\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'כי', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'לא ', 'Comment': '(non voc)'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'וכְמריו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', None), ('G-B Msr ', '34', '')]\n",
      "    Reading: {'Reading': 'כֹ'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'בָשנה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '', None), ('G-B Msr ', '34', '')]\n",
      "    Reading: {'Reading': 'בָשְנָה ל ומדׄ מיש ביה בֹשְנָה'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עינתם', 'k': True}, {'lemma': 'עונֹתם', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '89', None), ('G-B Eb ', '16', '')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', ''), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'עונותם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'לה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'non voc'), ('', '96', ''), ('', '150', 'non voc')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'את'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#old processing that doesnt include chapter extraction\n",
    "def post_process_witnesses(witnesses):\n",
    "    # Define the set of specific values for \"x\"\n",
    "    specific_values = {\"G-B Eb \", \"G-B Kb \", \"G-B Msr \"}  # Replace with the actual values\n",
    "\n",
    "    # Iterate over the witnesses, except for the last one\n",
    "    for i in range(len(witnesses) - 1):\n",
    "        z, y, x = witnesses[i]\n",
    "\n",
    "        # Check if \"x\" is one of the specific values\n",
    "        if x in specific_values:\n",
    "            # Remove \"x\" from the current tuple and prepend it to the \"z\" of the next witness\n",
    "            witnesses[i] = (z, y, None)\n",
    "            next_z, next_y, next_x = witnesses[i + 1]\n",
    "            witnesses[i + 1] = (x + next_z, next_y, next_x)\n",
    "\n",
    "    # Remove the first tuple if it becomes empty\n",
    "    if witnesses and witnesses[0] == (None, None, None):\n",
    "        witnesses.pop(0)\n",
    "\n",
    "    return witnesses\n",
    "\n",
    "# Example usage\n",
    "def compile_and_display_entries(entries):\n",
    "    previous_verse = None\n",
    "    compiled_results = []\n",
    "\n",
    "    for entry in entries:\n",
    "        lemma_dict, decoded_entries, used_verse = process_full_entry(entry, previous_verse)\n",
    "        previous_verse = used_verse\n",
    "\n",
    "        # Combine the lemma_dict and decoded_entries for display\n",
    "        entry_result = {\n",
    "            'Lemma': lemma_dict,\n",
    "            'Decoded Entries': decoded_entries\n",
    "        }\n",
    "        compiled_results.append(entry_result)\n",
    "\n",
    "    # Display the results in a structured format\n",
    "    for result in compiled_results:\n",
    "        print(\"Lemma:\")\n",
    "        for key, value in result['Lemma'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Decoded Entries:\")\n",
    "        last_witness_second_group = None\n",
    "        for i, decoded_entries_list in enumerate(result['Decoded Entries']):\n",
    "            for j, decoded_entry in enumerate(decoded_entries_list):\n",
    "                variant_type = \"Variant\" if j == 0 else \"Related Variant\"\n",
    "                print(f\"  {variant_type}:\")\n",
    "                for item in decoded_entry:\n",
    "                    if isinstance(item, dict) and 'Witnesses' in item:\n",
    "                        # Update witnesses with last non-empty second group if needed\n",
    "                        updated_witnesses = []\n",
    "                        for witness in item['Witnesses']:\n",
    "                            if witness[1] == '' and last_witness_second_group:\n",
    "                                updated_witnesses.append((witness[0], last_witness_second_group, witness[2]))\n",
    "                            else:\n",
    "                                updated_witnesses.append(witness)\n",
    "                                if witness[1]:\n",
    "                                    last_witness_second_group = witness[1]\n",
    "                        # Apply post-processing to witnesses\n",
    "                        item['Witnesses'] = post_process_witnesses(updated_witnesses)\n",
    "                    if isinstance(item, dict):\n",
    "                        for key, value in item.items():\n",
    "                            print(f\"    {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"    {item}\")\n",
    "        print(\"-\" * 50)  # Separator line\n",
    "    return compiled_results\n",
    "# Example usage\n",
    "test = compile_and_display_entries(full_entries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
