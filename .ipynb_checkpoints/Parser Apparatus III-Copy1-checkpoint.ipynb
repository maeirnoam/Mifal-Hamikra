{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558de29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import unicodedata\n",
    "from docx import Document\n",
    "from lxml import etree\n",
    "import os\n",
    "from win32com import client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98ff417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted successfully and saved as 'output3.txt'\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_docx(doc_path):\n",
    "    word = client.Dispatch(\"Word.Application\")\n",
    "    absolute_doc_path = os.path.abspath(doc_path)\n",
    "    doc = word.Documents.Open(absolute_doc_path)\n",
    "    doc_path_new = absolute_doc_path.replace(\".doc\", \".docx\")\n",
    "    doc.SaveAs2(doc_path_new, FileFormat=16)  # FileFormat=16 is for docx\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return doc_path_new\n",
    "\n",
    "# Example Usage\n",
    "docx_path = convert_doc_to_docx('Hosea.2.doc')\n",
    "\n",
    "def convert_docx_to_txt(docx_file_path, txt_file_path):\n",
    "    # Load the .docx file\n",
    "    doc = Document(docx_file_path)\n",
    "\n",
    "    # Extract text from each paragraph in the document\n",
    "    text_content = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "    # Write the extracted text to a .txt file\n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text_content)\n",
    "\n",
    "    print(f\"File converted successfully and saved as '{txt_file_path}'\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "convert_docx_to_txt('Hosea.2.docx', 'output3.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c96e775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffApp III: Hosea\\n',\n",
       " '\\n',\n",
       " 'Chapter 1\\n',\n",
       " '1 עזיה] 30 עזיהו\\n',\n",
       " 'יחזקיה] 30 93 (pm) 96 יחזקיהו\\n',\n",
       " 'ירבעם בן] 30 + נבט (non voc)\\n',\n",
       " '2 בהושע] 93 (pm) ביהושעIV (similarly PesiqtaR 33 (153b))\\n',\n",
       " '3 ותלד] 150 (pm) + בן\\n',\n",
       " ' לו] 96 >I  II IV\\n',\n",
       " '4 ופקדתי] 30 + על (non voc)\\n',\n",
       " 'ממלכוּת] 96 ממלכוֹת\\n',\n",
       " '5 את] 30 >\\n',\n",
       " 'יזרעאל] 150 ישראל (parall; but 150-Tg: יזרעאל)\\n',\n",
       " '6 עוד1] 30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\\n',\n",
       " 'כי] 93 (pm) + את\\n',\n",
       " 'אוסיף] 150 (pm) >\\n',\n",
       " 'את] 93 (pm) >\\n',\n",
       " '7 והושעתים] 93 (pm) והושעתם\\n',\n",
       " 'בסוסים] 96 ובסוסיםI IV\\n',\n",
       " '8 רֻחמה] 30 לח..\\n',\n",
       " '9 ואנכי] 150 (pm) אנכי | 93 ואני\\n',\n",
       " '\\n',\n",
       " 'Chapter 2\\n',\n",
       " '1 אשר1] 150 + יאמר (non voc)\\n',\n",
       " 'אשר2] 96 + לא\\n',\n",
       " '2 להם] 30 (pm) לכם\\n',\n",
       " 'אחד] 30 (pm) 150 (pm) >\\n',\n",
       " '4 ונאפופיה] 150 (pm) ונאפו\\n',\n",
       " '5 ערֻמה] 96 ערוֹמה \\n',\n",
       " 'והצגתיה] 93 (pm) + כיום ערומה והצגתיה \\n',\n",
       " 'ושתִּה] 150 (pm) ושמתיה\\n',\n",
       " '7 אלכה] 30 + ואשיבה אל איש (non voc)\\n',\n",
       " '8 שָׂך] 30 (pm) 93 (pm) 150 (pm) סךII IV (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\\n',\n",
       " '10 לה] 93 (non voc) 96 150 (non voc) + את\\n',\n",
       " 'כי] 150 (non voc) + כי\\n',\n",
       " '11 אשוב] 93 (pm) >IV\\n',\n",
       " '13 וכל] 150 (pm) כל\\n',\n",
       " '14 והשִׁמתי] 150 (pm) והשבתי \\n',\n",
       " '15 ותַעַד] G-B Eb 94 ותָעָד (understood as \\\\עוד (rather than \\\\עדי))\\n',\n",
       " 'שכְחה] 150 (pm) שכחת \\n',\n",
       " '16 אנכי] 30 (pm) > \\n',\n",
       " 'מפתיה] 89 מְפַּתֶיהָ\\n',\n",
       " 'המדבר] 96 המדברה (similarly SifreDeut 313 (356:6), RuthR 5:6)\\n',\n",
       " '18 יהוה] 150 + צבאות (non voc)\\n',\n",
       " 'תקראי1] 150 (pm) תקראו | 30 + לי (non voc)I II\\n',\n",
       " 'לי] G-B Eb 54 (pm) >II\\n',\n",
       " 'עוד] 30 (pm?) > \\n',\n",
       " '20 להם] 150 (pm) אלהם\\n',\n",
       " '21 וארשתיך לי לעולם] 93 (pm) > \\n',\n",
       " '22 וידעת] 150 (pm) וידעתם | 30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\\n',\n",
       " 'את] 30 89 (sm) 93 (pm) אניI II IV\\n',\n",
       " '23 והם] 30 (sm) והמה\\n',\n",
       " '\\n',\n",
       " 'Chapter 3\\n',\n",
       " '1 עוד] 150 (pm) >\\n',\n",
       " '3 ואמר] 30 (pm) ואמרה | 150 (pm) ויאמר\\n',\n",
       " 'לא] 96 ולאI\\n',\n",
       " 'תזני] 93 (pm) תתי (Caused by ligature ז+נ)\\n',\n",
       " 'אליך] 93 (pm) אלהיך\\n',\n",
       " '4 ואין3,2] 150 (pm) איןIV\\n',\n",
       " '5 אחר] 150 (pm) ואחרI II\\n',\n",
       " '\\n',\n",
       " 'Chapter 4\\n',\n",
       " '2 ודמים] 96 150 (pm) דמיםII\\n',\n",
       " '3 יושב] 30 (sm) 93 (pm) ישבי | 96 (pm) יושביI II IV\\n',\n",
       " 'וגם] 30 (pm) וכל\\n',\n",
       " '4 כמריבי] 150 (pm) כמריבת \\n',\n",
       " '6 הדעת1] 93 (pm) 150 (pm) דעתII\\n',\n",
       " 'אתה] 96 (pm) את\\n',\n",
       " 'k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\\n',\n",
       " 'ותשכח] 150 (pm) תשכחי\\n',\n",
       " '8 ישאו] 150 (pm) >\\n',\n",
       " 'נפשו] 89 (pm) 96 (pm) 150 (pm) נפשםI IV\\n',\n",
       " '9 ופקדתי] 93 (pm) ופקדתיו\\n',\n",
       " 'עליו] 96 + ודמו (non voc)\\n',\n",
       " 'דרכיו] 30 (pm) כדרכיו\\n',\n",
       " '10 ואכלו] 93 (sm) אכלוII\\n',\n",
       " 'הזנו] 150 (pm) והזנו\\n',\n",
       " 'כי] 96 >\\n',\n",
       " '11 ויין] 30 (pm) 89 (pm) 93 (pm) 96 150 ייןII\\n',\n",
       " '13 יקטרו] 150 (pm) יקטרון\\n',\n",
       " 'צלה] 93 (pm) יגלה \\n',\n",
       " 'וכלותיכם] 150 (pm) + כי \\n',\n",
       " '14 תנאפנה] 96 (pm) תנאפינה (similarly m. Soṭams 9:9, b. Soṭaed 47a, 47b)\\n',\n",
       " 'הזֹנות] 93 (pm) זנות\\n',\n",
       " 'יְפָרדו] 93 96 יִפָּרדו\\n',\n",
       " '15 יהודה] 93 (pm) יהוה\\n',\n",
       " 'ואל1] 150 (pm) אלI IV\\n',\n",
       " 'ואַל3] 30 ואֵל\\n',\n",
       " '16 ככבש] 89 (sm) בכבש \\n',\n",
       " '18 סבאם] 93 סבאים\\n',\n",
       " 'אהבו] 93 (pm) אתם\\n',\n",
       " 'קלון] 150 (pm) קלו\\n',\n",
       " 'מגניה] 96 (pm) מקלון\\n',\n",
       " '19 בכנפיה] 93 (pm) בכנפה | 150 (pm) בכפניה | 93 (pm) + ויזבחו\\n',\n",
       " 'מִזִּבְחותם] 30 93 150 מִזְבְּחתםI IV | 96 מִזְבְחותם\\n',\n",
       " '\\n',\n",
       " 'Chapter 5\\n',\n",
       " '1 פרושה] 93 (pm) פרוסה | 150 (pm) פרוטה\\n',\n",
       " '2 מוסר] 96 (pm) + העמקי\\n',\n",
       " '4 לא1] 30 (sm) ולאI IV\\n',\n",
       " 'אל] 93 (pm) + אלI IV \\n',\n",
       " 'בקרבם] 96 (pm) בקרבכם\\n',\n",
       " '5 וישראל] 150 (pm) ישראל\\n',\n",
       " 'עמם] 93 (pm) עמכם\\n',\n",
       " '6 ובבקרם] 93 (pm) ובקרם\\n',\n",
       " 'את] 93 + דבר (non voc)II IV\\n',\n",
       " '7 זרים] 93 (pm) > \\n',\n",
       " 'עתה] 93 (pm) ועתה\\n',\n",
       " 'את] 30 (pm) >\\n',\n",
       " '8 חצצרה] 96 (pm) חצצריה\\n',\n",
       " 'בית] 150 בין (similarly b. R.HaŠanams 32b)\\n',\n",
       " 'אחריך] 93 (pm) >\\n',\n",
       " '10 כמסיגי] 30 93 150 (pm?) כמשיגיIV \\n',\n",
       " 'גבול] 93 + עולם (non voc) (cf גבול עולם Prov 2228 2310)\\n',\n",
       " '11 אחרי] 96 (pm) > \\n',\n",
       " '12 לאפרים] 93 (pm) אפרים\\n',\n",
       " 'וְכָרקב] 93 96 וּכְרקב\\n',\n",
       " '13 מזֹרו] 93 (pm) מרזרו\\n',\n",
       " 'וישלח] 93 מ..\\n',\n",
       " '14 אשא] 30 (sm) 89 (pm) 93 96 (pm) 150 ואשאI IV\\n',\n",
       " '15 אשובה] 30 93 96 150 (pm) ואשובהI II IV\\n',\n",
       " '\\n',\n",
       " 'Chapter 6\\n',\n",
       " '2 יחינו] 30 (pm?) >\\n',\n",
       " 'מיֹמים] 30 (pm?) >\\n',\n",
       " '3 כַגֶּשם] 93 96 כְגֶשם\\n',\n",
       " 'כמלקוש] 150 (pm) ומלקושI II IV\\n',\n",
       " '4 לְךָ1] 96 לָךְ | 30 (pm) + יהודה \\n',\n",
       " 'מה2] 30 93 150 (pm) ומהI\\n',\n",
       " 'לְךָ2] 96 לָךְ | 30 (pm) + אפרים \\n',\n",
       " 'וחסדכם] 93 150 חסדכםI\\n',\n",
       " 'הֹלך] 96 והולךI\\n',\n",
       " '7 ברית] 96 (pm) כי (?)\\n',\n",
       " '8 מדם] 93 (pm) משם\\n',\n",
       " '9 וכחכי] 150 וכחכה (similarly GenRmss 80:2 (953:4))\\n',\n",
       " 'חבר] 93 (pm) וחבר\\n',\n",
       " '10 k שעריריה / q שערוריה] 30 (pm) 89 (pm) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) שערורהIV\\n',\n",
       " 'שׁם] 96 שׂם\\n',\n",
       " '11 לך] 93 (sm) להּ\\n',\n",
       " '\\n',\n",
       " 'Chapter 7\\n',\n",
       " '1 פעלו] 150 (pm) פעלי\\n',\n",
       " 'וגנב] 30 וכגנב\\n',\n",
       " 'פשט] 93 (pm) ופשטI (similarly S.Eli.R 22 (125))\\n',\n",
       " 'בחוץ] 96 (pm) בחרץ\\n',\n",
       " '2 ללבבם] 96 (pm) ללבם | 30 93 150 (pm) בלבבםI\\n',\n",
       " '4 כמו] 89 (pm) >\\n',\n",
       " 'מעיר] 96 (sm) עיר\\n',\n",
       " 'מלוש] 150 (pm) בלוש\\n',\n",
       " '5 מלכֵּנו] 30 93 (pm) 150 (pm) מלכינוI II IV\\n',\n",
       " 'שרים] 30 (pm) >\\n',\n",
       " 'ידו את] 30 ~\\n',\n",
       " '6 כַתנור] 96 כְתנור\\n',\n",
       " 'אֹפֵהֶם] 93 (pm) אפריםI\\n',\n",
       " '7 אין] 30 (sm) 93 150 ואיןI II IV\\n',\n",
       " '8 אפרים] 93 (pm) + הוא\\n',\n",
       " '9 גם] 150 (pm) וגם\\n',\n",
       " '11 אין] 93 (pm) ואין\\n',\n",
       " 'לב] 89 (pm) לבי\\n',\n",
       " '12 עליהם] 96 (pm) להם\\n',\n",
       " 'איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\\n',\n",
       " '13 ממני] 93 (pm) ממנו\\n',\n",
       " 'פשעוּ] 96 פשעִי\\n',\n",
       " 'ואנכי] 150 (pm) ואניIV\\n',\n",
       " 'דברו] 93 (pm) >\\n',\n",
       " '14 זעקו] 30 (pm) יזעקו | 150 (pm) >\\n',\n",
       " 'בלבם] 93 (pm) בלבבםIV\\n',\n",
       " 'יתגוררו] 93 (pm) >\\n',\n",
       " '15 יְחַשְּׁבו] 96 יַחְשְׁבו\\n',\n",
       " '16 לא] 93 (pm) 150 (pm) לו\\n',\n",
       " 'על היו] 150 (pm) ~\\n',\n",
       " 'זוֹ] 96 זוּ\\n',\n",
       " '\\n',\n",
       " 'Chapter 8\\n',\n",
       " '1 בית] 150 (pm) + על\\n',\n",
       " 'עברו] 96 (pm) עבר\\n',\n",
       " 'תורָתי] 89 (pm) תורֹתי\\n',\n",
       " '2 ישראל] 96 (pm) >\\n',\n",
       " '5 עגלך] 93 עגליךI\\n',\n",
       " '6 שבבים] 150 (pm) שבבוםIV\\n',\n",
       " '8 חפץ] 150 (pm) >\\n',\n",
       " 'בו] 96 בֹה\\n',\n",
       " '10 אקבצם] 93 (pm) קבצם\\n',\n",
       " 'שרים] 96 150 ושריםI II IV\\n',\n",
       " '11 כי] 89 (pm) >\\n',\n",
       " 'אפרים] 30 (pm) ישראל\\n',\n",
       " 'לו] 93 (pm) לי\\n',\n",
       " '12 k אכתוב / q אכתב] 93 96 150 (sm) k, 30 89 150 (pm) q\\n',\n",
       " 'k רבו / q רבי] 30 89 93 96 q, 150 (pm) רובו\\n',\n",
       " '13 וַיֹּאכלו] 30 89 93 96 וְיֹאכלו\\n',\n",
       " 'יהוה] 150 (pm) ויהוהI IV\\n',\n",
       " 'עתה] 150 (pm) ועתה\\n',\n",
       " 'חטֹאותם] 89 93 96 150 (pm) חטאתם, 30 חטָאתם\\n',\n",
       " 'המה] 150 (pm) והמהIV\\n',\n",
       " '14 ויבן] 93 א..\\n',\n",
       " 'הרבה] 30 (pm) + מזבחות\\n',\n",
       " 'ואכלה] 150 (pm) + כל\\n',\n",
       " 'ארמנתיה] 93 (pm) ארמנותיו\\n',\n",
       " '\\n',\n",
       " 'Chapter 9\\n',\n",
       " '2 בהּ] 30 (pm) 93 96 בםI IV\\n',\n",
       " '4 יטמאו] 93 (pm) יטמא\\n',\n",
       " 'בית] 93 (pm) >\\n',\n",
       " '5 יהוה] 150 (pm) ליהוה\\n',\n",
       " '6 תְקַברם] 30 93 תִקְברם\\n',\n",
       " 'לכספם] 150 לנפשם\\n',\n",
       " '7 ישראל] 96 (pm) לישראל\\n',\n",
       " 'אויל] 96 (pm) >\\n',\n",
       " 'רֹב] 96 רַב\\n',\n",
       " 'עונְךָ] 96 עונֵךְ\\n',\n",
       " 'ורבה] 150 (pm) רבהIV\\n',\n",
       " '8 אלהי] 150 (pm) אלהיו\\n',\n",
       " 'נביא] 96 (pm) הנביא\\n',\n",
       " 'יקוֹש] 93 96 יקוּש\\n',\n",
       " '9 יפקוד] 30 93 150 וְיפקד, 96 וְיפקודI IV\\n',\n",
       " 'חטאותם] 89 93 150 (pm) חטֹאתם, 30 חטָאתם\\n',\n",
       " '10 במדבר] 96 (pm) במדברה\\n',\n",
       " 'וַינזרו] 30 וְינזרו\\n',\n",
       " 'ויהיו] 96 (pm) ויהי\\n',\n",
       " '11 ומבטן] 30 מבטןIV\\n',\n",
       " '13 ואפרים] 89 (pm) 96 150 (pm) אפרים\\n',\n",
       " '14 תתן] 30 (pm) + להםI\\n',\n",
       " 'רחם] 96 (pm) מרחם\\n',\n",
       " '15 כי] 96 >\\n',\n",
       " 'מביתי] 93 (pm) מביתIV\\n',\n",
       " '16 k בלי / q בל] 150 (sm) k, 30 89 93 96 150 (pm) q\\n',\n",
       " 'ילדון] 93 (pm) ילזון\\n',\n",
       " '17 אלהי] 93 (pm) אלהו (?)\\n',\n",
       " 'לו] 150 >\\n',\n",
       " '\\n',\n",
       " 'Chapter 10\\n',\n",
       " '1 כרב לפריו הרבה למזבחות] 150 (pm) >\\n',\n",
       " 'למזבחות] 93 (pm) למזבח\\n',\n",
       " '2 ישֹׁדד] 96 (pm) ישוד | 150 (pm) וישבר\\n',\n",
       " '3 כי1] 150 + לא (non voc)\\n',\n",
       " 'יָרֵאנו] 30 יַרְאֵנו\\n',\n",
       " '4 דברו] 150 ..דברים\\n',\n",
       " 'כרֹת] 96 (pm) וכרותI\\n',\n",
       " 'ופרח] 150 (pm) ופתח\\n',\n",
       " '5 שמרון] 30 שמרין (?) \\n',\n",
       " 'וכְמריו] G-B Msr 34 כֹ\\n',\n",
       " 'יגילו] 150 (sm) יגלו \\n',\n",
       " 'על] 93 (pm) ועל\\n',\n",
       " 'ממנו] 96 (pm) ממני\\n',\n",
       " '6 בָשנה] G-B Msr 34 בָשְנָה ל ומדׄ מיש ביה בֹשְנָה\\n',\n",
       " '7 נדמֶה] 93 נדמָה | 30 (pm) + אפרים\\n',\n",
       " 'מלכהּ] 93 (pm) מלכם\\n',\n",
       " 'מים] 93 (pm) המים\\n',\n",
       " '8 ודרדר] G-B Eb 16 ודר דר \\n',\n",
       " 'כַּסונו] 89 כִּסונו (?)\\n',\n",
       " '9 מימי] 30 (pm) ממי\\n',\n",
       " 'חטאתָ] 93 (sm) 96 (sm) חטא (ת non voc)\\n',\n",
       " 'עלוה] 89 (sm) עולהI\\n',\n",
       " '10 ואסרם] 96 (pm) יאשרם | 150 ..על\\n',\n",
       " 'k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\\n',\n",
       " '12 קצרו] 30 96 (pm) 150 (pm) וקצרוI II IV\\n',\n",
       " 'ועת] 150 (pm) עת\\n',\n",
       " 'לדרוש] 96 >\\n',\n",
       " 'את] 30 (pm) >, 96 (non voc)\\n',\n",
       " 'יהוה] 93 (pm) יהודה\\n',\n",
       " 'ויֹרה] 93 (pm) G-B Eb 16 יורה\\n',\n",
       " '13 בדרכְּך] 96 150 (pm) בדרכיךI IV \\n',\n",
       " '14 וכל] 150 (pm) כל\\n',\n",
       " 'שלמן] 96 שלומך\\n',\n",
       " 'ארבֵאל] 93 ארבְּאֵל\\n',\n",
       " '15 בית-אל] 96 ביתְאלIV\\n',\n",
       " '\\n',\n",
       " 'Chapter 11\\n',\n",
       " '2 יזבחו] 150 (pm) יזבחון\\n',\n",
       " 'ולפסִלים] 96 לפסילים\\n',\n",
       " '3 זרועֹתיו] 96 (sm) זרועותיI II\\n',\n",
       " 'רפאתים] 96 (pm) רפאתיו\\n',\n",
       " '4 להם] 150 (pm) לה\\n',\n",
       " 'לחֵיהם] 30 93 לחָיֵיהם\\n',\n",
       " '6 וכִלתה] 96 וכָלתהI\\n',\n",
       " 'ממֹעצותיהם] 96 (pm) ממעֲוצותיהם\\n',\n",
       " '7 תלואִים] G-B Ea 12 תלואיִם\\n',\n",
       " 'למשובתי] 30 (pm) למשבתוI\\n',\n",
       " '8 כצבאיִם] 89 כצבאִים, 150 כצבוים\\n',\n",
       " '9 לא2] 30 (pm) 150 (pm) ולאII IV\\n',\n",
       " 'ולא2] 93 (sm) 150 (pm) לאII IV\\n',\n",
       " '11 וּכְיונה] 93 וְכַיונה\\n',\n",
       " '\\n',\n",
       " 'Chapter 12\\n',\n",
       " '1 רד] 96 (sm) >\\n',\n",
       " '2 כזב] 150 (pm) חמס\\n',\n",
       " 'ושֹׁד] 93 (pm) > \\n',\n",
       " 'וברית] 96 (pm) ובריית\\n',\n",
       " '3 כמעלליו] 150 (pm) וכמעלליוI II\\n',\n",
       " 'ישיב] 30 (pm) 150 (pm) אשיבI\\n',\n",
       " '4 שׂרה] 150 (pm) סרה\\n',\n",
       " '5 ימצאֶנו] 93 (pm) ימצאונוI\\n',\n",
       " '7 שמֹר] 30 שמו\\n',\n",
       " '10 כימי] 30 (pm) כיוםI\\n',\n",
       " '11 הרביתי] 150 (pm) + על הנביאים ואנכי חזון הרבתי (non voc)\\n',\n",
       " '12 גלעד און] 93 ~\\n',\n",
       " 'בגלגל] 150 (pm) ובגלגל\\n',\n",
       " 'זבחו] 93 (pm) > \\n',\n",
       " 'גם מזבחותם] 96 >\\n',\n",
       " '\\n',\n",
       " 'Chapter 13\\n',\n",
       " '2 כלֹה] 150 (pm) כלם (similarly PesiqtaRKms 24:10 (357:10))\\n',\n",
       " '3 הֹלך] 96 (pm) והולך\\n',\n",
       " '4 אין] 30 (pm) + אין\\n',\n",
       " '6 כן]  150 (pm) >\\n',\n",
       " '7 כנמר] 93 (pm) וכנמרI\\n',\n",
       " '8 חית] 93 150 (pm) וחיתI\\n',\n",
       " '9 בי] 150 (pm) >\\n',\n",
       " '10 אפוא] 30 איפֹה\\n',\n",
       " 'ויושיעֲך] 96 (pm) ויושיעוך\\n',\n",
       " 'לי] 96 לנו\\n',\n",
       " '13 לו] 93 (pm?) 96 לָךְ\\n',\n",
       " 'הוא] 93 (pm) 150 (pm) והואIV\\n',\n",
       " 'לא1] 93 ולא\\n',\n",
       " '14 ממות] 30 89 (sm) 93 (pm) 96 150 (pm) וממותI II\\n',\n",
       " 'דבריך] 30 93 (pm) 96 דברךI II IV\\n',\n",
       " 'נֹחם] G-B Msr 34 נַחֵם (taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)\\n',\n",
       " '15 בין] 93 (pm) בןI II IV\\n',\n",
       " 'ויבוש] 93 (pm) תיבש\\n',\n",
       " 'הוא2] 93 (pm) 96 150 (pm) והואI II\\n',\n",
       " '\\n',\n",
       " 'Chapter 14\\n',\n",
       " '1 עלליהם] 93 150 (pm) ועולליהםI\\n',\n",
       " '3 ושובו] 150 (pm) ושֻׁבו\\n',\n",
       " 'אמרו] 30 (pm) 93 (pm) 96 150 (pm) ואמרוII IV\\n',\n",
       " 'כל] 89 (pm) בלI\\n',\n",
       " '4 על] 93 (pm) 96 150 (pm) ועלIV\\n',\n",
       " '5 ממנו] G-B Msr 34 k ממני / q ממנוIV\\n',\n",
       " '6 יפרח] 150 (pm) ויפרח\\n',\n",
       " '7–8 ילכו ינקותיו – כיין לבנון] 30 > \\n',\n",
       " '8 כגפן] 93 כד..\\n',\n",
       " '9 אני1] 93 + אני\\n',\n",
       " '10 חכָם] 93 חכֵם (!)\\n',\n",
       " 'וצדקים] 96 צדיקים\\n',\n",
       " '\\u200fApp III: Hosea\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '1\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('01 Hosea App III - מתוקן.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    txt = file\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## render apparatus 3 ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new logic\n",
    "#1. split into lemma and app_entry. process each separately\n",
    "# lemma: split into number range and lemma range. \n",
    "#numbers include \\d+'-', lemmas need to include potential k\\q attribute, and word number.\n",
    "# app_entry: splits into mss., reading, comments, cross-reference.\n",
    "# \n",
    "#to do: \n",
    "#1. get_verse, if verse is empty. same for get_witness (if its inside a comma)\n",
    "#2. QA: \"איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\" (when split on comma allow for witness completion)\n",
    "# maybe run a post_processing function that will add .. if needed to the sigla, and the verse and witness if their missing.\n",
    "# get chapter of verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "811ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_entries = [\n",
    "    \"8 k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\",\n",
    "    \"8 שָׂך] 30 (pm) 93 (pm) 150 (pm) סךII IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))\",\n",
    "    \"6 עוד1] 30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\",\n",
    "    \"6 הדעת1] 93 (pm) 150 (pm) דעתII\",\n",
    "    \"14 זעקו] 30 (pm) יזעקו | 150 (pm) >\",\n",
    "    \"10 k שעריריה / q שערוריה] 30 (pm) 89 (pm) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) שערורהIV\",\n",
    "    \"2 ללבבם] 96 (pm) ללבם | 30 93 150 (pm) בלבבםI\",\n",
    "    \"12 עליהם] 96 (pm) להם\",\n",
    "    \"איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\",\n",
    "    \"7 נדמֶה] 93 נדמָה | 30 (pm) + אפרים\",\n",
    "    \"10 ואסרם] 96 (pm) יאשרם.. | 150  ..על\",\n",
    "    \"8 רֻחמה] 30 לח..\",\n",
    "    \"והצגתיה] 93 (pm) + כיום ערומה והצגתיה \",\n",
    "    \"4 דברו] 150 דברים\",\n",
    "    \"7–8 ילכו ינקותיו – כיין לבנון] 30 > \",\n",
    "    \"3 כי1] 150 + לא (non voc)\",\n",
    "    \"וכְמריו] 93 G-B Msr 34 כֹ\",\n",
    "    \"6 בָשנה] G-B Msr 34 בָשְנָה ל ומדׄ מיש ביה בֹשְנָה\",\n",
    "    \"k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\",\n",
    "    \"10 לה] 93 (non voc) 96 150 (non voc) + את\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9c2fbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[process_full_entry(example) for example in full_entries]#[-6]#[0]['verses']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99b04929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'ואמאסאך', 'k': True}, {'lemma': 'ואמאסך', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q  '}\n",
      "    Cross References: ['IV']\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'אמסך'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'שָׂך'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'סך  ', 'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}\n",
      "    Cross References: ['II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עוד', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'}\n",
      "    Cross References: ['I', 'II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'הדעת', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'דעת'}\n",
      "    Cross References: ['II']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [14]\n",
      "  lemmas: [{'lemma': 'זעקו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Reading': 'יזעקו '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'שעריריה', 'k': True}, {'lemma': 'שערוריה', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '89', 'pm'), ('', '150', 'sm')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'שערורה'}\n",
      "    Cross References: ['IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [2]\n",
      "  lemmas: [{'lemma': 'ללבבם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'ללבם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'בלבבם'}\n",
      "    Cross References: ['I']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'עליהם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'להם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'איסירם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '89', '')]\n",
      "    Reading: {'Reading': 'איסרם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'אייסרם'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '96', 'sm')]\n",
      "    Reading: {'Reading': 'אייסירים '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'אסירים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7]\n",
      "  lemmas: [{'lemma': 'נדמֶה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', '')]\n",
      "    Reading: {'Reading': 'נדמָה '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'אפרים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'ואסרם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'יאשרם.. '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', ' ')]\n",
      "    Reading: {'Sigla': '..', 'Reading': 'על'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'רֻחמה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'לח..'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'והצגתיה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'כיום ערומה והצגתיה '}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [4]\n",
      "  lemmas: [{'lemma': 'דברו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Reading': 'דברים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7, 8]\n",
      "  lemmas: {'from': [{'lemma': 'ילכו'}, {'lemma': 'ינקותיו'}], 'to': [{'lemma': 'כיין'}, {'lemma': 'לבנון'}]}\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'כי', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'לא ', 'Comment': '(non voc)'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'וכְמריו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'G-B Msr '), ('', '34', '')]\n",
      "    Reading: {'Reading': 'כֹ'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'בָשנה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '', 'G-B Msr '), ('', '34', '')]\n",
      "    Reading: {'Reading': 'בָשְנָה ל ומדׄ מיש ביה בֹשְנָה'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עינתם', 'k': True}, {'lemma': 'עונֹתם', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '89', 'G-B Eb '), ('', '16', '')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', ''), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'עונותם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'לה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'non voc'), ('', '96', ''), ('', '150', 'non voc')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'את'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# this will be changed into a build rather than display.\n",
    "def compile_and_display_entries(entries):\n",
    "    previous_verse = None\n",
    "    compiled_results = []\n",
    "\n",
    "    for entry in entries:\n",
    "        lemma_dict, decoded_entries, used_verse = process_full_entry(entry, previous_verse)\n",
    "        previous_verse = used_verse\n",
    "\n",
    "        # Combine the lemma_dict and decoded_entries for display\n",
    "        entry_result = {\n",
    "            'Lemma': lemma_dict,\n",
    "            'Decoded Entries': decoded_entries\n",
    "        }\n",
    "        compiled_results.append(entry_result)\n",
    "\n",
    "    # Display the results in a structured format\n",
    "    for result in compiled_results:\n",
    "        print(\"Lemma:\")\n",
    "        for key, value in result['Lemma'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Decoded Entries:\")\n",
    "        last_witness_second_group = None\n",
    "        for i, decoded_entries_list in enumerate(result['Decoded Entries']):\n",
    "            for j, decoded_entry in enumerate(decoded_entries_list):\n",
    "                variant_type = \"Variant\" if j == 0 else \"Related Variant\"\n",
    "                print(f\"  {variant_type}:\")\n",
    "                for item in decoded_entry:\n",
    "                    if isinstance(item, dict) and 'Witnesses' in item:\n",
    "                        # Update witnesses with last non-empty second group if needed\n",
    "                        updated_witnesses = []\n",
    "                        for witness in item['Witnesses']:\n",
    "                            if witness[1] == '' and last_witness_second_group:\n",
    "                                updated_witnesses.append((witness[0], last_witness_second_group, witness[2]))\n",
    "                            else:\n",
    "                                updated_witnesses.append(witness)\n",
    "                                if witness[1]:\n",
    "                                    last_witness_second_group = witness[1]\n",
    "                        item['Witnesses'] = updated_witnesses\n",
    "                    if isinstance(item, dict):\n",
    "                        for key, value in item.items():\n",
    "                            print(f\"    {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"    {item}\")\n",
    "        print(\"-\" * 50)  # Separator line\n",
    "\n",
    "# Example usage\n",
    "compile_and_display_entries(full_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5fad16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'ואמאסאך', 'k': True}, {'lemma': 'ואמאסך', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q  '}\n",
      "    Cross References: ['IV']\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'אמסך'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'שָׂך'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'סך  ', 'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}\n",
      "    Cross References: ['II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עוד', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'}\n",
      "    Cross References: ['I', 'II', 'IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'הדעת', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm'), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'דעת'}\n",
      "    Cross References: ['II']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [14]\n",
      "  lemmas: [{'lemma': 'זעקו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Reading': 'יזעקו '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'שעריריה', 'k': True}, {'lemma': 'שערוריה', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm'), ('', '89', 'pm'), ('', '150', 'sm')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Reading': 'שערורה'}\n",
      "    Cross References: ['IV']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [2]\n",
      "  lemmas: [{'lemma': 'ללבבם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'ללבם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '93', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'בלבבם'}\n",
      "    Cross References: ['I']\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'עליהם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'להם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [12]\n",
      "  lemmas: [{'lemma': 'איסירם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', ''), ('', '89', '')]\n",
      "    Reading: {'Reading': 'איסרם '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'אייסרם'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '96', 'sm')]\n",
      "    Reading: {'Reading': 'אייסירים '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'אסירים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7]\n",
      "  lemmas: [{'lemma': 'נדמֶה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', '')]\n",
      "    Reading: {'Reading': 'נדמָה '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'אפרים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'ואסרם'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '96', 'pm')]\n",
      "    Reading: {'Reading': 'יאשרם.. '}\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', ' ')]\n",
      "    Reading: {'Sigla': '..', 'Reading': 'על'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'רֻחמה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'לח..'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [8]\n",
      "  lemmas: [{'lemma': 'והצגתיה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'pm')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'כיום ערומה והצגתיה '}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [4]\n",
      "  lemmas: [{'lemma': 'דברו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Reading': 'דברים'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [7, 8]\n",
      "  lemmas: {'from': [{'lemma': 'ילכו'}, {'lemma': 'ינקותיו'}], 'to': [{'lemma': 'כיין'}, {'lemma': 'לבנון'}]}\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Sigla': '>'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'כי', 'number': '1'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '150', '')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'לא ', 'Comment': '(non voc)'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [3]\n",
      "  lemmas: [{'lemma': 'וכְמריו'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', None), ('G-B Msr ', '34', '')]\n",
      "    Reading: {'Reading': 'כֹ'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'בָשנה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '', None), ('G-B Msr ', '34', '')]\n",
      "    Reading: {'Reading': 'בָשְנָה ל ומדׄ מיש ביה בֹשְנָה'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [6]\n",
      "  lemmas: [{'lemma': 'עינתם', 'k': True}, {'lemma': 'עונֹתם', 'q': True}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '30', '')]\n",
      "    Reading: {'Reading': 'k'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '89', None), ('G-B Eb ', '16', '')]\n",
      "    Reading: {'Reading': 'q'}\n",
      "  Related Variant:\n",
      "    Witnesses: [('', '93', ''), ('', '96', ''), ('', '150', 'pm')]\n",
      "    Reading: {'Reading': 'עונותם'}\n",
      "--------------------------------------------------\n",
      "Lemma:\n",
      "  verses: [10]\n",
      "  lemmas: [{'lemma': 'לה'}]\n",
      "Decoded Entries:\n",
      "  Variant:\n",
      "    Witnesses: [('', '93', 'non voc'), ('', '96', ''), ('', '150', 'non voc')]\n",
      "    Reading: {'Sigla': '+', 'Reading': 'את'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def post_process_witnesses(witnesses):\n",
    "    # Define the set of specific values for \"x\"\n",
    "    specific_values = {\"G-B Eb \", \"G-B Kb \", \"G-B Msr \"}  # Replace with the actual values\n",
    "\n",
    "    # Iterate over the witnesses, except for the last one\n",
    "    for i in range(len(witnesses) - 1):\n",
    "        z, y, x = witnesses[i]\n",
    "\n",
    "        # Check if \"x\" is one of the specific values\n",
    "        if x in specific_values:\n",
    "            # Remove \"x\" from the current tuple and prepend it to the \"z\" of the next witness\n",
    "            witnesses[i] = (z, y, None)\n",
    "            next_z, next_y, next_x = witnesses[i + 1]\n",
    "            witnesses[i + 1] = (x + next_z, next_y, next_x)\n",
    "\n",
    "    # Remove the first tuple if it becomes empty\n",
    "    if witnesses and witnesses[0] == (None, None, None):\n",
    "        witnesses.pop(0)\n",
    "\n",
    "    return witnesses\n",
    "\n",
    "# Example usage\n",
    "def compile_and_display_entries(entries):\n",
    "    previous_verse = None\n",
    "    compiled_results = []\n",
    "\n",
    "    for entry in entries:\n",
    "        lemma_dict, decoded_entries, used_verse = process_full_entry(entry, previous_verse)\n",
    "        previous_verse = used_verse\n",
    "\n",
    "        # Combine the lemma_dict and decoded_entries for display\n",
    "        entry_result = {\n",
    "            'Lemma': lemma_dict,\n",
    "            'Decoded Entries': decoded_entries\n",
    "        }\n",
    "        compiled_results.append(entry_result)\n",
    "\n",
    "    # Display the results in a structured format\n",
    "    for result in compiled_results:\n",
    "        print(\"Lemma:\")\n",
    "        for key, value in result['Lemma'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Decoded Entries:\")\n",
    "        last_witness_second_group = None\n",
    "        for i, decoded_entries_list in enumerate(result['Decoded Entries']):\n",
    "            for j, decoded_entry in enumerate(decoded_entries_list):\n",
    "                variant_type = \"Variant\" if j == 0 else \"Related Variant\"\n",
    "                print(f\"  {variant_type}:\")\n",
    "                for item in decoded_entry:\n",
    "                    if isinstance(item, dict) and 'Witnesses' in item:\n",
    "                        # Update witnesses with last non-empty second group if needed\n",
    "                        updated_witnesses = []\n",
    "                        for witness in item['Witnesses']:\n",
    "                            if witness[1] == '' and last_witness_second_group:\n",
    "                                updated_witnesses.append((witness[0], last_witness_second_group, witness[2]))\n",
    "                            else:\n",
    "                                updated_witnesses.append(witness)\n",
    "                                if witness[1]:\n",
    "                                    last_witness_second_group = witness[1]\n",
    "                        # Apply post-processing to witnesses\n",
    "                        item['Witnesses'] = post_process_witnesses(updated_witnesses)\n",
    "                    if isinstance(item, dict):\n",
    "                        for key, value in item.items():\n",
    "                            print(f\"    {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"    {item}\")\n",
    "        print(\"-\" * 50)  # Separator line\n",
    "\n",
    "# Example usage\n",
    "compile_and_display_entries(full_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadb22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_entry(text, previous_verse=None):\n",
    "    lemma, part_entry = split_full_entry(text)\n",
    "    lemma_dict = lemma_verse_processor(lemma)\n",
    "\n",
    "    # Use the previous verse if the current verse list is empty\n",
    "    if not lemma_dict['verses'] and previous_verse is not None:\n",
    "        lemma_dict['verses'] = previous_verse\n",
    "\n",
    "    # Split part_entry by '|'\n",
    "    if '|' in part_entry:\n",
    "        entry_parts = part_entry.split('|')\n",
    "    else:\n",
    "        entry_parts = [part_entry]\n",
    "\n",
    "    # Initialize a list to hold all processed parts\n",
    "    processed_parts = []\n",
    "\n",
    "    # Process each part separately\n",
    "    for part in entry_parts:\n",
    "        # Split part by ',' not inside parentheses\n",
    "        sub_parts = split_on_comma_not_in_parentheses(part)\n",
    "\n",
    "        # Process each sub-part using process_comma_entry\n",
    "        processed_sub_parts = [process_comma_entry(sub_part) for sub_part in sub_parts]\n",
    "\n",
    "        # Concatenate processed sub-parts for each part\n",
    "        processed_parts.append(processed_sub_parts)\n",
    "\n",
    "    # Combine processed parts. Assuming you want them as a nested list\n",
    "    decoded_entries = processed_parts\n",
    "\n",
    "    # Return the lemma_dict and decoded_entries, along with the verses used for this entry\n",
    "    return lemma_dict, decoded_entries, lemma_dict['verses']\n",
    "\n",
    "def split_on_comma_not_in_parentheses(part):\n",
    "    \"\"\"\n",
    "    Splits the string on ',' not inside parentheses.\n",
    "    \"\"\"\n",
    "    sub_parts = []\n",
    "    current_part = []\n",
    "    paren_depth = 0  # Track depth of parentheses\n",
    "\n",
    "    for char in part:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0:\n",
    "            # At a top-level comma, split here\n",
    "            sub_parts.append(''.join(current_part))\n",
    "            current_part = []\n",
    "            continue\n",
    "\n",
    "        current_part.append(char)\n",
    "\n",
    "    # Add the last part if there's any\n",
    "    if current_part:\n",
    "        sub_parts.append(''.join(current_part))\n",
    "\n",
    "    return sub_parts\n",
    "\n",
    "def split_full_entry(text):\n",
    "    sliced_entry = text.split(sep=']')\n",
    "    lemma, entry = sliced_entry\n",
    "#         print(f\"lemma: {lemma}\")\n",
    "#         print(f\"entry: {entry}\")\n",
    "    return lemma, entry    \n",
    "\n",
    "def lemma_verse_processor(text):\n",
    "    # Simplified approach: first split into digits and lemmas\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    verses = list(map(int, verses_match.group(1).split('–'))) if verses_match else []\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    return {\n",
    "        'verses': verses,\n",
    "        'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "    }\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(k|q)?\\s*([^\\d\\s]+)(\\d?\\,?\\d?)'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "\n",
    "    # Split lemma if there are separate lemmas with \"/\"\n",
    "    split_lemmas = re.split(r'\\s*/\\s*', lemma) if '/' in lemma else [lemma]\n",
    "    \n",
    "    processed_lemmas = []\n",
    "    for split_lemma in split_lemmas:\n",
    "        processed = process_individual_lemma(split_lemma)\n",
    "        processed_lemmas.extend(processed)\n",
    "    \n",
    "    return processed_lemmas\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "    for match in matches:\n",
    "        prefix, word, number = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if prefix: lemma_dict[prefix] = True\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas\n",
    "\n",
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def extract_cross_references(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def parse_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d.]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_comma_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d*)?\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~\\.]*)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]*\\s?)[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def witness_reading_splitter(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>~.]*\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>~])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Reading\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n",
    "\n",
    "def process_comma_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Reading\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over full entries. get verse number from previous if needed. also get reading from lemma. and split on | ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "715948c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process lemma:\n",
    "#split into digits and lemmas. then process each separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "b18607da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'verses': [10], 'lemmas': [{'lemma': 'ואסרם'}]},\n",
       " [[({'Witnesses': [('', '96', 'pm')]},\n",
       "    {'Reading': {'Reading': 'יאשרם '}},\n",
       "    {'Cross References': []})],\n",
       "  [({'Witnesses': [('', '150', '')]},\n",
       "    {'Reading': {'Reading': 'על'}},\n",
       "    {'Cross References': []})]])"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[process_full_entry(example) for example in full_entries][-1]#[0]['verses']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "b8c31720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old function, didnt take the splitting into commas consideration\n",
    "# def process_full_entry(text):\n",
    "#     lemma, part_entry = split_full_entry(text)\n",
    "#     lemma_dict = lemma_verse_processor(lemma)\n",
    "# #     if len(lemma_dict['verses'])==0: #get verse from previous entry\n",
    "# #         lemma_dict['verses'] = \n",
    "        \n",
    "#     #entry_units = split_entry_units # splits on | and ,\n",
    "#     #for entry in entry_units:\n",
    "#     decoded_entry = process_entry(part_entry)\n",
    "#     return lemma_dict, decoded_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "4b9188ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def remove_and_list_roman_numerals(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "    split_entry = split_string(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "        if len(split_entry)==2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else: #there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry)}\n",
    "        reading = ''\n",
    "    return witnesses, {\"Reading\":reading}, {\"Cross References\":cross_references}\n",
    "\n",
    "\n",
    "# for entry in sample_texts:\n",
    "#     print(f\"entry: {entry}\")\n",
    "#     clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "#     split_entry = split_string(clean_entry)\n",
    "#     if type(split_entry) is tuple:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry[0])}\n",
    "#         reading = parse_reading_entry(split_entry[1])\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#         print(f\"reading: {reading}\")\n",
    "#     else:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry)}\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#     print(f\"references: {cross_references}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "cd41862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"96 (non voc)\",\n",
    "    \"30 (pm) 93 (pm) 150 (pm) + סךII IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))\",\n",
    "    \"93 (non voc) 96 150 (non voc) + את\",\n",
    "    \"30 (pm) >\",\n",
    "    \"30 + לי (non voc)I II\",\n",
    "    \"30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\",\n",
    "    \"93 (pm) ביהושעIV (similarly PesiqtaR 33 (153b))\",\n",
    "    \"96 >I II IV\",\n",
    "    \"130 k\",\n",
    "    \"G-B Msr 34 k ממני / q ממנוIV\",\n",
    "    \"93 כד..\",\n",
    "    \"150 ..דברים\",\n",
    "    \"G-B Eb 94 ותָעָד (understood as \\עוד (rather than \\עדי))\",\n",
    "    \"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "a0ae7422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Witnesses': [('', '93', 'pm')]},\n",
       " {'Reading': {'Reading': 'ביהושע ',\n",
       "   'Comment': '(similarly PesiqtaR 33 (153b))'}},\n",
       " {'Cross References': ['IV']})"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_entry(sample_texts[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "2a94af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'}"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_entry, cross_references = remove_and_list_roman_numerals(sample_texts[6])\n",
    "split_entry = split_string(clean_entry)\n",
    "if type(split_entry) is tuple:\n",
    "    witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "    if len(split_entry)==2:\n",
    "        reading = parse_reading_entry(split_entry[1])\n",
    "    else: #there are 3 groups:\n",
    "        reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "\n",
    "reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "08fa1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', '30', 'pm'), ('', '93', ''), ('', '150', 'pm')]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "# \"96 (non voc)\",\n",
    "# \"30 (pm) 93 (pm) 150 (pm)\n",
    "test_witness = \"30 (pm) 93 150 (pm)\"\n",
    "custom_split_string(test_witness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "fbefcdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['96 (non voc)', ('30 (pm) 93 (pm) 150 (pm) ', '+ סך', 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'), ('93 (non voc) 96 150 (non voc) ', '+ את', ''), ('30 (pm) ', '>', ''), ('30 ', '+ לי', ' (non voc)I II'), ('30 (pm) ', '>', 'I II IV (similarly b. Pesaḥim 87bmss)'), ('93 (pm)', ' ביהושע', 'IV (similarly PesiqtaR 33 (153b))'), ('96 ', '>', 'I II IV'), ('130', ' k', ''), ('G-B Msr 34', ' k', ' ממני / q ממנוIV'), ('93', ' כד', '..'), ('150 ..', 'דברים', ''), ('G-B Eb 94', ' ותָעָד', ' (understood as \\\\עוד (rather than \\\\עדי))'), ('30 89 (sm) 93 (pm) 150 (non voc) ', '+ כי', 'I II IV')]\n"
     ]
    }
   ],
   "source": [
    "#try parsing single entry app, splitting into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "processed_sample = [split_string(text) for text in sample_texts]\n",
    "\n",
    "print(processed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "473068c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Reading': 'סך ',\n",
       "  'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'},\n",
       " {'Sigla': '+', 'Reading': 'את'},\n",
       " {'Sigla': '>'},\n",
       " {'Sigla': '+', 'Reading': 'לי ', 'Comment': '(non voc)'},\n",
       " {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'},\n",
       " {'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'},\n",
       " {},\n",
       " {'Reading': 'k'},\n",
       " {'Reading': 'k ממני / q ממנו'},\n",
       " {'Reading': 'כד..'},\n",
       " {'Reading': '..דברים'},\n",
       " {'Reading': 'נַחֵם ',\n",
       "  'Comment': '(taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)'},\n",
       " {'Reading': 'חכֵם ', 'Comment': '(!)'}]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for parsing the reading+comment (assumes witnesses and cross references have been removed)\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "# Process the sample reading texts with the refined function\n",
    "parse_reading_entry = [parse_reading_entry(text) for text in sample_reading_texts]\n",
    "\n",
    "parse_reading_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "94a5de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [{'witnesses': '30 (pm) 93 (pm) 150 (pm)', 'reading': '+ סך', 'comments': 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}], [{'witnesses': '93 (non voc) 96 150 (non voc)', 'reading': '+ את', 'comments': ''}], [], [{'witnesses': '30', 'reading': '+ לי', 'comments': '(non voc)I II'}], [], [{'witnesses': '93 (pm)', 'reading': 'ביהושע', 'comments': 'IV (similarly PesiqtaR 33 (153b))'}], [], [], [{'witnesses': 'G-B Msr 34 k', 'reading': 'ממני', 'comments': '/ q ממנוIV'}], [{'witnesses': '93', 'reading': 'כד', 'comments': '..'}], [{'witnesses': '150 ..', 'reading': 'דברים', 'comments': ''}], [{'witnesses': 'G-B Eb 94', 'reading': 'ותָעָד', 'comments': '(understood as \\\\עוד (rather than \\\\עדי))'}], [{'witnesses': '30 89 (sm) 93 (pm) 150 (non voc)', 'reading': '+ כי', 'comments': 'I II IV'}]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_string_processor(input_string, regex_pattern):\n",
    "    # Helper function to apply regex and extract groups\n",
    "    def apply_regex_and_extract(text):\n",
    "        matches = re.finditer(regex_pattern, text)\n",
    "        results = []\n",
    "        for match in matches:\n",
    "            results.append({\n",
    "                'witnesses': match.group(1).strip(),\n",
    "                'reading': match.group(2).strip(),\n",
    "                'comments': match.group(3).strip() if match.group(3) else ''\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    # Process splits with \"|\", then \",\"\n",
    "    def process_splits(text, delimiter):\n",
    "        parts = text.split(delimiter)\n",
    "        processed_parts = []\n",
    "        for part in parts:\n",
    "            # Apply regex to each part\n",
    "            processed = apply_regex_and_extract(part)\n",
    "            if processed:\n",
    "                processed_parts.extend(processed)\n",
    "        return processed_parts\n",
    "\n",
    "    # Start processing\n",
    "    processed_result = process_splits(input_string, '|')  # Start with the highest level of split\n",
    "\n",
    "    return processed_result\n",
    "\n",
    "# Custom regex pattern as provided\n",
    "custom_regex = r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$'\n",
    "\n",
    "# Test with the provided sample input\n",
    "sample_input = \"G-B msr. 30 (pm) G-A 89 (sm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) + שערורהIV II (bla bla (f)) | 150 >\"\n",
    "processed_sample = [custom_string_processor(text, custom_regex) for text in sample_texts]\n",
    "\n",
    "\n",
    "print(processed_sample)\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "# text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "# split_parts = split_string(text)\n",
    "# if split_parts:\n",
    "#     print(\"witnesses:\", split_parts[0])\n",
    "#     print(\"reading:\", split_parts[1])\n",
    "#     print(\"After dividers:\", split_parts[2])\n",
    "# else:\n",
    "#     print(\"No dividers found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5b4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_apparatus_entry(entry):\n",
    "    \"\"\"Parse an apparatus entry into lemma(s) and content.\"\"\"\n",
    "    parts = entry.split(']')\n",
    "    lemmas_contents = []\n",
    "    for part in parts:\n",
    "        if part.strip():\n",
    "            lemma, content = part.split('[', 1) if '[' in part else (part, '')\n",
    "            lemmas_contents.append((lemma.strip(), content.strip()))\n",
    "    return lemmas_contents\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    \"\"\"Create a TEI document from apparatus lines.\"\"\"\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    NSMAP = {\"tei\": TEI_NAMESPACE}\n",
    "    \n",
    "    tei_root = ET.Element(TEI+\"TEI\", nsmap=NSMAP)\n",
    "    tei_header = ET.SubElement(tei_root, TEI+\"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI+\"text\")\n",
    "    body = ET.SubElement(text, TEI+\"body\")\n",
    "    current_chapter = None\n",
    "    last_verse = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1]\n",
    "            current_chapter = ET.SubElement(body, TEI+\"div\", type=\"chapter\", n=chapter_number)\n",
    "            last_verse = None\n",
    "            continue\n",
    "        # Use regex to check if the line starts with a verse number and capture it\n",
    "        match = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "        if match:\n",
    "            verse_number, entry = match.groups()\n",
    "            last_verse = verse_number\n",
    "        else:\n",
    "            entry = line\n",
    "            verse_number = last_verse\n",
    "        \n",
    "        if current_chapter is not None and verse_number:\n",
    "            lemmas_contents = parse_apparatus_entry(entry)\n",
    "            for lemma, content in lemmas_contents:\n",
    "                app = ET.SubElement(current_chapter, TEI+\"app\")\n",
    "                lem = ET.SubElement(app, TEI+\"lem\", n=verse_number)\n",
    "                lem.text = lemma\n",
    "                if content:\n",
    "                    rdg = ET.SubElement(app, TEI+\"rdg\")\n",
    "                    rdg.text = content\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    \"\"\"Save the TEI XML tree to a file.\"\"\"\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caaa3e86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line does not conform to expected format: ﻿App III: Hosea\n",
      "Line does not conform to expected format: יחזקיה] 30 93 (pm) 96 יחזקיהו\n",
      "Line does not conform to expected format: ירבעם בן] 30 + נבט (non voc)\n",
      "Line does not conform to expected format: לו] 96 >I  II IV\n",
      "Line does not conform to expected format: ממלכוּת] 96 ממלכוֹת\n",
      "Line does not conform to expected format: יזרעאל] 150 ישראל (parall; but 150-Tg: יזרעאל)\n",
      "Line does not conform to expected format: כי] 93 (pm) + את\n",
      "Line does not conform to expected format: אוסיף] 150 (pm) >\n",
      "Line does not conform to expected format: את] 93 (pm) >\n",
      "Line does not conform to expected format: בסוסים] 96 ובסוסיםI IV\n",
      "Line does not conform to expected format: אשר2] 96 + לא\n",
      "Line does not conform to expected format: אחד] 30 (pm) 150 (pm) >\n",
      "Line does not conform to expected format: והצגתיה] 93 (pm) + כיום ערומה והצגתיה\n",
      "Line does not conform to expected format: ושתִּה] 150 (pm) ושמתיה\n",
      "Line does not conform to expected format: כי] 150 (non voc) + כי\n",
      "Line does not conform to expected format: שכְחה] 150 (pm) שכחת\n",
      "Line does not conform to expected format: מפתיה] 89 מְפַּתֶיהָ\n",
      "Line does not conform to expected format: המדבר] 96 המדברה (similarly SifreDeut 313 (356:6), RuthR 5:6)\n",
      "Line does not conform to expected format: תקראי1] 150 (pm) תקראו | 30 + לי (non voc)I II\n",
      "Line does not conform to expected format: לי] G-B Eb 54 (pm) >II\n",
      "Line does not conform to expected format: עוד] 30 (pm?) >\n",
      "Line does not conform to expected format: את] 30 89 (sm) 93 (pm) אניI II IV\n",
      "Line does not conform to expected format: לא] 96 ולאI\n",
      "Line does not conform to expected format: תזני] 93 (pm) תתי (Caused by ligature ז+נ)\n",
      "Line does not conform to expected format: אליך] 93 (pm) אלהיך\n",
      "Line does not conform to expected format: וגם] 30 (pm) וכל\n",
      "Line does not conform to expected format: אתה] 96 (pm) את\n",
      "Line does not conform to expected format: k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\n",
      "Line does not conform to expected format: ותשכח] 150 (pm) תשכחי\n",
      "Line does not conform to expected format: נפשו] 89 (pm) 96 (pm) 150 (pm) נפשםI IV\n",
      "Line does not conform to expected format: עליו] 96 + ודמו (non voc)\n",
      "Line does not conform to expected format: דרכיו] 30 (pm) כדרכיו\n",
      "Line does not conform to expected format: הזנו] 150 (pm) והזנו\n",
      "Line does not conform to expected format: כי] 96 >\n",
      "Line does not conform to expected format: צלה] 93 (pm) יגלה\n",
      "Line does not conform to expected format: וכלותיכם] 150 (pm) + כי\n",
      "Line does not conform to expected format: הזֹנות] 93 (pm) זנות\n",
      "Line does not conform to expected format: יְפָרדו] 93 96 יִפָּרדו\n",
      "Line does not conform to expected format: ואל1] 150 (pm) אלI IV\n",
      "Line does not conform to expected format: ואַל3] 30 ואֵל\n",
      "Line does not conform to expected format: אהבו] 93 (pm) אתם\n",
      "Line does not conform to expected format: קלון] 150 (pm) קלו\n",
      "Line does not conform to expected format: מגניה] 96 (pm) מקלון\n",
      "Line does not conform to expected format: מִזִּבְחותם] 30 93 150 מִזְבְּחתםI IV | 96 מִזְבְחותם\n",
      "Line does not conform to expected format: אל] 93 (pm) + אלI IV\n",
      "Line does not conform to expected format: בקרבם] 96 (pm) בקרבכם\n",
      "Line does not conform to expected format: עמם] 93 (pm) עמכם\n",
      "Line does not conform to expected format: את] 93 + דבר (non voc)II IV\n",
      "Line does not conform to expected format: עתה] 93 (pm) ועתה\n",
      "Line does not conform to expected format: את] 30 (pm) >\n",
      "Line does not conform to expected format: בית] 150 בין (similarly b. R.HaŠanams 32b)\n",
      "Line does not conform to expected format: אחריך] 93 (pm) >\n",
      "Line does not conform to expected format: גבול] 93 + עולם (non voc) (cf גבול עולם Prov 2228 2310)\n",
      "Line does not conform to expected format: וְכָרקב] 93 96 וּכְרקב\n",
      "Line does not conform to expected format: וישלח] 93 מ..\n",
      "Line does not conform to expected format: מיֹמים] 30 (pm?) >\n",
      "Line does not conform to expected format: כמלקוש] 150 (pm) ומלקושI II IV\n",
      "Line does not conform to expected format: מה2] 30 93 150 (pm) ומהI\n",
      "Line does not conform to expected format: לְךָ2] 96 לָךְ | 30 (pm) + אפרים\n",
      "Line does not conform to expected format: וחסדכם] 93 150 חסדכםI\n",
      "Line does not conform to expected format: הֹלך] 96 והולךI\n",
      "Line does not conform to expected format: חבר] 93 (pm) וחבר\n",
      "Line does not conform to expected format: שׁם] 96 שׂם\n",
      "Line does not conform to expected format: וגנב] 30 וכגנב\n",
      "Line does not conform to expected format: פשט] 93 (pm) ופשטI (similarly S.Eli.R 22 (125))\n",
      "Line does not conform to expected format: בחוץ] 96 (pm) בחרץ\n",
      "Line does not conform to expected format: מעיר] 96 (sm) עיר\n",
      "Line does not conform to expected format: מלוש] 150 (pm) בלוש\n",
      "Line does not conform to expected format: שרים] 30 (pm) >\n",
      "Line does not conform to expected format: ידו את] 30 ~\n",
      "Line does not conform to expected format: אֹפֵהֶם] 93 (pm) אפריםI\n",
      "Line does not conform to expected format: לב] 89 (pm) לבי\n",
      "Line does not conform to expected format: איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\n",
      "Line does not conform to expected format: פשעוּ] 96 פשעִי\n",
      "Line does not conform to expected format: ואנכי] 150 (pm) ואניIV\n",
      "Line does not conform to expected format: דברו] 93 (pm) >\n",
      "Line does not conform to expected format: בלבם] 93 (pm) בלבבםIV\n",
      "Line does not conform to expected format: יתגוררו] 93 (pm) >\n",
      "Line does not conform to expected format: על היו] 150 (pm) ~\n",
      "Line does not conform to expected format: זוֹ] 96 זוּ\n",
      "Line does not conform to expected format: עברו] 96 (pm) עבר\n",
      "Line does not conform to expected format: תורָתי] 89 (pm) תורֹתי\n",
      "Line does not conform to expected format: בו] 96 בֹה\n",
      "Line does not conform to expected format: שרים] 96 150 ושריםI II IV\n",
      "Line does not conform to expected format: אפרים] 30 (pm) ישראל\n",
      "Line does not conform to expected format: לו] 93 (pm) לי\n",
      "Line does not conform to expected format: k רבו / q רבי] 30 89 93 96 q, 150 (pm) רובו\n",
      "Line does not conform to expected format: יהוה] 150 (pm) ויהוהI IV\n",
      "Line does not conform to expected format: עתה] 150 (pm) ועתה\n",
      "Line does not conform to expected format: חטֹאותם] 89 93 96 150 (pm) חטאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: המה] 150 (pm) והמהIV\n",
      "Line does not conform to expected format: הרבה] 30 (pm) + מזבחות\n",
      "Line does not conform to expected format: ואכלה] 150 (pm) + כל\n",
      "Line does not conform to expected format: ארמנתיה] 93 (pm) ארמנותיו\n",
      "Line does not conform to expected format: בית] 93 (pm) >\n",
      "Line does not conform to expected format: לכספם] 150 לנפשם\n",
      "Line does not conform to expected format: אויל] 96 (pm) >\n",
      "Line does not conform to expected format: רֹב] 96 רַב\n",
      "Line does not conform to expected format: עונְךָ] 96 עונֵךְ\n",
      "Line does not conform to expected format: ורבה] 150 (pm) רבהIV\n",
      "Line does not conform to expected format: נביא] 96 (pm) הנביא\n",
      "Line does not conform to expected format: יקוֹש] 93 96 יקוּש\n",
      "Line does not conform to expected format: חטאותם] 89 93 150 (pm) חטֹאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: וַינזרו] 30 וְינזרו\n",
      "Line does not conform to expected format: ויהיו] 96 (pm) ויהי\n",
      "Line does not conform to expected format: רחם] 96 (pm) מרחם\n",
      "Line does not conform to expected format: מביתי] 93 (pm) מביתIV\n",
      "Line does not conform to expected format: ילדון] 93 (pm) ילזון\n",
      "Line does not conform to expected format: לו] 150 >\n",
      "Line does not conform to expected format: למזבחות] 93 (pm) למזבח\n",
      "Line does not conform to expected format: יָרֵאנו] 30 יַרְאֵנו\n",
      "Line does not conform to expected format: כרֹת] 96 (pm) וכרותI\n",
      "Line does not conform to expected format: ופרח] 150 (pm) ופתח\n",
      "Line does not conform to expected format: וכְמריו] G-B Msr 34 כֹ\n",
      "Line does not conform to expected format: יגילו] 150 (sm) יגלו\n",
      "Line does not conform to expected format: על] 93 (pm) ועל\n",
      "Line does not conform to expected format: ממנו] 96 (pm) ממני\n",
      "Line does not conform to expected format: מלכהּ] 93 (pm) מלכם\n",
      "Line does not conform to expected format: מים] 93 (pm) המים\n",
      "Line does not conform to expected format: כַּסונו] 89 כִּסונו (?)\n",
      "Line does not conform to expected format: חטאתָ] 93 (sm) 96 (sm) חטא (ת non voc)\n",
      "Line does not conform to expected format: עלוה] 89 (sm) עולהI\n",
      "Line does not conform to expected format: k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\n",
      "Line does not conform to expected format: ועת] 150 (pm) עת\n",
      "Line does not conform to expected format: לדרוש] 96 >\n",
      "Line does not conform to expected format: את] 30 (pm) >, 96 (non voc)\n",
      "Line does not conform to expected format: יהוה] 93 (pm) יהודה\n",
      "Line does not conform to expected format: ויֹרה] 93 (pm) G-B Eb 16 יורה\n",
      "Line does not conform to expected format: שלמן] 96 שלומך\n",
      "Line does not conform to expected format: ארבֵאל] 93 ארבְּאֵל\n",
      "Line does not conform to expected format: ולפסִלים] 96 לפסילים\n",
      "Line does not conform to expected format: רפאתים] 96 (pm) רפאתיו\n",
      "Line does not conform to expected format: לחֵיהם] 30 93 לחָיֵיהם\n",
      "Line does not conform to expected format: ממֹעצותיהם] 96 (pm) ממעֲוצותיהם\n",
      "Line does not conform to expected format: למשובתי] 30 (pm) למשבתוI\n",
      "Line does not conform to expected format: ולא2] 93 (sm) 150 (pm) לאII IV\n",
      "Line does not conform to expected format: ושֹׁד] 93 (pm) >\n",
      "Line does not conform to expected format: וברית] 96 (pm) ובריית\n",
      "Line does not conform to expected format: ישיב] 30 (pm) 150 (pm) אשיבI\n",
      "Line does not conform to expected format: בגלגל] 150 (pm) ובגלגל\n",
      "Line does not conform to expected format: זבחו] 93 (pm) >\n",
      "Line does not conform to expected format: גם מזבחותם] 96 >\n",
      "Line does not conform to expected format: ויושיעֲך] 96 (pm) ויושיעוך\n",
      "Line does not conform to expected format: לי] 96 לנו\n",
      "Line does not conform to expected format: הוא] 93 (pm) 150 (pm) והואIV\n",
      "Line does not conform to expected format: לא1] 93 ולא\n",
      "Line does not conform to expected format: דבריך] 30 93 (pm) 96 דברךI II IV\n",
      "Line does not conform to expected format: נֹחם] G-B Msr 34 נַחֵם (taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)\n",
      "Line does not conform to expected format: ויבוש] 93 (pm) תיבש\n",
      "Line does not conform to expected format: הוא2] 93 (pm) 96 150 (pm) והואI II\n",
      "Line does not conform to expected format: אמרו] 30 (pm) 93 (pm) 96 150 (pm) ואמרוII IV\n",
      "Line does not conform to expected format: כל] 89 (pm) בלI\n",
      "Line does not conform to expected format: וצדקים] 96 צדיקים\n",
      "Line does not conform to expected format: ‏App III: Hosea\n",
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    \n",
    "    tei_root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    tei_header = ET.SubElement(tei_root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    current_chapter = None\n",
    "    last_verse_number = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1].strip()\n",
    "            current_chapter = ET.SubElement(body, TEI + \"div\", type=\"chapter\", n=chapter_number)\n",
    "        else:\n",
    "            # Attempt to extract verse number and lemma content\n",
    "            parts = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "            if parts:\n",
    "                verse_number, remainder = parts.groups()\n",
    "                last_verse_number = verse_number  # Update last verse number with current\n",
    "                \n",
    "                # Further split to separate lemma from variants, if present\n",
    "                lemma_section, variants_section = remainder.split(']', 1) if ']' in remainder else (remainder, \"\")\n",
    "                lemma_section = lemma_section.strip()\n",
    "                variants_section = variants_section.strip()\n",
    "\n",
    "                if current_chapter is not None and verse_number:\n",
    "                    # Create an apparatus entry for the lemma\n",
    "                    app = ET.SubElement(current_chapter, TEI + \"app\")\n",
    "                    lem = ET.SubElement(app, TEI + \"lem\", n=verse_number)\n",
    "                    lem.text = lemma_section\n",
    "                    \n",
    "                    # Add variant readings if present\n",
    "                    if variants_section:\n",
    "                        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "                        rdg.text = variants_section\n",
    "            else:\n",
    "                print(f\"Line does not conform to expected format: {line}\")\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808c9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    app = ET.Element(TEI + \"app\")\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, TEI + \"lem\")\n",
    "    lem.text = lemma_text.strip()\n",
    "    \n",
    "    # Extract comments\n",
    "    comments = re.findall(r'\\((.*?)\\)', rest)\n",
    "    for comment in comments:\n",
    "        note = ET.SubElement(app, TEI + \"note\")\n",
    "        note.text = comment\n",
    "    \n",
    "    # Remove comments from rest for further processing\n",
    "    rest = re.sub(r'\\(.*?\\)', '', rest).strip()\n",
    "    \n",
    "    # Extract and process witnesses and cross-references\n",
    "    if rest:\n",
    "        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "        witnesses, _, variant_reading = rest.partition(' ')\n",
    "        if witnesses:\n",
    "            rdg.set('wit', witnesses.strip())\n",
    "        if variant_reading:\n",
    "            rdg.text = variant_reading.strip()\n",
    "        \n",
    "        # Extract cross-references, assuming they are indicated by Roman numerals at the start\n",
    "        cross_refs = re.findall(r'\\bI{1,3}V?|\\bIV', rest)\n",
    "        for ref in cross_refs:\n",
    "            ref_element = ET.SubElement(rdg, TEI + \"ref\")\n",
    "            ref_element.set('target', '#' + ref)  # Assuming target IDs are prefixed with '#'\n",
    "            ref_element.text = \"See apparatus entry \" + ref\n",
    "    \n",
    "    return app\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    div = ET.SubElement(body, TEI + \"div\")\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI)\n",
    "            div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a6244acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "witnesses: G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) \n",
      "reading: > שערורה\n",
      "After dividers: IV (bla bla (f))\n"
     ]
    }
   ],
   "source": [
    "#split entry into witnesses, reading, and comments \n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "split_parts = split_string(text)\n",
    "if split_parts:\n",
    "    print(\"witnesses:\", split_parts[0])\n",
    "    print(\"reading:\", split_parts[1])\n",
    "    print(\"After dividers:\", split_parts[2])\n",
    "else:\n",
    "    print(\"No dividers found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "70cc4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('G-B msr. ', '30', 'pm'), ('G-A ', '89', 'pm?'), ('', '150', 'non voc'), ('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('MS-G ', '150', 'pm')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "25936b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\n",
      "Numerals found: ['II', 'IV']\n"
     ]
    }
   ],
   "source": [
    "#parse comments\n",
    "import re\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# Example usage\n",
    "text = \"II IV (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\"\n",
    "result_text, numerals_found = remove_and_list_roman_numerals(text)\n",
    "print(\"Modified text:\", result_text.strip())\n",
    "print(\"Numerals found:\", numerals_found)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d33f9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entry(entry):\n",
    "    split_parts = split_string(entry)\n",
    "    if split_parts is None:\n",
    "        return None\n",
    "    \n",
    "    witnesses, reading, comments = split_parts\n",
    "\n",
    "    structured_entry = {\n",
    "        'witnesses': [],\n",
    "        'reading': reading,\n",
    "        'comments': '',\n",
    "        'cross_references': []\n",
    "    }\n",
    "\n",
    "    for part in custom_split_string(witnesses):\n",
    "        # Assuming part[1] contains the witness number and part[0], part[2], part[3] contain additional info\n",
    "        witness_info = {\n",
    "            'n': part[1],\n",
    "            'text': f\"{part[0]}{part[1]} {part[2].strip()}{part[3]}\"\n",
    "        }\n",
    "        structured_entry['witnesses'].append(witness_info)\n",
    "\n",
    "    comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "    structured_entry['comments'] = comments_text\n",
    "    structured_entry['cross_references'] = numerals_found\n",
    "\n",
    "    return structured_entry\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    TEI_ns = {'tei': TEI}  # Define the namespace dictionary if needed\n",
    "    app = ET.Element(f\"{{{TEI}}}app\")  # Using namespace in the tag\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, f\"{{{TEI}}}lem\")\n",
    "    lem.text = lemma_text.strip('[] ')\n",
    "\n",
    "    structured_entry = process_entry(rest)\n",
    "    if not structured_entry:\n",
    "        return None\n",
    "\n",
    "    for witness in structured_entry['witnesses']:\n",
    "        wit_element = ET.SubElement(app, f\"{{{TEI}}}wit\", {'n': witness['n']})\n",
    "        wit_element.text = witness['text']\n",
    "    \n",
    "    rdg_element = ET.SubElement(app, f\"{{{TEI}}}rdg\")\n",
    "    rdg_element.text = structured_entry['reading']\n",
    "\n",
    "    if structured_entry['comments']:\n",
    "        comment_element = ET.SubElement(app, f\"{{{TEI}}}note\")\n",
    "        comment_element.text = structured_entry['comments']\n",
    "\n",
    "    for ref in structured_entry['cross_references']:\n",
    "        ref_element = ET.SubElement(app, f\"{{{TEI}}}ref\")\n",
    "        ref_element.text = ref\n",
    "\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8e18d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    ET.register_namespace('', TEI_NAMESPACE)  # Register the default namespace\n",
    "\n",
    "    # Create the root element without redundantly specifying the xmlns attribute\n",
    "    root = ET.Element(\"{%s}TEI\" % TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, \"{%s}teiHeader\" % TEI_NAMESPACE)\n",
    "    text = ET.SubElement(root, \"{%s}text\" % TEI_NAMESPACE)\n",
    "    body = ET.SubElement(text, \"{%s}body\" % TEI_NAMESPACE)\n",
    "    div = ET.SubElement(body, \"{%s}div\" % TEI_NAMESPACE)\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI_NAMESPACE)\n",
    "            if entry is not None:  # Ensure entry creation was successful\n",
    "                div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a4a220d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'witnesses': [{'n': '30', 'text': 'G-B msr. 30 (pm) '}, {'n': '89', 'text': 'G-A 89 (pm?) '}, {'n': '150', 'text': '150 (non voc) k'}, {'n': '30', 'text': ' 30 (sm) '}, {'n': '89', 'text': '89 (sm) '}, {'n': '93', 'text': '93 (sm) '}, {'n': '96', 'text': '96 '}, {'n': '150', 'text': '150 (pm) q'}, {'n': '93', 'text': ' 93 (pm) '}], 'reading': '> שערורה', 'comments': '  (bla bla (f))', 'cross_references': ['IV', 'II']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def custom_split_string(text):\n",
    "    pattern = re.compile(r'([^,\\d]*?)?(\\d+)\\s?(\\([^\\)]+\\)?)?([\\skq]*)?', re.DOTALL|re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# def process_entry(entry):\n",
    "#     split_parts = split_string(entry)\n",
    "#     if split_parts is None:\n",
    "#         return \"Unable to process entry: No valid dividers found.\"\n",
    "    \n",
    "#     witnesses, reading, comments = split_parts\n",
    "\n",
    "#     witness_entries = []\n",
    "#     for part in custom_split_string(witnesses):\n",
    "#         witness_entry = f'<witness n=\"{part[1]}\">{part[0]}{part[1]} {part[2].strip()}{part[3]}</witness>'\n",
    "#         witness_entries.append(witness_entry)\n",
    "#     witnesses_tagged = \"\\n\".join(witness_entries)\n",
    "\n",
    "#     reading_tagged = f'<reading>{reading}</reading>'\n",
    "\n",
    "#     comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "#     comments_tagged = f'<comment>{comments_text}</comment>'\n",
    "#     cross_references = \"\\n\".join([f'<ref>{numeral}</ref>' for numeral in numerals_found])\n",
    "\n",
    "#     # Combine all parts, placing cross_references outside the comment\n",
    "#     tei_entry = f\"{witnesses_tagged}\\n{reading_tagged}\\n{comments_tagged}\\n{cross_references}\"\n",
    "#     return tei_entry\n",
    "\n",
    "# Example usage\n",
    "entry =\"G-B msr. 30 (pm) G-A 89 (pm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV II (bla bla (f))\"\n",
    "processed_entry = process_entry(entry)\n",
    "print(processed_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12325297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93 (pm) + ביהושעIV (similarly PesiqtaR 33 (153b))'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = \"93 (pm) + ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caa1d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tei_hebrew_output_enhanced.xml'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def strip_non_hebrew(word):\n",
    "    normalized_word = unicodedata.normalize('NFD', word)\n",
    "    stripped_word = ''.join(re.findall(r'[\\u05D0-\\u05EA]', normalized_word))\n",
    "    return unicodedata.normalize('NFC', stripped_word)\n",
    "\n",
    "def process_word(token, verse_id, word_id, parent_element):\n",
    "    parts = token.split('־')\n",
    "    pe_count = 1  # Counter for 'פ' tags\n",
    "\n",
    "    for part in parts:\n",
    "        w = ET.SubElement(parent_element, 'w', id=f'verse{verse_id}_word{word_id}')\n",
    "\n",
    "        alphabetic = strip_non_hebrew(part)\n",
    "        non_alphabetic = ''.join(re.findall(r'[^\\u05D0-\\u05EA]', part))\n",
    "\n",
    "        original = ET.SubElement(w, 'original')\n",
    "        original.text = part\n",
    "        stripped = ET.SubElement(w, 'stripped')\n",
    "        stripped.text = alphabetic\n",
    "        punctuation = ET.SubElement(w, 'punctuation')\n",
    "        punctuation.text = non_alphabetic\n",
    "\n",
    "        if \"פ\" in part:\n",
    "            pe_tag = ET.SubElement(w, 'pe', id=f'verse{verse_id}_pe{pe_count}')\n",
    "            pe_tag.text = \"פ\"\n",
    "            pe_count += 1\n",
    "        \n",
    "        word_id += 1\n",
    "    return word_id\n",
    "\n",
    "def encode_tei_hebrew_word_details_enhanced(file_path, output_file):\n",
    "    text = read_text_from_file(file_path)\n",
    "    TEI = ET.Element('TEI', xmlns='http://www.tei-c.org/ns/1.0')\n",
    "    text_element = ET.SubElement(TEI, 'text')\n",
    "    body = ET.SubElement(text_element, 'body')\n",
    "\n",
    "    chapter_id = 1\n",
    "    verse_id = 1\n",
    "\n",
    "    chapters = text.split('פרק')\n",
    "    for chapter in chapters[1:]:\n",
    "        div = ET.SubElement(body, 'div', type='chapter', id=f'chapter{chapter_id}')\n",
    "        chapter_id += 1\n",
    "\n",
    "        verses = re.split(r'(\\[\\פ\\]|:)', chapter)\n",
    "        for verse in verses:\n",
    "            if verse.strip() and verse not in ['[פ]', ':']:\n",
    "                p = ET.SubElement(div, 'p', type='verse', id=f'verse{verse_id}')\n",
    "                word_id = 1\n",
    "\n",
    "                tokens = verse.strip().split()\n",
    "                for token in tokens:\n",
    "                    word_id = process_word(token, verse_id, word_id, p)\n",
    "\n",
    "                verse_id += 1\n",
    "\n",
    "    tree = ET.ElementTree(TEI)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        tree.write(f, encoding=\"unicode\")\n",
    "\n",
    "# Specify the file paths\n",
    "file_path = 'file.txt'  # Replace with your input file path\n",
    "output_file = 'tei_hebrew_output_enhanced.xml'  # Replace with your output file path\n",
    "\n",
    "# Run the function\n",
    "encode_tei_hebrew_word_details_enhanced(file_path, output_file)\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[' ', '\"', '$', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', 'E', 'I', 'T', '_', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', '֑', '֔', '֕', '֖', '֗', '֙', '֛', '֜', '֞', '֣', '֤', '֥', '֨', '֩', 'ְ', 'ֱ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ֽ', '׀', 'ׁ', 'ׂ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3cf327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '$', '$1', '$2', '$4', '2', ':', '[', ']', '֑', '֔', '֕', '֖', '֗', '֙', '֜', '֣', '֤', '֥', '֥$', '֨', '֩', 'ְ', 'ְ$', 'ְ֙', 'ְּ', 'ְׁ', 'ְׂ', 'ֱ', 'ֲ', 'ִ', 'ִ$', 'ִ֔', 'ִ֖', 'ִ֜', 'ִ֨', 'ִּ', 'ִֽ', 'ִׁ', 'ֵ', 'ֵ$', 'ֵ֔', 'ֵ֖', 'ֵ֗', 'ֵ֛', 'ֵ֣', 'ֵ֤', 'ֵ֨', 'ֵּ', 'ֵֽ', 'ֵׁ', 'ֶ', 'ֶ֑', 'ֶ֙', 'ֶ֣', 'ֶ֤', 'ֶ֥', 'ֶּ', 'ֶֽ', 'ֶׁ', 'ַ', 'ַ֗', 'ַ֙', 'ַּ', 'ַׁ', 'ָ', 'ָ֑', 'ָ֔', 'ָ֖', 'ָ֗', 'ָ֛', 'ָ֜', 'ָ֞', 'ָ֣', 'ָ֥', 'ָ֨', 'ָּ', 'ָֽ', 'ֹ', 'ֹ֖', 'ֹ֣', 'ֹ֤', 'ֹ֨', 'ֹּ', 'ֹׂ', 'ֻ', 'ּ', 'ּ֣', 'ֽ', '־', '־$', '׀', 'ׁ', 'ׂ֖', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "def extract_consecutive_non_hebrew_groups(file_path):\n",
    "    text = read_text_from_file(file_path)\n",
    "    non_hebrew_groups = set()\n",
    "\n",
    "    # Using a regular expression to find sequences of non-Hebrew characters\n",
    "    pattern = re.compile(r'([^\\u05D0-\\u05EA]{,2})')\n",
    "    matches = pattern.findall(unicodedata.normalize('NFD', text))\n",
    "\n",
    "    for match in matches:\n",
    "        non_hebrew_groups.add(match.strip())\n",
    "\n",
    "    return non_hebrew_groups\n",
    "\n",
    "# Extract and print groups of consecutive non-Hebrew characters\n",
    "file_path = 'file.txt'\n",
    "\n",
    "consecutive_non_hebrew_groups = extract_consecutive_non_hebrew_groups(file_path)\n",
    "print(sorted(consecutive_non_hebrew_groups))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
