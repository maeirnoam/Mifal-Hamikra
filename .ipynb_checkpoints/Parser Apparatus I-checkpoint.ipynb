{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558de29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from docx import Document\n",
    "from lxml import etree\n",
    "import zipfile\n",
    "import os\n",
    "from win32com import client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e6dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo:\n",
    "# 1. you know to extract footnotes and font info of main text and footnotes. now need to combine it all into a \n",
    "# good txt file that could be rendered to the xml. \n",
    "# consider rendering already via the xml of the worddocx, since anyways your using it for the footnotes\n",
    "\n",
    "# get footnote placement from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30874b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def process_footnotes(docx_path):\n",
    "    # Dictionary to store footnote data\n",
    "    footnotes_dict = {}\n",
    "\n",
    "    # Step 1: Extract the footnotes XML from the .docx file\n",
    "    with zipfile.ZipFile(docx_path, 'r') as docx:\n",
    "        # Look for footnotes XML part\n",
    "        if 'word/footnotes.xml' in docx.namelist():\n",
    "            footnote_xml = docx.read('word/footnotes.xml').decode('utf-8')\n",
    "        else:\n",
    "            print(\"No footnotes.xml found in this document.\")\n",
    "            return footnotes_dict\n",
    "\n",
    "    # Step 2: Parse the footnote XML and store in dictionary\n",
    "    if footnote_xml:\n",
    "        root = ET.fromstring(footnote_xml)\n",
    "        namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "        \n",
    "        non_blank_count = 1  # Start counting footnotes for non-blank lines only\n",
    "\n",
    "        for footnote in root.findall('w:footnote', namespaces):\n",
    "            footnote_text = \"\"\n",
    "\n",
    "            # Extract each run's text, font, and superscript/subscript information in the footnote\n",
    "            for run in footnote.findall('.//w:r', namespaces):\n",
    "                text_elem = run.find('w:t', namespaces)\n",
    "                font_elem = run.find('.//w:rPr//w:rFonts', namespaces)\n",
    "                vert_align_elem = run.find('.//w:rPr//w:vertAlign', namespaces)\n",
    "\n",
    "                if text_elem is not None:\n",
    "                    text = text_elem.text\n",
    "                    font = font_elem.get(f'{{{namespaces[\"w\"]}}}ascii') if font_elem is not None else \"Unknown\"\n",
    "\n",
    "                    # Check for superscript or subscript alignment\n",
    "                    if vert_align_elem is not None:\n",
    "                        align_val = vert_align_elem.get(f'{{{namespaces[\"w\"]}}}val')\n",
    "                        if align_val == \"superscript\":\n",
    "                            text = f\"<superscript {text} >\"\n",
    "                        elif align_val == \"subscript\":\n",
    "                            text = f\"<subscript {text} >\"\n",
    "\n",
    "                    # Wrap the text in <specialFont ...> if it’s in the special font\n",
    "                    if font == \"HUBPSigla\":  # Replace with your actual font name if different\n",
    "                        footnote_text += f\"<specialFont {text} >\"\n",
    "                    else:\n",
    "                        footnote_text += text\n",
    "\n",
    "            # Only store non-blank footnotes in the dictionary\n",
    "            if footnote_text.strip():  # Check if footnote text is non-blank\n",
    "                footnotes_dict[f'footnote-{non_blank_count}'] = footnote_text.strip()\n",
    "                non_blank_count += 1  # Increment count only for non-blank footnotes\n",
    "\n",
    "    return footnotes_dict\n",
    "\n",
    "\n",
    "def process_main_text(docx_path):\n",
    "    # Temporary storage for extracted XML content\n",
    "    document_xml = None\n",
    "\n",
    "    # Step 1: Extract `document.xml` from the .docx file\n",
    "    with zipfile.ZipFile(docx_path, 'r') as docx:\n",
    "        if 'word/document.xml' in docx.namelist():\n",
    "            document_xml = docx.read('word/document.xml').decode('utf-8')\n",
    "\n",
    "    # Define the WordprocessingML namespace\n",
    "    namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "\n",
    "    # Initialize a dictionary to store the main text with formatting\n",
    "    main_text_dict = {}\n",
    "\n",
    "    # Step 2: Parse `document.xml` to identify and tag footnote references, fonts, superscript, and subscript\n",
    "    if document_xml:\n",
    "        document_root = ET.fromstring(document_xml)\n",
    "        \n",
    "        # Initialize title and chapter, and skip empty rows\n",
    "        title_and_chapter = \"\"\n",
    "        first_row_processed = False\n",
    "\n",
    "        for i, paragraph in enumerate(document_root.findall('.//w:p', namespaces), start=1):\n",
    "            paragraph_text = \"\"\n",
    "            \n",
    "            # Check if this is the first row for title and chapter\n",
    "            if not first_row_processed:\n",
    "                # Extract the first row's text as title and chapter\n",
    "                title_and_chapter = ''.join(\n",
    "                    run.find('w:t', namespaces).text or ''\n",
    "                    for run in paragraph.findall('.//w:r', namespaces)\n",
    "                    if run.find('w:t', namespaces) is not None\n",
    "                ).strip()\n",
    "                \n",
    "                # Mark first row as processed and continue to next paragraph\n",
    "                first_row_processed = True\n",
    "                continue\n",
    "\n",
    "            # Skip empty rows (rows with only whitespace or no text)\n",
    "            if not any(run.find('w:t', namespaces) is not None for run in paragraph.findall('.//w:r', namespaces)):\n",
    "                continue\n",
    "\n",
    "            # Assign a unique ID for each paragraph after the first row\n",
    "            app_id = f\"app-{i-2}\"\n",
    "\n",
    "            # Process each run in the paragraph\n",
    "            for run in paragraph.findall('.//w:r', namespaces):\n",
    "                text_elem = run.find('w:t', namespaces)\n",
    "                font_elem = run.find('.//w:rPr//w:rFonts', namespaces)\n",
    "                vert_align_elem = run.find('.//w:rPr//w:vertAlign', namespaces)\n",
    "                footnote_ref = run.find('.//w:footnoteReference', namespaces)\n",
    "\n",
    "                # Initialize tags for formatting\n",
    "                font_tag_open = \"\"\n",
    "                font_tag_close = \"\"\n",
    "                vert_align_tag_open = \"\"\n",
    "                vert_align_tag_close = \"\"\n",
    "\n",
    "                # Check for special font and wrap in <specialFont ...> if present\n",
    "                if font_elem is not None:\n",
    "                    font = font_elem.get(f'{{{namespaces[\"w\"]}}}ascii')\n",
    "                    if font == \"HUBPSigla\":  # Replace with your actual font name if needed\n",
    "                        font_tag_open = \"<specialFont \"\n",
    "                        font_tag_close = \">\"\n",
    "\n",
    "                # Check for superscript or subscript\n",
    "                if vert_align_elem is not None:\n",
    "                    align_val = vert_align_elem.get(f'{{{namespaces[\"w\"]}}}val')\n",
    "                    if align_val == \"superscript\":\n",
    "                        vert_align_tag_open = \"<superscript \"\n",
    "                        vert_align_tag_close = \">\"\n",
    "                    elif align_val == \"subscript\":\n",
    "                        vert_align_tag_open = \"<subscript \"\n",
    "                        vert_align_tag_close = \">\"\n",
    "\n",
    "                # Process text and footnote references\n",
    "                if text_elem is not None:\n",
    "                    # Wrap the text according to font, superscript, or subscript tags\n",
    "                    text_content = f\"{font_tag_open}{vert_align_tag_open}{text_elem.text or ''}{vert_align_tag_close}{font_tag_close}\"\n",
    "                    paragraph_text += text_content\n",
    "\n",
    "                elif footnote_ref is not None:\n",
    "                    # Get the ID of the footnote reference and wrap it in <ref ...> tags without content\n",
    "                    footnote_id = footnote_ref.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "                    paragraph_text += f\"<ref {footnote_id}>\"\n",
    "\n",
    "            # Store the formatted paragraph in the dictionary, identified by `app_id`\n",
    "            main_text_dict[app_id] = paragraph_text\n",
    "\n",
    "    return {\n",
    "        'title_and_chapter': title_and_chapter,\n",
    "        'content': main_text_dict\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e064928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Hosea.1.docx:\n",
      "\n",
      "Main Text: {'title_and_chapter': 'Hosea 1', 'content': {'app-1': '1 יותם אחז יחזקיה] <specialFont ][> <specialFont &>', 'app-2': 'מלכי] <specialFont ]h> num<subscript II><ref 2>', 'app-3': '2 דִּבֶּר] <specialFont ]> λόγου<ref 3> = <specialFont [T>', 'app-4': 'ב(הושע)] <specialFont ]h> πρός<ref 4> <specialFont +> <specialFont [>ܕܗܘܐ ܥܠ<ref 5>', 'app-5': 'ו(יאמר)] <specialFont ]h[> >', 'app-6': 'לֵךְ] <specialFont ]h> ><subscript II>', 'app-7': '3 ויקח] <specialFont [> + ܠܗ<ref 6>', 'app-8': 'לו] <specialFont ]h*-> ><subscript II III IV><ref 7>', 'app-9': '4 יהוא] <specialFont ]h> Ιουδα<ref 8>', 'app-10': '(ו)הִשְׁבַּתִּי] <specialFont ]-> ἀποστρέψω<ref 9>', 'app-11': 'בית<superscript 2>] <specialFont ]h*h><specialFont T><specialFont -> + prep<ref 10>', 'app-12': '5 והיה (ביום ההוא)] <specialFont [> ><ref 11>', 'app-13': '(ו)היה] <specialFont *> >', 'app-14': 'ההוא] <specialFont ]h> + dicit dominus<ref 12>', 'app-15': '6 עוד<superscript 1>] <specialFont *hT-> ><subscript II III IV>', 'app-16': 'לו] <specialFont ]h> + κύριος<subscript II><ref 13> = <specialFont [>| <specialFont [> pron<ref 14>', 'app-17': 'נשׂא אשׂא] <specialFont ]> ἀντιτασσόμενος ἀντιτάξομαι<ref 15> | <specialFont *> oblivione obliviscar<ref 16> <specialFont +> <specialFont ~>', 'app-18': '7 בית] <specialFont ]> υἱούς<ref 17>', 'app-19': 'יהודה] <specialFont ]h> >', 'app-20': 'ולא] <specialFont ][> rep', 'app-21': '(ו)במלחמה] <specialFont ]-> + (οὐδὲ) ἐν ἅρμασιν<ref 18>', 'app-22': 'בסוסים] <specialFont ]*[> <specialFont &><subscript III IV>', 'app-23': '8 ותהר] <specialFont ]-> + ἔτι<subscript II><ref 19> = <specialFont [>', 'app-24': 'ותלד] <specialFont ]h> + αὐτῷ<subscript IV><ref 20> = <specialFont *h>', 'app-25': '9 ויאמר] <specialFont ]h> + κύριος (αὐτῷ)<subscript II><ref 21> = <specialFont Th> <specialFont +> <specialFont [>', 'app-26': 'כי – עמי ~ ואנכי – לכם] <specialFont 9> ~', 'app-27': 'לכם] <specialFont ]h> + θεός<ref 22> = <specialFont *h> <specialFont +><specialFont  [h>'}}\n",
      "\n",
      "Footnotes: {'footnote-1': 'cf app Mic 1<subscript 1 >', 'footnote-2': '(a) voc דְּבַר (יהוה), formula, cf v<subscript 1 > 4<subscript 1 > et al; cf app 13<subscript 1 >; cf תחלת דִּבְרֵי Qoh 10<subscript 13 >; note seq; (b) noun דִּבֵּר, cf app Jer 5<subscript 13 > and Rabb Heb; cf gerund in <specialFont * > loquendi “of speaking”', 'footnote-3': '“to”; main evid, cf v<subscript 1 >', 'footnote-4': '“which was to”, ex v<subscript 1 >', 'footnote-5': '“for himself”, cf v<subscript 2 >', 'footnote-6': 'cf vv<subscript 6,8 >; contrast Hier 10<subscript 154 >', 'footnote-7': 'main evid; inner-Grk (בית יהודה common collocation), cf Hier 12<subscript 208−211 >', 'footnote-8': 'voc הֲשִׁבֹתִי, similarly app 2<subscript 13 > Ezek 7<subscript 24 >; for parall השיב//פקד cf 4<subscript 9 > 12<subscript 3 >; main evid <specialFont ]h ><subscript   >καταπαύσω (=<specialFont x >)', 'footnote-9': 'common formula השבית מן, cf e.g. Lev 26<subscript 6 > Jer 7<subscript 34 >', 'footnote-10': 'formulaic change, cf app Joel 4<subscript 18 > Mic 5<subscript 9 > et al', 'footnote-11': '“says the Lord”, formula (נאם יהוה), cf 2<subscript 18,23 > et al', 'footnote-12': '“the Lord”, cf v<subscript 4 >, app v<subscript 9 > (ויאמר)', 'footnote-13': '1sg, cf 3<subscript 1 >', 'footnote-14': '“opposing I shall oppose” (= <specialFont ] > 1Kgs 11<subscript 34 >); p etym <specialFont \\\\ > נשׁא“oppress, set against” (cf Ps 89<subscript 23 >), cf Obad <subscript 7 > הִשִּׁיאוּךָ <specialFont J > <specialFont ] > ἀντέστησάν σοι “they opposed you” (for interchange of ἀντιτάσσεσθαι “to oppose” / ἀνθίστασθαι “to stand against” cf <specialFont ]i > 4Macc 16<subscript 23 >); cf also Jer 49<subscript 16 > הִשִּׁיא = <specialFont ] > [29<subscript 17 >] ἐνεχείρησε “(it) attacked” (contrast etym <specialFont \\\\ >נשׂא<specialFont   ><specialFont ~ ><specialFont 9 > and <subscript p >Obad <subscript 3 > <specialFont ] >)', 'footnote-15': '“by forgetfulness I shall forget”, etym <specialFont \\\\ >נשׁה, contrast app Jer 23<subscript 39 >', 'footnote-16': '“sons (of)”, for בני/בית cf app Amos 1<subscript 5 > 3<subscript 1 > Zeph 1<subscript 8 >', 'footnote-17': 'p (ו)ברכב; common collocation, cf e.g. Ezek 26<subscript 7 > בסוס וברכב ובפרשים', 'footnote-18': '“again”, cf v<subscript 6 >', 'footnote-19': '“(to) him”, cf v<subscript 3 >', 'footnote-20': '“the Lord (to him)”, cf app v<subscript 6 > (לו); for <specialFont [ > pron cf nError: Reference source not found', 'footnote-21': '“God”, cf e.g. Exod 6<subscript 7 > Lev 26<subscript 12 > Zech 8<subscript 8 >; note diverse word-order in <specialFont ]h >'}\n",
      "\n",
      "\n",
      "Results for Hosea.10.docx:\n",
      "\n",
      "Main Text: {'title_and_chapter': 'Hosea 10', 'content': {'app-1': '1 בוקק] <specialFont ]> εὐκληματοῦσα<ref 2> <specialFont +> <specialFont 9> ὑλομανοῦσα<ref 3> = <specialFont ~><subscript Syh> <specialFont +> <specialFont *> | <specialFont ~><subscript Hier> ἔνυδρος<ref 4> | <specialFont [> ܕܫܒ̈ܘܩܐ<ref 5> | <specialFont T> בזיזא<ref 6>', 'app-2': '(פרי) ישוה לו] <specialFont ]h> (ὁ καρπὸς) αὐτῆς εὐθηνῶν<ref 7> | <specialFont [> ܕܥܒܕܬ (ܦܐܪ̈ܐ)<ref 8>', 'app-3': 'יְשַוֶּה] <specialFont *> adaequatus est<ref 9> = <specialFont ~9>', 'app-4': 'לפריו ... למזבחות ... לארצו] <specialFont ]*[> ptcl', 'app-5': 'למזבחות] <specialFont ]h> > det', 'app-6': 'כטוב] <specialFont ]h[> <specialFont &>', 'app-7': 'היטיבו] <specialFont ]-> ᾠκοδόμησαν<ref 10> = <specialFont [><ref 11> | <specialFont ]h~*> pers<ref 12>', 'app-8': '2 חלק לבם]<ref 13> <specialFont ]h> /num/<ref 14>', 'app-9': 'יאשמו] <specialFont ]> ἀφανισθήσονται<ref 15> = <specialFont *> ', 'app-10': 'מזבחותם ... מצבותם] <specialFont *> ~', 'app-11': 'ישדד מצבותם] <specialFont ]> diath<ref 16>', 'app-12': 'ישדד] <specialFont ]h[> <specialFont &>', 'app-13': '3 כי<superscript 2>] <specialFont [> >', 'app-14': '<specialFont יהוה>] <specialFont *h> div<specialFont  >', 'app-15': '4 דִבְּרוּ ... כָּרֹת] <specialFont ]*[T> verb', 'app-16': 'אלות] <specialFont ]> προφάσεις<ref 17> = <specialFont [> <specialFont +> <specialFont *> visiones<ref 18> | <specialFont T> ימן<ref 19>', 'app-17': 'כָּרֹת] <specialFont *> <specialFont &><subscript III>', 'app-18': 'ופרח] <specialFont ]-> ἀνατελεῖ<ref 20> = <specialFont *-> | <specialFont [> pers<ref 21> ', 'app-19': '(כ)ראש] <specialFont ]> ἄγρωστις<ref 22> <specialFont +> <specialFont ~|[> | <specialFont *> amaritudo<ref 23>', 'app-20': 'תלמי]<ref 24> <specialFont ]> χέρσον<ref 25> = <specialFont [> | <specialFont T> תחומי<ref 26>', 'app-21': '5 לעגלות] <specialFont ]|[Th> num', 'app-22': '(בית) אָוֶן]<ref 27> <specialFont ]-> Ων = <specialFont [>| <specialFont T> אל', 'app-23': 'יגורו] <specialFont ]> παροικήσουσιν<ref 28> <specialFont +> <specialFont [>| <specialFont ~> ἐσεβάσθησαν<ref 29> = <specialFont *> <specialFont +> <specialFont |> | <specialFont T> יסבון<ref 30>', 'app-24': 'שְׁכַן] <specialFont ]*[> num | <specialFont T> עגלא<ref 31>', 'app-25': 'כי<superscript 1>] <specialFont ]h> connect', 'app-26': 'עליו עמו] <specialFont ]> ~', 'app-27': '<specialFont v>יגילו<specialFont ,>עליו<specialFont ,>וכמריו<specialFont v>] <specialFont ]> <specialFont v>καὶ καθὼς παρεπίκραναν αὐτόν<specialFont v>ἐπιχαροῦνται<specialFont ,><ref 32> | <specialFont [> <specialFont ,>ܢܚܕܘܢ<specialFont ,>ܘܥܠܘܗܝ<specialFont v>ܘܟܘܡܪ̈ܘܗܝ<specialFont ,><ref 33>', 'app-28': '(ו)כמריו] <specialFont ]> καθὼς παρεπίκραναν<ref 34>', 'app-29': '6 גם] <specialFont *[> <specialFont &>', 'app-30': '(ל)אשור] <specialFont ]> + δήσαντες<ref 35>', 'app-31': 'יוּבָל] <specialFont ][T-> diath', 'app-32': 'יָרֵב]<ref 36>', 'app-33': 'בָּשְׁנָה]<ref 37> <specialFont ]> ἐν δόματι<ref 38> ', 'app-34': 'ו(יבוש<specialFont )>] <specialFont ]h*h> >', 'app-35': 'מעצתו] <specialFont ]*[> prep', 'app-36': '7 נדמה]<ref 39> <specialFont ]> ἀπέρριψε<ref 40> = <specialFont [>ܫܕܬ <ref 41> <specialFont +> <specialFont *> transire fecit<ref 42> | <specialFont T> בהיתת ... ב-<ref 43>', 'app-37': '(כ)קצף] <specialFont ]> φρύγανον<ref 44> = <specialFont [> | <specialFont ~> ܪܘܥܬܐ<ref 45> = <specialFont 9><specialFont *T>', 'app-38': '8 ונשמדו] <specialFont T> ויצדיין<ref 46>', 'app-39': 'אָוֶן] <specialFont ]> Ων<ref 47> = <specialFont [>', 'app-40': 'כסונו (ולגבעות) ~ נפלו עלינו] <specialFont ]h> ~', 'app-41': 'נִפְלוּ עלינו] <specialFont [> reformul<ref 48>', 'app-42': '9 הגבעה]<ref 49> <specialFont ][h><ref 50> num ', 'app-43': 'חטאתָ] <specialFont ]*> pers<ref 51>', 'app-44': 'לא] <specialFont [T> <specialFont &><subscript IV>', 'app-45': 'עלוה] <specialFont ]> ἀδικίας<subscript III><ref 52> = <specialFont *[> | <specialFont T> סליקו<ref 53>', 'app-46': '10 בְּאַוָּתִי] <specialFont ]-> ἦλθον<ref 54> | <specialFont ]h><subscript 1> ἦλθε(ν)<ref 55> | <specialFont ]h><subscript 2> > | <specialFont [> ܒܟܐܬܝ<ref 56>', 'app-47': '(וְ)אֶסֳּרֵ(ם)] <specialFont ]-> παιδεῦσαι<ref 57> <specialFont +> <specialFont ]h*[T>', 'app-48': 'ואֻספו] <specialFont T> diath<ref 58>', 'app-49': '(ב)אסר(ם)] <specialFont ]> παιδεύεσθαι<ref 59> <specialFont +> <specialFont *[>', 'app-50': 'ל(שתי)] <specialFont ]-[T-> prep', 'app-51': 'k עינתם / q עוֹנֹתם] <specialFont ]> ἀδικίαις αὐτῶν<ref 60> = <specialFont *[> ', 'app-52': '11 ו(אפרים)] <specialFont ]*[> ><subscript II>', 'app-53': 'מלֻמדה] <specialFont T> diath', 'app-54': 'אֹהבתי לדוש]<ref 61> <specialFont T> ~', 'app-55': 'לדוש] <specialFont ]> νεῖκος<ref 62>', 'app-56': 'עברתי עַל] <specialFont T> פרקתי יתהון משעבוד מצראי אעדיתי<ref 63>', 'app-57': 'טוב] <specialFont [> >', 'app-58': 'ארכיב] <specialFont *> ascendam (super)<ref 64>', 'app-59': 'יחרוש] <specialFont ]h[> <specialFont &> | <specialFont ]> παρασιωπήσομαι<ref 65> | <specialFont [~h|h> ܢܕܪܟ<ref 66> ', 'app-60': 'ישַׂדד] <specialFont ]> ἐνισχύσει<ref 67> | <specialFont [> (ܘ)ܢܒܘܙ<ref 68>', 'app-61': '12 לצדקה ... לפי] <specialFont *-> prep<ref 69>', 'app-62': 'קצרו] <specialFont ]h*h[> <specialFont &><subscript II III IV> | <specialFont ]h> + ἑαυτοῖς<ref 70>', 'app-63': '(ל)פי חסד] <specialFont ]> καρπὸν ζωῆς<ref 71>', 'app-64': 'נירו ... ניר] <specialFont ]> φωτίσατε … φῶς<ref 72> <specialFont +> <specialFont [><ref 73>', 'app-65': 'ועת<specialFont v>(ניר)] <specialFont ]> (φῶς)<specialFont ,> γνώσεως<ref 74> | <specialFont ]h> + ὡς ἔτι καιρός<ref 75>', 'app-66': 'לדרוש] <specialFont ]> verb<ref 76>', 'app-67': 'וירה (צדק)<specialFont v>] <specialFont ]> <specialFont ,>γενήματα<ref 77>', 'app-68': 'צדק] <specialFont [> + pron<ref 78>', 'app-69': '13 חרשתם] <specialFont ]> pr ἵνα τί<ref 79> | <specialFont ]><superscript -> παρεσιωπήσατε<ref 80>', 'app-70': 'אכלתם<specialFont v>קצרתם<specialFont ,>עולתה<specialFont v>] <specialFont [> ܘܐܟܠܬܘܢ<specialFont ,>ܘܚܨܕܬܘܢ<specialFont v>ܘܥܘܠܐ<specialFont ,>', 'app-71': 'עַוְלָתָ(ה)] <specialFont ][> <specialFont &> |<specialFont ]h> τὸν καρπόν<ref 81>', 'app-72': '(עולת)ה] <specialFont ]> αὐτῆς<ref 82>', 'app-73': 'בטחת – גבוריך] <specialFont [> /pers/<ref 83>', 'app-74': 'בדרכך lex] <specialFont ]-> ἅρμασι<ref 84> | <specialFont ]h> ἁρματήμασι<ref 85> | <specialFont *[T> num<subscript III IV> ', 'app-75': 'גבוריך] <specialFont ]> δυνάμεώς σου<ref 86> = <specialFont [>', 'app-76': '14 <specialFont יושד><specialFont  ><specialFont –><specialFont  ><specialFont ארבאל>]<ref 87> ', 'app-77': 'יושד] <specialFont ]-> οἰχήσεται<ref 88> <specialFont +> <specialFont ]h> ἀφανισθήσεται<ref 89> | <specialFont *[T> pers<ref 90> ', 'app-78': '(כ)שֹׁד] <specialFont ]> ἄρχων<ref 91>', 'app-79': '(כשד) שלמן] <specialFont ]> Σαλαμαν<ref 92> = <specialFont *9> | <specialFont [> (ܕ)ܫܠܡܐ<ref 93> | <specialFont T> (ד)שַלמָא<ref 94> | <specialFont ]> + ἐκ<ref 95> = <specialFont *[>', 'app-80': '(בית) ארבאל] <specialFont ]-> Ιεροβααλ<ref 96>, <specialFont *> eius qui iudicavit Bahal<ref 97> <specialFont +> <specialFont ~> | <specialFont |> ܟܡܐܢܐ<ref 98> = <specialFont T> | <specialFont [> (ܒܝܬ) ܐܝܠ<ref 99>', 'app-81': '(ב)יום] <specialFont ]> num ', 'app-82': 'בנים] <specialFont [> + pron<ref 100>', 'app-83': 'רֻטשה] <specialFont ][> diath', 'app-84': '15 עָשָׂה] <specialFont ]><specialFont [T> pers<ref 101>', 'app-85': '(בית) אל] <specialFont ]> (οἶκος τοῦ) Ισραηλ<ref 102>', 'app-86': 'רעת] <specialFont ]> ><ref 103>', 'app-87': 'בשחר – ישראל] <specialFont ]*> 11<subscript 1>', 'app-88': 'ב(שחר)] <specialFont *> sicuti<ref 104>', 'app-89': ' (ב)שחר] <specialFont T> סופא<ref 105>', 'app-90': 'נדמָה<specialFont ,>נדמֹה]<ref 106> <specialFont ]*><specialFont v><ref 107> | <specialFont [-> ܬܘܪ ܘܒܗܬ<ref 108>, <specialFont T> בהית (ו)אתכנע<ref 109> | <specialFont ~> κατεσιωπήθη<ref 110>'}}\n",
      "\n",
      "Footnotes: {'footnote-1': '“growing luxuriantly”, apt exeg ex context; parall seq; for picture cf Ezek 17<subscript 7 ><subscript – ><subscript 8 > Ps 80<subscript 9 ><subscript – ><subscript 10 >', 'footnote-2': '“overgrown”', 'footnote-3': '“watered”, cf e.g. Ezek 17<subscript 8 >; but cf Hier 105<subscript 6 ><subscript – ><subscript 8 > (“watery”)', 'footnote-4': '“of (many) branches”, cf <specialFont [ > Ezek 17<subscript 6 >; note homoph (בק/ܒܩ)', 'footnote-5': '“plundered”, cf <specialFont T > Isa 24<subscript 1,3 > Nah 2<subscript 3,11 >; for picture cf <specialFont T > 5<subscript 7 >', 'footnote-6': '“its (fruit) is abundant”; apt for picture, cf <specialFont ] > Ezek 17<subscript 6 > Ps 128<subscript 3 >; hardly יִשְׁלֶה; no evid for <specialFont ]- > εὐθηνῶν αὐτῇ', 'footnote-7': '“which produced (fruits)”, etym <specialFont \\\\ >שוה<subscript 2 ><superscript   >“to set, make”, cf 9<subscript 16 > עשׂה + פרי', 'footnote-8': 'voc יִשְׁוֶה, etym <specialFont \\\\ >שוה<subscript 1 > “to be like”', 'footnote-9': '“they built”; atten, cf Zech 8<subscript 15 > להיטיב <specialFont J > <specialFont ] > ποιῆσαι', 'footnote-10': 'ܒܢܘ (ܥ̈ܠܘܬܐ) usus for בנו (במות), cf Jer 7<subscript 31 > 19<subscript 5 > 32<subscript 35 > 1Kgs 14<subscript 23 > 2Kgs 17<subscript 9 >', 'footnote-11': '3sg', 'footnote-12': 'understood as <specialFont \\\\ >חלק<subscript 2 > “to divide” in Vrs; in <specialFont ] > חלק taken as transitive, in <specialFont ~9 ><specialFont *[T > as intransitive; see Talmon, Studies in Language 11–12 (2009), 133–137', 'footnote-13': 'in <specialFont ] > לבם (pl) taken as object <specialFont 7 > in <specialFont ]h > verb (pl, main evid) refers to Israel, in <specialFont ]- > verb (sg) p refers to God', 'footnote-14': 'etym <specialFont \\\\ ><specialFont שמם >, cf app 5<subscript 15 >', 'footnote-15': 'p coniug, cf e.g. <specialFont ] > Joel 1<subscript 10 >', 'footnote-16': 'p עִלּוֹת* (phon א/ע), cf <specialFont | > Dan 6<subscript 5–6 >;<subscript   >p עֲלִלוֹת, cf <specialFont ] > Deut 22<subscript 14 > Ps 141<subscript 4 >', 'footnote-17': '“cause(s)” (legal term)', 'footnote-18': '“(they) swear”; אלות taken as inf (parall כָּרֹת); cf <specialFont T > 4<subscript 2 > ימן <specialFont J > אָלֹה', 'footnote-19': 'p יפרח (ו/י); <specialFont ]h > ἀνετέλει p inner-Grk', 'footnote-20': '3pl, but incongruent with sg subject; p inner-Syr <specialFont # >ܘܦܪܥ (3sg / 3pl perf, common orthographic interchange in Syr) = <specialFont x >; p parall ܡܠܠܘ ... ܦܣܩܘ', 'footnote-21': 'p דשא (ד/ר and metathesis), cf <specialFont ] > Deut 32<subscript 2 > (note Isa 66<subscript 14 > כדשא + פרח); hardly apt for ראש<subscript 2 > “poisonous herb”', 'footnote-22': '“bitterness”, apt, cf <specialFont * > Amos 6<subscript 12[13] > Ps 140[139]<subscript 10 > 141[140]<subscript 5 >', 'footnote-23': 'similarly app 12<subscript 12 >', 'footnote-24': '“untilled part (of the field)”; p context exeg, for picture cf v<subscript 8 >, <specialFont ] > Isa 5<subscript 6 >', 'footnote-25': '“boundaries (of the fields)”', 'footnote-26': 'cf app 4<subscript 15 >', 'footnote-27': 'etym <specialFont \\\\ >גור<subscript 1 > “to dwell”, cf שכן seq', 'footnote-28': '“they worshipped”, etym <specialFont \\\\ >גור<subscript 3 ><superscript   >“to fear (god)”; opposed to v<subscript 3 > לא יראנו את יהוה', 'footnote-29': '“they will take”', 'footnote-30': '“calf”, cf לעגלות init; cf עגל שמרון 8<subscript 6 >', 'footnote-31': '<specialFont ; > lexic, see nError: Reference source not found', 'footnote-32': 'p <specialFont ; > <specialFont & >; p ditt (וכמרי)ו ו(עליו)', 'footnote-33': '“as they embittered”; lexic, cf transliteration in <specialFont ] > 2Kgs 23<subscript 5 > (contrast Zeph 1<subscript 4 >); understood as כְּ- + etym <specialFont \\\\ >מר(ה/ר)', 'footnote-34': '“(they,) having tied (it) up”; p אָשׂוּר/אָסוּר (dupl) and diath (cf app seq)', 'footnote-35': 'for Vrs cf app 5<subscript 13 >', 'footnote-36': 'hapax; understood as בֹּשֶׁת/בּוּשָׁה in most Vrs (cf ויבוש seq, Hab 2<subscript 10 >)', 'footnote-37': 'ב- taken as prep (“in”); -שנה understood as “gift”; p parall מנחה prec; <specialFont ]h > add alternative transl (=<specialFont x >)', 'footnote-38': 'taken as transitive in Vrs', 'footnote-39': '“it cast away”, p <specialFont \\\\ >דמה/רמה (ד/ר; cf <specialFont [ >), but see Weissert, Textus 22 (2005), 77–86; cf app v<subscript 15 > Obad <subscript 5 >', 'footnote-40': 'cf <specialFont [ > Jer 4<subscript 29 > Ps 78<subscript 9 > (<specialFont J > <specialFont \\\\ ><specialFont רמה >)', 'footnote-41': '“it caused (the king) to pass by”, cf v<subscript 15 > [<specialFont * > 11<subscript 1 >]', 'footnote-42': '“was ashamed of”, cf <specialFont T > v<subscript 15 > Jer 6<subscript 2 > 8<subscript 14  >(<specialFont J > <specialFont \\\\ >דמה/דמם)', 'footnote-43': '“brushwood”, apt, cf Joel 1<subscript 7 > קְצָפָה', 'footnote-44': '“foam”, context exeg', 'footnote-45': 'וְנָשַׁמּוּ, cf e.g. Amos 7<subscript 9 > Ezek 6<subscript 6 >', 'footnote-46': 'cf app 4<subscript 15 >', 'footnote-47': 'change from direct to indirect speech', 'footnote-48': 'cf app 5<subscript 8 > 9<subscript 9 >', 'footnote-49': 'according to Bar Hebraeus 7<subscript 24 >', 'footnote-50': '3sg; p parall; p <specialFont x > ditt (paleo-Heb א/ת)', 'footnote-51': 'apt (עַוְלָה = עַלְוָה, cf e.g. Qimḥi), for בן/בני עולה cf 2Sam 3<subscript 34 > 7<subscript 10 > || 1Chr 17<subscript 9 > Ps 89<subscript 23 >', 'footnote-52': '“they went up”, p etym <specialFont \\\\ >עלה; p עָלוּ', 'footnote-53': 'p בָּאתִי; but all evid <specialFont ]h >; <specialFont ]h > add alternative transl κατὰ τὴν ἐπιθυμίαν μου (=<specialFont x >)', 'footnote-54': '“he came”, main evid; hardly בָּא; p inner-Grk', 'footnote-55': '“in my rebuke”, ex context in <specialFont [ > (see nError: Reference source not found)', 'footnote-56': '“to discipline”, etym <specialFont \\\\ >יסר, cf 7<subscript 12 >, cf nError: Reference source not found', 'footnote-57': 'parall ואסרם; cf Zech 14<subscript 2 >', 'footnote-58': 'cf nError: Reference source not found; understood as passive', 'footnote-59': 'עֲוֹנֹתָם (cf q); <specialFont T > עונתיה inconclusive, cf Epstein, MGWJ 65 (1921), 357–364', 'footnote-60': 'taken as object of מלֻמדה in <specialFont ]* >', 'footnote-61': '“strife, quarrel”; (a) exeg: <specialFont \\\\ >דוש “to thresh” <specialFont $ > “to trample down” (cf e.g. <specialFont ] > Isa 25<subscript 10 >), “to shatter” (cf <specialFont ] > Hab 3<subscript 12 >) <specialFont $ > “to quarrel”; (b) מָדוֹן/לָדוּן (cf <specialFont ] > Prov 10<subscript 12 > 22<subscript 10 > 29<subscript 22 >); (c) inner-Grk <specialFont # > νειός (=νειόν, cf Thackeray §28) “ploughing”, cf <specialFont T > למרדי “to plough”; for “thresh/plough” cf also app Amos 9<subscript 13 > (cf nError: Reference source not found)', 'footnote-62': 'p (ה)עברתי עֹל; dupl transl: midrashic (“I delivered them from the servitude of the Egyptians”, cf <specialFont T > Ezek 16<subscript 9 > Zech 9<subscript 11 >) and literal (“I removed the yoke”, cf e.g. <specialFont T > Isa 9<subscript 3 >)', 'footnote-63': 'p coniug אֶרְכַּב = <specialFont [ ><subscript U,M > (but SyrLex s.v. ܪܟܒ reads ܐܲܪܟܸܒ = <specialFont x >)', 'footnote-64': 'pers (1sg); etym <specialFont \\\\ >חרשׁ<subscript 2 > “to be silent”, cf app v<subscript 13 > Amos 6<subscript 12 >', 'footnote-65': '(a) p “he will thresh”, parall <specialFont [ > prec (<specialFont J > <specialFont לדוש >), for דוש/חרש cf nError: Reference source not foundc; (b) hardly “he will seize”, different picture, cf nError: Reference source not found', 'footnote-66': '“he will prevail”, <specialFont \\\\ >שׂר(ה/ר), cf app v<subscript 14 > 12<subscript 4,5 >, Gen 32<subscript 29 >', 'footnote-67': 'ישֹׁדד, cf v<subscript 2 >; cf also v<subscript 14 >', 'footnote-68': 'in <specialFont [ > ל- taken as nota accusativi, cf Prov 11<subscript 18 >', 'footnote-69': '“to you (pl)”, parall', 'footnote-70': \"“fruit of life”; p פרי חלד; for פרי cf v<subscript 13 >; for חלד <specialFont J > ζωή cf Job 11<subscript 17 >, cf also Ps 39<subscript 6 > 88<subscript 48 >; hardly abbrev פרי ח' (ח' expanded as חיים); for similar picture cf Prov 11<subscript 30 >\", 'footnote-71': '“lighten ... light”, etym <specialFont \\\\ >נור “to give light”', 'footnote-72': 'similarly <specialFont [ > Jer 4<subscript 3 > (cf app); note usus נִ(י)ר <specialFont J > ܫܪܓܐ (e.g. 1Kgs 11<subscript 36 >)', 'footnote-73': 'דעת, for ד/ו cf app 12<subscript 2 >, 1Sam 21<subscript 14 > (<specialFont x >/<specialFont ] >), 1Kgs 12<subscript 33 > (k/q)', 'footnote-74': 'p וְעֹד עֵת (dupl), alternative reading; but p ὡς <specialFont # > inner-Grk ditt (γνώσε)ως or ὡς = כ(י) (rather than וְ-), cf <specialFont [ > ܡܛܘܠ ܕ-', 'footnote-75': 'imperative 2pl; parall', 'footnote-76': 'p context exeg; p פרי, cf nError: Reference source not found; note v<subscript 13 > פרי כחש; for <specialFont \\\\ >פרי + צדק cf Amos 6<subscript 12 > Prov 11<subscript 30 >; differently app Joel 2<subscript 23 >', 'footnote-77': '3sg', 'footnote-78': '“why”; cf Hab 1<subscript 13 > למה ... תחריש ... רשע', 'footnote-79': 'cf app v<subscript 11 >', 'footnote-80': 'parall seq (פרי [כחש]) and v<subscript 12 > (καρπὸν ζωῆς, see nError: Reference source not found); hardly עוֹלָתָ(הּ), for ע(וֹ)לָה <specialFont J > καρπ‐ cf e.g. Exod 30<subscript 9 > Lev 1<subscript 3,4 >', 'footnote-81': '-ה understood as 3sgf pron', 'footnote-82': '2pl; parall', 'footnote-83': 'רִכְבְּךָ, cf Isa 31<subscript 1 > 2Kgs 18<subscript 24 > || Isa 36<subscript 9 >', 'footnote-84': '“in your sins”; p inner-Grk, cf <specialFont ]h > Mic 5<subscript 9 >; hardly apt, cf 1Kgs 22<subscript 53 > דרך ירבעם <specialFont J > <specialFont ] > ἐν ταῖς ἁμαρτίαις οἴκου Ιεροβοαμ (usually <specialFont J > חטאות בית ירבעם)', 'footnote-85': '“your strength”, for abstract noun cf app Joel 4<subscript 11 >; but cf גבורתך/גבוריך app<subscript II > Isa 3<subscript 25 >', 'footnote-86': 'note struct of <specialFont ] >: οἰχήσεται<specialFont , > ὡς ἄρχων Σαλαμαν· (contra Ziegler); <specialFont ] ><specialFont 9 ><specialFont * > allude to Gideon-Jerobaal traditions, cf Judg 6–8 Ps 83<subscript 10–11 >; cf Syh and Hier 118<subscript 495–500 >', 'footnote-87': '“will go away”, i.e. “will vanish”; p apt, cf <specialFont ] ><specialFont h > Jer 10<subscript 20 > 49[30]<subscript 3 >; for picture cf <specialFont ] > Isa 17<subscript 3 > (ונשבת מבצר מאפרים); <specialFont ]h > οἰκήσεται inner-Grk <specialFont # > <specialFont ]- > (phon κ/χ)', 'footnote-88': '“will be destroyed”, parall ἀπώλεια “ruin”; not יושמד', 'footnote-89': '3pl', 'footnote-90': 'שַׂר (ד/ר); cf nError: Reference source not found', 'footnote-91': 'understood as proper name (= צַלְמֻנָּע)', 'footnote-92': '(a) ܫܲܠܡܐ “complete (plunder)” (according to Bar Bahlul 1981<subscript 19 >, Bar Ali 438<subscript 12 >, Išo‘dad 75<subscript 8–9 >), etym שָׁלֵם, = <specialFont ~ > (ܕ)ܡܫܡܠܝܐ; (b) ܫܠܵܡܐ “peace” (according to <specialFont [ ><subscript U,M > and Ḥnana apud Išo‘dad 75<subscript 11 >), etym שָׁל(וֹ)ם', 'footnote-93': 'problematic vocalization, p שלָמָא (cf nError: Reference source not foundb), cf Rashi; cf <specialFont T > 1Kgs 2<subscript 5 > (כמנת שלָמָא) and nError: Reference source not found', 'footnote-94': 'p ditt (של)מן מן; in <specialFont [ > p ditt (של)מ מ-, cf nError: Reference source not found', 'footnote-95': 'cf nError: Reference source not found; for בית ירבעל cf Judg 8<subscript 35 >; <specialFont ]h > Ιεροβοαμ inner-Grk, cf Hier 118<subscript 508 >–119<subscript 509 >', 'footnote-96': '“who judged Baal”, i.e. Gideon, cf Judg 6<subscript 32 >; etym <specialFont \\\\ >ריב (for <specialFont \\\\ ><specialFont ריב >/<specialFont \\\\ ><specialFont ארב > cf 1Sam 15<subscript 5 > and Vrs)', 'footnote-97': '“ambush”, etym <specialFont \\\\ >ארב; cf <specialFont T > 7<subscript 6 > (<specialFont J > בארבם); cf nError: Reference source not found', 'footnote-98': '“Bethel”, cf v<subscript 15 >', 'footnote-99': '3sgf', 'footnote-100': '<specialFont ] > 1sg (future), <specialFont [T > 3pl', 'footnote-101': 'cf seq; p abbrev; similarly app Amos 5<subscript 6 >', 'footnote-102': 'p <specialFont x > ditt; p reduct', 'footnote-103': 'כ(שחר) (ב/כ), cf <specialFont ]h > dupl', 'footnote-104': '“(in) the end”; <specialFont T- > add בצפרא (=<specialFont x >)', 'footnote-105': 'taken as two finite verbs in all Vrs', 'footnote-106': 'for <specialFont ]* > lex cf app v<subscript 7 >', 'footnote-107': '“became confounded and ashamed”; for ܬܘܪ <specialFont J > דמה cf e.g. <specialFont [ > Zeph 1<subscript 11 > Isa 15<subscript 1 > (ܬܡܗܘ ... ܬܘܪܘ <specialFont J > נדמה ... נדמה); for ܒܗܬ <specialFont J > דמה cf <specialFont T >; note <specialFont [h > /pers/ (3pl)', 'footnote-108': '“became ashamed and humbled”; for בהת <specialFont J > דמה cf app v<subscript 7 >; בהת + אתכנע common collocation in <specialFont T >, cf e.g. Mic 3<subscript 6,7 > Ezek 36<subscript 32 >', 'footnote-109': '“was silenced”; reduct'}\n",
      "\n",
      "\n",
      "Results for Hosea.11.docx:\n",
      "\n",
      "Main Text: {'title_and_chapter': 'Hosea 11', 'content': {'app-1': '1 כי] <specialFont [> ܡܛܠ ܕܟܕ<ref 2> ', 'app-2': '(ו)אהבהו] <specialFont ]-> pr ἐγὼ<ref 3> | <specialFont 9> diath', 'app-3': 'קראתי לבני] <specialFont |> ἐκάλεσα αὐτὸν υἱόν μου<ref 4> = <specialFont [> <specialFont +> <specialFont T>', 'app-4': 'לבְנִי] <specialFont ]> τὰ τέκνα αὐτοῦ<ref 5>', 'app-5': '2 קָרְאוּ] <specialFont ]-> pr καθὼς<ref 6> = <specialFont [> | <specialFont ]-> pers<ref 7>', 'app-6': 'מִפְּנֵיהֶם] <specialFont ]> ἐκ προσώπου μου<specialFont v> αὐτοί<ref 8> <specialFont +> <specialFont [>', 'app-7': 'לבעלים] <specialFont [h> (ܘ)ܠܥ̈ܓܠܐ<ref 9> ', 'app-8': '3 תרגלתי]<ref 10> <specialFont ]> συνεπόδισα<ref 11> | <specialFont *> quasi nutricius<ref 12> <specialFont +> <specialFont 9> ܡܬܪܐܐ ܗܘܝܬ<ref 13> | <specialFont [> ܕܒܪܬ<ref 14> <specialFont +> <specialFont T><ref 15>', 'app-9': 'קָחָ(ם)]<ref 16> <specialFont ]> ἀνέλαβον<ref 17> = <specialFont *[T>', 'app-10': '(קח)ם] <specialFont ]-> αὐτόν<ref 18>', 'app-11': 'זרועתיו] <specialFont ]> num | <specialFont ]*[> pron<subscript II III><ref 19> | <specialFont T> > pron', 'app-12': '4 (ב)חַבלי] <specialFont ]> διαφθορᾷ<ref 20>', 'app-13': 'אדם] <specialFont T> בנין רחימין<ref 21>', 'app-14': 'אהבה] <specialFont ]> + pron<ref 22>', 'app-15': '(כ)מרימי עֹל] <specialFont ]-> ῥαπίζων ἄνθρωπος ἐπί<ref 23>', 'app-16': '(כ)מרימי] <specialFont ]~><specialFont 9><specialFont *[T> num', 'app-17': 'על לחיהם] <specialFont [> ܡܢ ܩܕܠܗܘܢ<ref 24>', 'app-18': 'לחיהם] <specialFont ]-> pron<ref 25>', 'app-19': '(ו)אט] <specialFont ]> ἐπιβλέψομαι<ref 26>', 'app-20': 'אליו] <specialFont [T> pron<ref 27>', 'app-21': 'אוכיל] <specialFont ]h[> <specialFont &> | <specialFont 9> cibos<ref 28> = <specialFont ~|> <specialFont +> <specialFont *> ut vesceretur<ref 29> <specialFont +> <specialFont [T> ', 'app-22': '4–5 <specialFont ,>לֹא<specialFont v>אוֹכִיל] <specialFont ]> δυνήσομαι<specialFont ,>αὐτῷ<specialFont v><ref 30>', 'app-23': '5 ישוב ... מלכו] <specialFont [><specialFont T> pers/pron<ref 31>', 'app-24': 'ישוב אל ארץ (מצרים)] <specialFont ]> κατῴκησεν Εφραιμ ἐν<ref 32> <specialFont +> <specialFont Th> יתבון ב-', 'app-25': 'מאנו] <specialFont ]h> pers<ref 33>', 'app-26': '6 (ו)חלה]<ref 34> <specialFont ]> ἠσθένησε<ref 35> = <specialFont [> <specialFont +> <specialFont ~><subscript Syh><ref 36>| <specialFont 9> vulnerabit<ref 37> | <specialFont *> coepit<ref 38> | <specialFont T> תחול<ref 39> ', 'app-27': 'בעריו ... בדיו] <specialFont [> pron<ref 40>', 'app-28': 'וכִלתה] <specialFont [> ܘܢܬܛܠܩ<subscript III><ref 41>', 'app-29': 'בַדָּיו]<ref 42> <specialFont ]> ἐν ταῖς χερσὶν αὐτοῦ<ref 43> <specialFont +> <specialFont [> <specialFont ܡܢ><specialFont  ><specialFont ܐ̈ܝܕܝܗܘܢ> | <specialFont 9> bracchia illius<ref 44> | <specialFont *> electos eius<ref 45> <specialFont +> <specialFont T> גיברוהי<ref 46>', 'app-30': '<specialFont v>(ו)אכלה] <specialFont ]*[T> <specialFont ,> | <specialFont ][> pers<ref 47> | <specialFont T> + רברבוהי<ref 48>', 'app-31': 'ממעצותיהם] <specialFont *> capita eorum<ref 49> ', 'app-32': '7 ועמי ... למשובתי] <specialFont ]> pron<subscript III><ref 50>', 'app-33': 'ל(משובתי)] <specialFont ]~|> prep', 'app-34': 'למשובתי lex] <specialFont ]> κατοικία<ref 51>', 'app-35': '(למשובת)י] <specialFont [> (ܠܡܬܒ) ܠܘܬܝ<ref 52> = <specialFont 9> | <specialFont |> pron<subscript III><ref 53>', 'app-36': '(ו)אֶל עַל] <specialFont ]> ὁ θεὸς ἐπί<ref 54> | <specialFont ~> ܠܘܬ ܢܝܪܐ<ref 55> = <specialFont |> <specialFont +> <specialFont T> במרועא קשיא<ref 56> <specialFont +> <specialFont 9> ܢܝܪܐ<ref 57> = <specialFont *> iugum | <specialFont [> ܠܐܠܗܐ<ref 58>', 'app-37': 'יחד<specialFont v>יקראהו] <specialFont ]:*> <specialFont ,>', 'app-38': 'יקרָאֻהו]<ref 59> <specialFont ]> τὰ τίμια αὐτοῦ<ref 60> | <specialFont 9> ܢܦܓܥ ܒܗ<ref 61> <specialFont +> <specialFont T> יתערעון<ref 62> | <specialFont *> inponetur ei<ref 63> | <specialFont :> pers<ref 64> | <specialFont [> > pron', 'app-39': 'יַחַד] <specialFont ]> θυμωθήσεται<ref 65> | <specialFont [-> pr ܘܢܪܢܐ<ref 66>', 'app-40': 'לא] <specialFont ][> <specialFont &>', 'app-41': 'יְרוֹמֵם] <specialFont ]~|> + pron<ref 67> | <specialFont 9> ܢܫܬܩܠ<ref 68> = <specialFont *[> | <specialFont T> יהכון בקומא זקופא<ref 69>', 'app-42': '8 אתנך<superscript 1>] <specialFont [> ܐܣܝܥܟ<ref 70>', 'app-43': 'אמגנך ... אתנך<superscript 2>] <specialFont T-> אש(י)צינך ... אבדינך<ref 71>', 'app-44': 'אמגנ(ך)] <specialFont ]> ὑπερασπιῶ<ref 72> <specialFont +> <specialFont ~*> <specialFont +> <specialFont [> ܐܥܕܪܟ<ref 73>, <specialFont |> ἀφοπλίσω<ref 74>', 'app-45': 'אתנך<superscript 2> ... אשימך] <specialFont [> reduct', 'app-46': '<specialFont v>כְאַדְמָה<specialFont ,>] <specialFont ]-> <specialFont v>ὡς Αδαμα<specialFont ,><ref 75>', 'app-47': 'כצבאים] <specialFont ]><specialFont [h> <specialFont &><ref 76>', 'app-48': 'עלי] <specialFont ][> >', 'app-49': 'יחד] <specialFont [> >', 'app-50': 'נחומי] <specialFont [> ܪ̈ܚܡܝ<ref 77> <specialFont +> <specialFont T>, <specialFont |> ܡܥ̈ܝܐ ܕܪ̈ܚܡܐ<ref 78>', 'app-51': '9 חרון] <specialFont ]> pr κατά<ref 79>', 'app-52': 'אשוב] <specialFont ]> ἐγκαταλίπω<ref 80>', 'app-53': '<specialFont ,>בקרבך<specialFont v>] <specialFont [> <specialFont v>ܒܝܢܬܟܘܢ<specialFont ,>', 'app-54': 'קדוש] <specialFont [> + ܐܢܐ<ref 81>', 'app-55': '10 יהוה] <specialFont *h> div', 'app-56': 'ילכו] <specialFont ]-> πορεύσομαι<ref 82> | <specialFont ]h> πορεύεσθε<ref 83>', 'app-57': 'ישאג<superscript 1>] <specialFont ~> pers<ref 84>', 'app-58': 'ויחרדו] <specialFont T> ויתכנש(ו)ן<ref 85>', 'app-59': 'מִיָּם] <specialFont ]> ὑδάτων<ref 86>', 'app-60': '<specialFont (>מ)ים] <specialFont [-> ܥܡܐ<ref 87>', 'app-61': '11 יחרדו] <specialFont ]*[> <specialFont &> | <specialFont ]h><subscript 1> ἐκπτήσονται<ref 88> = <specialFont *> | <specialFont ]h><subscript 2> ἥξουσιν<ref 89>', 'app-62': '(ו)הוֹשַׁבְתִּי(ם)] <specialFont ]-> ἀποκαταστήσω<ref 90> = <specialFont [T>'}}\n",
      "\n",
      "Footnotes: {'footnote-1': '“because when”; dupl transl; usually <specialFont J > כי ב-, cf <specialFont [ > Josh 20<subscript 5 > Judg 11<subscript 16 > 1Sam 24<subscript 12 >', 'footnote-2': '“I”, cf v<subscript 3 >', 'footnote-3': 'קראתי לו בני; note diath in <specialFont 9 > κέκληται υἱός μου “he is called My son”; cf 2<subscript 1 >', 'footnote-4': 'voc לבנָ(י)ו; for pl cf <specialFont T > and vv<subscript 2–4 >', 'footnote-5': 'formula כ- (... כן) cf 4<subscript 7 > et al, cf app Ezek 22<subscript 20 >', 'footnote-6': '1sg, cf v<subscript 1 > קראתי', 'footnote-7': 'הֵם<specialFont v >מִפָּנַי', 'footnote-8': 'cf 1Kgs 12<subscript 32 > (לזבח) לעגלים', 'footnote-9': 'lexic diffic', 'footnote-10': '“I bound (his) feet together”; etym רֶגֶל, cf <specialFont | > ܒܥܩܒܬܐ', 'footnote-11': '“like a guardian”; note nutricius <specialFont J > אֹמֵן e.g. Esth 2<subscript 7 >; parall קחם על זרועתיו seq, cf Num 11<subscript 12 >', 'footnote-12': '“I raised, brought up”; note <specialFont [ > ܬܪܐܐ <specialFont J > אֹמֵן e.g. 2Kgs 10<subscript 5 >', 'footnote-13': '“I led, guided”, etym רֶגֶל', 'footnote-14': 'for add באורח תקנא “in the right way” cf e.g. <specialFont T > Isa 41<subscript 18 > Jer 31<subscript 8 > Gen 24<subscript 27 >', 'footnote-15': 'morph diffic', 'footnote-16': '“I took up”; parall תרגלתי ... רפאתי(ם); p אקח', 'footnote-17': '“him”; p (אקח)נו, lig נו/ם', 'footnote-18': '1sg; p ditt/hapl (זרועתי)ו ו(לא); p parall, cf nError: Reference source not found', 'footnote-19': '“destruction”, etym חֶבֶל<subscript 2 >, cf Mic 2<subscript 10 >', 'footnote-20': '“beloved sons”, cf אהבה seq; cf app Amos 9<subscript 7 >', 'footnote-21': '1sg', 'footnote-22': '“(like) a man striking on (his cheeks)”, cf <specialFont ] > Isa 50<subscript 6 >; (a) כמַכּי(ם) and hapl (עֹל) עַל; cf common collocation הִכָּה עַל לחי e.g. Mic 4<subscript 14 > 1Kgs 22<subscript 24 >; (b) dupl transl of כחבל(י) אדם (etym <specialFont \\\\ >חבל Aram and RH “to injure [by striking]”), note <specialFont ]h > ῥαπίζων ἄνθρωπον “one striking a man” (אדם taken as object)', 'footnote-23': '“off their neck”, cf <specialFont [ > Job 39<subscript 10 >; picture of removing yoke from the neck, cf e.g. Gen 27<subscript 40 > Jer 30<subscript 8 >; cf <specialFont T >', 'footnote-24': '3sg, parall seq', 'footnote-25': 'p אַבֵּט, p exeg; <specialFont *[ > etym <specialFont \\\\ >נטה (=<specialFont x >?)', 'footnote-26': '3pl, parall prec', 'footnote-27': '“food”; p אוֹכֶל; p אוֹכִיל taken as noun (etym <specialFont \\\\ >אכל), cf e.g. Qimḥi', 'footnote-28': '“so that he should eat”, etym <specialFont \\\\ >אכל', 'footnote-29': 'אוּכַל לוֹ (<specialFont \\\\ >יכל)', 'footnote-30': '3plm (cf nError: Reference source not found), parall v<subscript 4 > and מאנו seq', 'footnote-31': '“Ephraim dwelt in”, ex <specialFont ] > 9<subscript 3 >; cf app v<subscript 7 > 9<subscript 3 >', 'footnote-32': '3sg (main evid), parall ישוב prec', 'footnote-33': 'different derivations of <specialFont \\\\ >חל; cf app 8<subscript 10 >', 'footnote-34': '“it became ill”, etym <specialFont \\\\ >חלה', 'footnote-35': 'but <specialFont ~ ><subscript Hier > irruet “it will break in”', 'footnote-36': '“it will pierce”, etym <specialFont \\\\ >חלל<subscript 1 >', 'footnote-37': '“it began”, etym <specialFont \\\\ >חלל<subscript 3 >', 'footnote-38': '“it will occur”, etym <specialFont \\\\ >חול, cf <specialFont T > Ezek 30<subscript 4 >', 'footnote-39': '3plm (cf nError: Reference source not found)', 'footnote-40': 'voc וכָלתה', 'footnote-41': 'lexic diffic in context', 'footnote-42': 'understood as בְיָדָיו (for בד = ב+יד cf HALOT 383b s.v. יד)', 'footnote-43': '“his arms”, usus for בד, cf <specialFont 9 > Isa 16<subscript 6 > Jer 48<subscript 30 > 50<subscript 36 > Ezek 19<subscript 14 >', 'footnote-44': '“his chosen ones”; (a) exeg (parall capita seq), cf <specialFont ~ > Jer 48<subscript 30 >, <specialFont [ > Ezek 19<subscript 14 >; (b) hardly בריו (for <specialFont \\\\ >בר[ר] <specialFont J > elect- cf e.g. Amos 5<subscript 11 > Zeph 3<subscript 9 >), but Hier 125<subscript 196 > reads baddau', 'footnote-45': '“their warriors”, slot, cf e.g. <specialFont T > Isa 37<subscript 24 > Jer 2<subscript 16 >, <specialFont T ><superscript N,F > Num 24<subscript 8 >', 'footnote-46': '3pl, cf nError: Reference source not found', 'footnote-47': '“his princes”, parall גיברוהי (cf e.g. <specialFont T > Jer 26<subscript 21 > Ezek 39<subscript 18 >); note Hier 125<subscript 19 ><subscript 7 >: (electos et) principes', 'footnote-48': '“their heads (i.e. leaders)”, parall electos prec (see nError: Reference source not found); see Hier 125<subscript 198 >: vel capita vel consilia eorum (for consilium <specialFont J > מועצה cf Ps 5<subscript 11 > 81<subscript 13 > Prov 1<subscript 31 >)', 'footnote-49': '3sg, cf vv<subscript 5–6 >, cf nError: Reference source not found', 'footnote-50': '“dwelling place”, etym <specialFont \\\\ >ישב (cf <specialFont Th >); cf app v<subscript 5 > 9<subscript 3 > 14<subscript 5 >', 'footnote-51': '“(to return) to me”, cf e.g. Rashi', 'footnote-52': '3sg, cf nError: Reference source not found', 'footnote-53': 'אֵל עַל; for אֶל/אֵל cf e.g. app Jer 50<subscript 29 >', 'footnote-54': 'אֶל עֹל; cf app 7<subscript 16 >; for עֹל cf v<subscript 4 >', 'footnote-55': '“hard oppression” (cf <specialFont T > Mic 6<subscript 3 >), see Joosten, VT 51 (2001), 552–555; apt for עֹל', 'footnote-56': 'עֹל; p hapl (אל) על', 'footnote-57': 'אֶל אֵל; cf e.g. <specialFont [ > Jon 3<subscript 8 > (<specialFont J > אֶל אלהים)', 'footnote-58': 'different derivations of <specialFont \\\\ ><specialFont קר > in Vrs', 'footnote-59': '“his precious things”, etym <specialFont \\\\ >יקר; nom/verb', 'footnote-60': '<specialFont \\\\ >קרה/קרא<subscript 2 > “to befall”; p יקרֵ(א)הו', 'footnote-61': '“they will encounter”, <specialFont \\\\ >קרה/קרא<subscript 2 >; p יִקָּר(א)וּ', 'footnote-62': '“(the yoke) will be laid upon him”; iugum + (in)ponere common collocation, cf e.g. <specialFont * > 1Sam 6<subscript 7 >; cf nError: Reference source not found', 'footnote-63': '3sg', 'footnote-64': 'יִחַר (ד/ר)', 'footnote-65': '“and he/it will think”', 'footnote-66': '<specialFont ] > 3sg, parall prec; <specialFont ~| > 3pl, p יְרִימֵם', 'footnote-67': 'coniug (יְרוֹמַם); cf Isa 33<subscript 10 > Ps 75<subscript 11 >', 'footnote-68': '“they will (not) walk erect”; cf <specialFont T > Mic 2<subscript 3 > (<specialFont J > תלכו רוֹמָה), cf also <specialFont T > Zech 2<subscript 4 > <specialFont T ><superscript PsJ,N,F > Lev 26<subscript 13 >', 'footnote-69': '“I will assist you”, parall ܐܥܕܪܟ seq (cf nError: Reference source not found); for ܥܕܪ + ܣܝܥ cf e.g. <specialFont [ > Isa 25<subscript 4 > 31<subscript 4 > Ps 28<subscript 7 > 33<subscript 20 > (<specialFont J > עזרנו ומגננו)', 'footnote-70': '“I will destroy you ... I will make you perish”, ex context (destruction of Sodom, cf Gen 19); for אובד + שיצי cf e.g. <specialFont T > Isa 26<subscript 14 > (<specialFont J > ותשמידם ותאבּד), Mic 5<subscript 9 > (<specialFont J > והכרַתי ... והאבדתי); <specialFont Th > א(י)בדרינך “I will disperse you” inner-Aram', 'footnote-71': '“I will shield”, etym מָגֵן, cf <specialFont ]* > Prov 4<subscript 9 >', 'footnote-72': '“I will help you”; for מָגֵן <specialFont J > <specialFont \\\\ >ܥܕܪ cf e.g. Ps 84<subscript 12 > 2Sam 22<subscript 31 > || Ps 18<subscript 31 >; cf nError: Reference source not found', 'footnote-73': '“I will disarm”, etym מָגֵן (Piel privativum)', 'footnote-74': 'struct connected to <specialFont & > seq', 'footnote-75': 'see nError: Reference source not found', 'footnote-76': 'for (נכמרו) רחמים cf Gen 43<subscript 30 > 1Kgs 3<subscript 26 >', 'footnote-77': 'cf <specialFont : > Isa 63<subscript 15 > Gen 43<subscript 30 >', 'footnote-78': '“according to”, cf Ezek 25<subscript 14 >', 'footnote-79': '“I will (not) abandon (Ephraim to be destroyed)”; (a) אעזב (see Schleusner 2:228), either ע/ש (cf app 8<subscript 1 >) and ו/ז (cf app Hag 2<subscript 19 >) or <specialFont # > אשֻב (lig עז/ש, cf e.g. Neh 11<subscript 11 > שריה || 1Chr 9<subscript 11 > עזריה); (b) exeg, cf Deut 31<subscript 17 >', 'footnote-80': 'parall (אל) אנכי prec', 'footnote-81': '1sg (cf v<subscript 9 >)<subscript ,  >but p inner-Grk <specialFont # > πορεύσονται (=<specialFont x >)', 'footnote-82': '(תֵ)לְכוּ', 'footnote-83': '3pl, parall ילכו', 'footnote-84': '“(the exiles) will gather”, cf picture v<subscript 11 >; cf <specialFont T > Mic 7<subscript 12 >', 'footnote-85': 'voc מַיִם; for <specialFont x > מִיָּם / <specialFont ] > מַיִם cf app Amos 8<subscript 12 > Mic 7<subscript 12 > Nah 3<subscript 8 > Zech 9<subscript 10 > (cf also 1Kgs 18<subscript 44 >); cf Hier 128<subscript 340–342 >', 'footnote-86': '“nation”, cf Isa 7<subscript 8 >; p inner-Syr <specialFont # > ܝܡܐ (<specialFont [h > according to Gelston, Peshiṭta, 94)', 'footnote-87': '“they will fly away”, for picture cf 9<subscript 11 >; p inner-Grk <specialFont # > <specialFont ]- > ἐκστήσονται (=<specialFont x >)', 'footnote-88': '“they will come”, cf Isa 27<subscript 13 >', 'footnote-89': 'p (ו)הֲשִׁבֹתִי(ם) <specialFont 7 > prep; p <specialFont \\\\ >שוב/<specialFont \\\\ >ישב, for reverse case cf app vv<subscript 5,7 >'}\n",
      "\n",
      "\n",
      "Results for Hosea.12.docx:\n",
      "\n",
      "Main Text: {'title_and_chapter': 'Hosea 12', 'content': {'app-1': '1] <specialFont ]*> 11<subscript 12>', 'app-2': '<specialFont ,>ויהודה<specialFont v>] <specialFont ]> <specialFont ,>καὶ Ιουδα<specialFont v><ref 2> = <specialFont [>', 'app-3': 'עֹד רָד עִם (אֵל)] <specialFont ]> νῦν ἔγνω αὐτούς<ref 3> | <specialFont *> testis descendit cum<ref 4>| <specialFont [> ܥܕܡܐ ܕܢܚܬ ܥܡܗ (ܕܐܠܗܐ)<subscript II><ref 5> <specialFont +> <specialFont T>', 'app-4': 'רָד] <specialFont ~> ἐπικρατῶν/ἐπικράτειαν<ref 6> ', 'app-5': 'ו(עם)] <specialFont [> >', 'app-6': '(וְ)עִם] <specialFont ]> λαός<subscript II><ref 7> = <specialFont [T>', 'app-7': 'נאמן] <specialFont [> <specialFont &><ref 8> | <specialFont ]-> κεκλήσεται<ref 9> <specialFont +> <specialFont ]h> <specialFont +> <specialFont T> מתקרן (עמא קדישא) בכין הוו קיימין<ref 10>| <specialFont ]> + θεοῦ<ref 11> ', 'app-8': '2 אפרים] <specialFont ]> connect', 'app-9': 'רעה – קדים] <specialFont T> diff<ref 12>', 'app-10': 'רֹעֶה] <specialFont ]> πονηρόν<ref 13>', 'app-11': 'וְרֹדֵף] <specialFont ]> ἐδίωξε<ref 14>', 'app-12': '(ו)שֹׁד] <specialFont ]> μάταια<ref 15>', 'app-13': '(ו)שמן] <specialFont T> קורבנא<ref 16>', 'app-14': 'יוּבל] <specialFont *[T> diath<ref 17>', 'app-15': '3 ו(לפקד)] <specialFont ]> ><subscript IV>', 'app-16': 'כמעלליו] <specialFont ]*[Th> <specialFont &><subscript II III>', 'app-17': 'ישיב] <specialFont ]h> pers<subscript III><ref 18>', 'app-18': '4 ובאונו lex] <specialFont ]> κόποις<ref 19>', 'app-19': 'שׂרה] <specialFont *> directus est<ref 20> = <specialFont ~>', 'app-20': 'אלהים] <specialFont *> angelo<ref 21> = <specialFont ~><specialFont T>', 'app-21': '5 וישׂר] <specialFont ~|> ܘܬܪܨ<ref 22> | <specialFont [> ><ref 23>', 'app-22': 'מלאך] <specialFont ~><specialFont |> ܐܠܗܐ<ref 24>', 'app-23': 'בכה ויתחנן] <specialFont ]-> pers<ref 25> | <specialFont [> ܘܒܥܐ<ref 26>', 'app-24': 'לו] <specialFont ]> μου<ref 27>', 'app-25': '(בית) אל] <specialFont ]-> Ων<ref 28> | <specialFont ]h> (ἐν τῷ οἴκῳ) μου<ref 29>', 'app-26': 'ימצא(נו)] <specialFont ]-> pers<subscript III><ref 30>', 'app-27': '(ימצא)נוּ] <specialFont ]> με<ref 31>', 'app-28': 'ידבר] <specialFont ]><specialFont -> diath<ref 32>', 'app-29': 'עמנו] <specialFont ]-> πρὸς αὐτόν<ref 33> = <specialFont [><ref 34> | <specialFont ]><specialFont h> πρὸς αὐτούς<ref 35>', 'app-30': '6 (ו)יהוה אלהי צבאות] <specialFont ]h> div', 'app-31': 'יהוה] <specialFont ]> ἔσται<ref 36> | <specialFont [> > ', 'app-32': 'זִכְרוֹ] <specialFont [> ܐܬܕܟܪܗ<ref 37> <specialFont +> <specialFont |>', 'app-33': '7 (ו)קוה] <specialFont ]><specialFont h> ἔγγιζε<ref 38>', 'app-34': 'אלהיך] <specialFont ]><specialFont h> div', 'app-35': '9 אוֹן]<ref 39> <specialFont ]> ἀναψυχήν<ref 40>', 'app-36': 'יגיעַי] <specialFont [Th> num<ref 41> | <specialFont ]T> pron<ref 42>', 'app-37': 'ימְצְאו] <specialFont ]> εὑρεθήσονται<ref 43>', 'app-38': 'לִי<superscript 2>] <specialFont ]T> pron<ref 44>', 'app-39': 'עון] <specialFont ][> prep', 'app-40': 'חֵטְא] <specialFont ]> ἥμαρτεν<ref 45> | <specialFont *> peccavi<ref 46> = <specialFont [>', 'app-41': '10 אלהיך] <specialFont ]h> > pron', 'app-42': 'מארץ] <specialFont ]> pr ἀνήγαγόν σε<subscript II><ref 47><subscript  ><specialFont +> <specialFont [Th><ref 48>', 'app-43': 'כ(ימי)] <specialFont ]h> καθὼς ἐν<ref 49> = <specialFont *> ', 'app-44': '(כ)ימי] <specialFont ]-> num<subscript III><ref 50> ', 'app-45': '11 על] <specialFont [T> prep', 'app-46': 'הנביאים<superscript 1><superscript , ><superscript 2>] <specialFont ]-> det', 'app-47': 'חזון] <specialFont [> + pron<ref 51>', 'app-48': 'אֲדַמֶּה] <specialFont ]> ὡμοιώθην<ref 52> = <specialFont *[>', 'app-49': '12 אם – זבחו] <specialFont [> reformul<ref 53>', 'app-50': 'גלעד] <specialFont *h> Galgal<ref 54>', 'app-51': 'אָוֶן] <specialFont ]> μὴ … ἔστιν<ref 55>', 'app-52': '<specialFont v>היו] <specialFont ]> ἦσαν<specialFont ,>', 'app-53': '(ב)גלגל] <specialFont ]h><subscript  >Γαλααδ<subscript IV><ref 56>', 'app-54': 'שְׁוָרים] <specialFont ]> ἄρχοντες<ref 57>', 'app-55': 'מזבחותם] <specialFont [> pron<ref 58>', 'app-56': '(כ)גלים] <specialFont ]> χελῶναι<ref 59> = <specialFont [>', 'app-57': 'תלמי]<ref 60> <specialFont ]> χέρσον = <specialFont [> | <specialFont T> תחומי', 'app-58': '14 (מ)מצרים] <specialFont ]h> pr γῆς<ref 61> = <specialFont [h>', 'app-59': '15 הכעיס] <specialFont ]h> + με<ref 62> = <specialFont *>', 'app-60': 'תמרורים] <specialFont ]> καὶ παρώργισε<ref 63> <specialFont +> <specialFont [> | <specialFont T> <specialFont מוספין למחטי><ref 64> | <specialFont *> + pron<ref 65>', 'app-61': 'לו] <specialFont ]h> >', 'app-62': 'אדניו] <specialFont ]-> > pron'}}\n",
      "\n",
      "Footnotes: {'footnote-1': 'cf Ezek 9<subscript 9 > 2Sam 12<subscript 8 >', 'footnote-2': 'עַתָּ(ה) יְדָעָם', 'footnote-3': 'עֵד רָד עִם (<specialFont \\\\ >ירד)', 'footnote-4': 'עַד רָד עַם (אֵל) (<specialFont \\\\ >ירד), cf app Jon 4<subscript 2 >', 'footnote-5': '“overpowering”, usus for <specialFont \\\\ >רדה in <specialFont ~ >', 'footnote-6': 'עַם <specialFont 7 > struct, cf seq', 'footnote-7': 'taken as second attribute of ܥܡܐ (cf nError: Reference source not found)', 'footnote-8': 'p נאמר, cf 2<subscript 1 > [<specialFont ] > 1<subscript 10 >]; for נ/ר cf e.g. app Isa 48<subscript 10 >, <specialFont ] > Josh 19<subscript 29 >', 'footnote-9': 'p dupl: מתקרן <specialFont J > נאמר (cf <specialFont ] >), הוו קיימין <specialFont J > נאמן (=<specialFont x >)', 'footnote-10': '“of God”; for similar struct cf 2Macc 6<subscript 2 >; p exeg, cf Deut 28<subscript 9 ><subscript – ><subscript 10 >; p parall אֵל prec', 'footnote-11': 'ex 8<subscript 7 >', 'footnote-12': 'voc רָעָה; cf רוח רָעָה Judg 9<subscript 23 > 1Sam 16<subscript 14,23 >', 'footnote-13': 'p יִרְדֹּף (ו/י); note verbs seq', 'footnote-14': '“vanities”; (a) slot, κενά + μάταια common collocation, cf e.g. Mic 1<subscript 14 > (<specialFont J > אכזיב לאכזב) Isa 30<subscript 7 >; (b) שָׁוְ(א), for ד/ו cf app 10<subscript 12 > (ועת), for כזב//שוא cf e.g. Ezek 16<subscript 6–9 >; cf app 5<subscript 11 > (צו)', 'footnote-15': '“tribute, offering”; apt, cf e.g. <specialFont T > 10<subscript 6 > (<specialFont J > יוּבָל מנחה) Ps 76<subscript 12 > (<specialFont J > יובילו שי)', 'footnote-16': 'but p יוֹבִל(וּ), note pers in Vrs prec', 'footnote-17': '1sg, cf 4<subscript 9 >; for reverse case cf app Hab 2<subscript 1 >', 'footnote-18': 'taken as construct of אָוֶן; similarly <specialFont ] > Ps 78<subscript 51 > 105<subscript 36 >', 'footnote-19': 'etym <specialFont \\\\ >ישׁר, cf app v<subscript 5 > (וישׂר)', 'footnote-20': 'ex v<subscript 5 > מלאך, cf nError: Reference source not found', 'footnote-21': 'etym <specialFont \\\\ >ישׁר, cf app v<subscript 4 > (שׂרה)', 'footnote-22': 'reduct שׂרה ... וישׂר', 'footnote-23': 'ex v<subscript 4 > אלהים, cf nError: Reference source not found', 'footnote-24': '3pl, cf nError: Reference source not found', 'footnote-25': '“and he beseeched”; p condens (cf Dan 6<subscript 12–13 >); hardly inner-Syr hapl <specialFont # > ܘܒܟܐ ܘܒܥܐ', 'footnote-26': 'לי (ו/י)', 'footnote-27': 'similarly <specialFont ]h ><specialFont * > Josh 8<subscript 12 >; cf app 4<subscript 15 >, cf Amos 5<subscript 5 >', 'footnote-28': \"“(in) my (house)”; (a) apt, God as speaker in context (cf nnError: Reference source not found,Error: Reference source not found); (b) hardly בית אל <specialFont $ > בית י' (abbrev) <specialFont $ > ביתִי, cf <specialFont ] > Judg 19<subscript 18 >\", 'footnote-29': '3pl, cf nError: Reference source not found', 'footnote-30': '-נִי, cf nnError: Reference source not found,Error: Reference source not found', 'footnote-31': 'theol', 'footnote-32': 'עִמוֹ', 'footnote-33': 'parall ܐܫܟܚܗ (=<specialFont x >) prec', 'footnote-34': 'עמם (lig נו/ם)', 'footnote-35': 'יִהְיֶה, cf app Joel 4<subscript 11 > Ezek 48<subscript 10,35 >; cf Ezra 1<subscript 3 > (יְהִי אלהיו)  || 2Chr 36<subscript 23 > (יהוה אלהיו)', 'footnote-36': 'p voc זְכָרוֹ', 'footnote-37': '“approach!”, all evid; inner-Grk <specialFont ]h > ΕΝΓΙΖΕ (sic! see Ziegler, “Einleitung”, 118) <specialFont # > <specialFont ]- > ΕΛΠΙΖΕ (=<specialFont x >)', 'footnote-38': 'understood as אָוֶן in <specialFont ~*[T >, cf v<subscript 12 >; cf app v<subscript 4 >', 'footnote-39': '“respite (from toil)”; apt, cf Judg 15<subscript 19 >, cf seq', 'footnote-40': 'pl in <specialFont x > only here', 'footnote-41': '<specialFont ] > 3sg, <specialFont T > 2plm; cf nError: Reference source not found', 'footnote-42': 'p coniug יִמָּצְאוּ', 'footnote-43': '<specialFont ] > 3sg, <specialFont T > 2plm; cf nError: Reference source not found', 'footnote-44': 'p חָטָא; p nom/verb', 'footnote-45': 'nom/verb (1sg)', 'footnote-46': 'המעלך; formula, cf Ps 81<subscript 11 > Lev 11<subscript 45 >, cf also v<subscript 14 > Amos 2<subscript 10 > et al; similarly app 13<subscript 4 >', 'footnote-47': 'note <specialFont T- > דאפיקתך, alternative formula המוציא מארץ מצרים, cf Exod 20<subscript 2 > || Deut 5<subscript 6 >; similarly <specialFont Th > 13<subscript 4 > Deut 20<subscript 1 > Jer 2<subscript 6 >, <specialFont [ > 2Kgs 17<subscript 7 >, <specialFont ] > Exod 32<subscript 1,7 > et al; cf app 2<subscript 17 >', 'footnote-48': 'cf app 2<subscript 5 > 9<subscript 9 >', 'footnote-49': 'cf 9<subscript 5 > Lam 2<subscript 7,22 >', 'footnote-50': '1sg', 'footnote-51': 'p voc אֶדַּמֶּה (coniug), cf Isa 14<subscript 14 >; p exeg, cf Rashi', 'footnote-52': 'ܒܓܠܥܕ ܟܐ̈ܒܐ ܘܒܓܠܓܠܐ ܠܣܪܝܩܘܬܐ ܕܒܚܬܘܢ ܬܘܪ̈ܐ “Pain in Gilead, and in Gilgal you (pl) sacrificed bulls in vain”', 'footnote-53': 'main evid, contrast app seq, note Hier 138<subscript 253 > = <specialFont x >; similarly app 6<subscript 8 >', 'footnote-54': 'אין (ו/י), cf app Amos 5<subscript 5 > Zech 10<subscript 2 >; accentuation according to Rahlfs', 'footnote-55': 'main evid, cf prec; for reverse case cf app prec', 'footnote-56': 'שָׂרים', 'footnote-57': '2plm', 'footnote-58': '“tortoises, tortoise shells” (lit.), “mounds” (fig.); exeg, cf Qoh 12<subscript 6 > גֻלת <specialFont J > <specialFont | > χελώνη; cf Sifra šemini 3:1 (49c): את הגלים ואת הצפרדעים, cf also <specialFont 9h > βάτραχοι “frogs”; see ArComp 2:280–281', 'footnote-59': 'similarly app 10<subscript 4 >', 'footnote-60': 'cf v<subscript 10 > 13<subscript 4 >', 'footnote-61': '“me”, similarly e.g. <specialFont ]* > 2Kgs 21<subscript 6 > 23<subscript 19 > Ps 106<subscript 29 >', 'footnote-62': '“and he angered”, nom/verb; for ὀργίζειν <specialFont J > <specialFont \\\\ ><specialFont מר ><specialFont ( ><specialFont ה ><specialFont / ><specialFont ר >) cf Dan 11<subscript 11 >; cf also <specialFont \\\\ >מרה <specialFont J > ܡܪܡܪ <specialFont [ > 14<subscript 1 > et al; parall prec', 'footnote-63': 'ex 13<subscript 2 >', 'footnote-64': '3sg, parall seq'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "\n",
    "# Define the folder containing the .docx files\n",
    "folder_path = 'Hosea.App.1'\n",
    "\n",
    "# Dictionary to store results for each file\n",
    "all_results = {}\n",
    "\n",
    "# Iterate over each .docx file in the folder\n",
    "for filename in os.listdir(folder_path)[:4]:\n",
    "    if filename.endswith('.docx'):\n",
    "        docx_path = os.path.join(folder_path, filename)\n",
    "          \n",
    "        # Process footnotes and main text\n",
    "        footnotes_dict = process_footnotes(docx_path)\n",
    "        main_text_dict = process_main_text(docx_path)\n",
    "        \n",
    "        # Store results for this file\n",
    "        all_results[filename] = {\n",
    "            'footnotes': footnotes_dict,\n",
    "            'main_text': main_text_dict\n",
    "        }\n",
    "\n",
    "# Display results\n",
    "for file, data in all_results.items():\n",
    "    print(f\"Results for {file}:\")\n",
    "    print(\"\\nMain Text:\", data['main_text'])\n",
    "    print(\"\\nFootnotes:\", data['footnotes'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81aacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Footnote ID -1: \n",
      "\n",
      "Footnote ID 0: \n",
      "\n",
      "Footnote ID 1:  cf app Mic 1<subscript 1 >\n",
      "\n",
      "Footnote ID 2:  (a) voc דְּבַר (יהוה), formula, cf v<subscript 1 > 4<subscript 1 > et al; cf app 13<subscript 1 >; cf תחלת דִּבְרֵי Qoh 10<subscript 13 >; note seq; (b) noun דִּבֵּר, cf app Jer 5<subscript 13 > and Rabb Heb; cf gerund in <specialFont * > loquendi “of speaking”\n",
      "\n",
      "Footnote ID 3:  “to”; main evid, cf v<subscript 1 >\n",
      "\n",
      "Footnote ID 4:  “which was to”, ex v<subscript 1 >\n",
      "\n",
      "Footnote ID 5:  “for himself”, cf v<subscript 2 >\n",
      "\n",
      "Footnote ID 6:  cf vv<subscript 6,8 >; contrast Hier 10<subscript 154 >\n",
      "\n",
      "Footnote ID 7:  main evid; inner-Grk (בית יהודה common collocation), cf Hier 12<subscript 208−211 >\n",
      "\n",
      "Footnote ID 8:  voc הֲשִׁבֹתִי, similarly app 2<subscript 13 > Ezek 7<subscript 24 >; for parall השיב//פקד cf 4<subscript 9 > 12<subscript 3 >; main evid <specialFont ]h ><subscript   >καταπαύσω (=<specialFont x >)\n",
      "\n",
      "Footnote ID 9:  common formula השבית מן, cf e.g. Lev 26<subscript 6 > Jer 7<subscript 34 >\n",
      "\n",
      "Footnote ID 10:  formulaic change, cf app Joel 4<subscript 18 > Mic 5<subscript 9 > et al\n",
      "\n",
      "Footnote ID 11:  “says the Lord”, formula (נאם יהוה), cf 2<subscript 18,23 > et al\n",
      "\n",
      "Footnote ID 12:  “the Lord”, cf v<subscript 4 >, app v<subscript 9 > (ויאמר)\n",
      "\n",
      "Footnote ID 13:  1sg, cf 3<subscript 1 >\n",
      "\n",
      "Footnote ID 14:  “opposing I shall oppose” (= <specialFont ] > 1Kgs 11<subscript 34 >); p etym <specialFont \\ > נשׁא“oppress, set against” (cf Ps 89<subscript 23 >), cf Obad <subscript 7 > הִשִּׁיאוּךָ <specialFont J > <specialFont ] > ἀντέστησάν σοι “they opposed you” (for interchange of ἀντιτάσσεσθαι “to oppose” / ἀνθίστασθαι “to stand against” cf <specialFont ] ><specialFont i > 4Macc 16<subscript 23 >); cf also Jer 49<subscript 16 > הִשִּׁיא = <specialFont ] > [29<subscript 17 >] ἐνεχείρησε “(it) attacked” (contrast etym <specialFont \\ >נשׂא<specialFont  ~9 > and <subscript p >Obad <subscript 3 > <specialFont ] >) \n",
      "\n",
      "Footnote ID 15:  “by forgetfulness I shall forget”, etym <specialFont \\ >נשׁה, contrast app Jer 23<subscript 39 >\n",
      "\n",
      "Footnote ID 16:  “sons (of)”, for בני/בית cf app Amos 1<subscript 5 > 3<subscript 1 > Zeph 1<subscript 8 >  \n",
      "\n",
      "Footnote ID 17:  p (ו)ברכב; common collocation, cf e.g. Ezek 26<subscript 7 > בסוס וברכב ובפרשים\n",
      "\n",
      "Footnote ID 18:  “again”, cf v<subscript 6 >\n",
      "\n",
      "Footnote ID 19:  “(to) him”, cf v<subscript 3 >\n",
      "\n",
      "Footnote ID 20:  “the Lord (to him)”, cf app v<subscript 6 > (לו); for <specialFont [ > pron cf n14\n",
      "\n",
      "Footnote ID 21:  “God”, cf e.g. Exod 6<subscript 7 > Lev 26<subscript 12 > Zech 8<subscript 8 >; note diverse word-order in <specialFont ]h >\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#process footnotes\n",
    "# Path to the .docx file\n",
    "docx_path = 'Hosea.1.App I.Full.docx'\n",
    "\n",
    "# Dictionary to store footnote data\n",
    "footnotes_dict = {}\n",
    "\n",
    "# Step 1: Extract the footnotes XML from the .docx file\n",
    "with zipfile.ZipFile(docx_path, 'r') as docx:\n",
    "    # Look for footnotes XML part\n",
    "    if 'word/footnotes.xml' in docx.namelist():\n",
    "        footnote_xml = docx.read('word/footnotes.xml').decode('utf-8')\n",
    "    else:\n",
    "        print(\"No footnotes.xml found in this document.\")\n",
    "        footnote_xml = None\n",
    "\n",
    "# Step 2: Parse the footnote XML and store in dictionary\n",
    "if footnote_xml:\n",
    "    root = ET.fromstring(footnote_xml)\n",
    "    namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "    \n",
    "    for footnote in root.findall('w:footnote', namespaces):\n",
    "        footnote_id = footnote.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "        footnote_text = \"\"\n",
    "        \n",
    "        # Extract each run's text, font, and superscript/subscript information in the footnote\n",
    "        for run in footnote.findall('.//w:r', namespaces):\n",
    "            text_elem = run.find('w:t', namespaces)\n",
    "            font_elem = run.find('.//w:rPr//w:rFonts', namespaces)\n",
    "            vert_align_elem = run.find('.//w:rPr//w:vertAlign', namespaces)\n",
    "            \n",
    "            if text_elem is not None:\n",
    "                text = text_elem.text\n",
    "                font = font_elem.get(f'{{{namespaces[\"w\"]}}}ascii') if font_elem is not None else \"Unknown\"\n",
    "                \n",
    "                # Check for superscript or subscript alignment\n",
    "                if vert_align_elem is not None:\n",
    "                    align_val = vert_align_elem.get(f'{{{namespaces[\"w\"]}}}val')\n",
    "                    if align_val == \"superscript\":\n",
    "                        text = f\"<superscript {text} >\"\n",
    "                    elif align_val == \"subscript\":\n",
    "                        text = f\"<subscript {text} >\"\n",
    "\n",
    "                # Wrap the text in <specialFont ...> if it’s in the special font\n",
    "                if font == \"HUBPSigla\":  # Replace with your actual font name if different\n",
    "                    footnote_text += f\"<specialFont {text} >\"\n",
    "                else:\n",
    "                    footnote_text += text\n",
    "\n",
    "        # Store the formatted text in the dictionary with footnote_id as the key\n",
    "        footnotes_dict[footnote_id] = footnote_text\n",
    "\n",
    "# Print the final dictionary to verify\n",
    "for fid, ftext in footnotes_dict.items():\n",
    "    print(f\"Footnote ID {fid}: {ftext}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec416d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Text Dictionary with Formatting:\n",
      "app-1: Hosea 1\n",
      "\n",
      "app-2: \n",
      "\n",
      "app-3: 1 יותם אחז יחזקיה] <specialFont ]><specialFont [> <specialFont &>\n",
      "\n",
      "app-4: מלכי] <specialFont ]><specialFont h> num<subscript II><ref 1>\n",
      "\n",
      "app-5: 2 דִּבֶּר] <specialFont ]> λόγου<ref 2> = <specialFont [><specialFont T>\n",
      "\n",
      "app-6: ב(הושע)] <specialFont ]h> πρός<ref 3> <specialFont +> <specialFont [>ܕܗܘܐ ܥܠ<ref 4>\n",
      "\n",
      "app-7: ו(יאמר)] <specialFont ]h><specialFont [> >\n",
      "\n",
      "app-8: לֵךְ] <specialFont ]h> ><subscript II>\n",
      "\n",
      "app-9: 3 ויקח] <specialFont [> + ܠܗ<ref 5>\n",
      "\n",
      "app-10: לו] <specialFont ]h><specialFont *><specialFont -> ><subscript II III><subscript  IV><ref 6>\n",
      "\n",
      "app-11: 4 יהוא] <specialFont ]h> Ιουδα<ref 7>\n",
      "\n",
      "app-12: (ו)הִשְׁבַּתִּי] <specialFont ]><specialFont -> ἀποστρέψω<ref 8>\n",
      "\n",
      "app-13: בית<superscript 2>] <specialFont ]h*><specialFont h><specialFont T><specialFont -> + prep<ref 9>\n",
      "\n",
      "app-14: 5 והיה (ביום ההוא)] <specialFont [> ><ref 10>\n",
      "\n",
      "app-15: (ו)היה] <specialFont *> >\n",
      "\n",
      "app-16: ההוא] <specialFont ]h> + dicit dominus<ref 11>\n",
      "\n",
      "app-17: 6 עוד<superscript 1>] <specialFont *><specialFont hT><specialFont -> ><subscript II><subscript  III IV>\n",
      "\n",
      "app-18: לו] <specialFont ]h> + κύριος<subscript II><ref 12> = <specialFont [>| <specialFont [> pron<ref 13>\n",
      "\n",
      "app-19: נשׂא אשׂא] <specialFont ]> ἀντιτασσόμενος ἀντιτάξομαι<ref 14> | <specialFont *> oblivione obliviscar<ref 15> <specialFont +> <specialFont ~>\n",
      "\n",
      "app-20: 7 בית] <specialFont ]> υἱούς<ref 16>\n",
      "\n",
      "app-21: יהודה] <specialFont ]h> >\n",
      "\n",
      "app-22: ולא] <specialFont ][> rep\n",
      "\n",
      "app-23: (ו)במלחמה] <specialFont ]><specialFont -> + (οὐδὲ) ἐν ἅρμασιν<ref 17>\n",
      "\n",
      "app-24: בסוסים] <specialFont ]><specialFont *><specialFont [> <specialFont &><subscript III><subscript  IV>\n",
      "\n",
      "app-25: 8 ותהר] <specialFont ]><specialFont -> + ἔτι<subscript II><ref 18> = <specialFont [>\n",
      "\n",
      "app-26: ותלד] <specialFont ]h> + αὐτῷ<subscript IV><ref 19> = <specialFont *h>\n",
      "\n",
      "app-27: 9 ויאמר] <specialFont ]h> + κύριος (αὐτῷ)<subscript II><ref 20> = <specialFont T><specialFont h> <specialFont +> <specialFont [>\n",
      "\n",
      "app-28: כי – עמי ~ ואנכי – לכם] <specialFont 9> ~\n",
      "\n",
      "app-29: לכם] <specialFont ]h> + θεός<ref 21> = <specialFont *h> <specialFont +><specialFont  ><specialFont [h>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Path to your .docx file\n",
    "docx_path = 'Hosea.1.App I.Full.docx'\n",
    "\n",
    "# Temporary storage for extracted XML content\n",
    "document_xml = None\n",
    "\n",
    "# Step 1: Extract `document.xml` from the .docx file\n",
    "with zipfile.ZipFile(docx_path, 'r') as docx:\n",
    "    if 'word/document.xml' in docx.namelist():\n",
    "        document_xml = docx.read('word/document.xml').decode('utf-8')\n",
    "\n",
    "# Define the WordprocessingML namespace\n",
    "namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "\n",
    "# Initialize a dictionary to store the main text with formatting\n",
    "main_text_dict = {}\n",
    "\n",
    "# Step 2: Parse `document.xml` to identify and tag footnote references, fonts, superscript, and subscript\n",
    "if document_xml:\n",
    "    document_root = ET.fromstring(document_xml)\n",
    "    for i, paragraph in enumerate(document_root.findall('.//w:p', namespaces), start=1):\n",
    "        app_id = f\"app-{i}\"  # Unique ID for each paragraph\n",
    "        paragraph_text = ''#f\"<app ID='{app_id}'>\"\n",
    "        \n",
    "        # Process each run in the paragraph\n",
    "        for run in paragraph.findall('.//w:r', namespaces):\n",
    "            text_elem = run.find('w:t', namespaces)\n",
    "            font_elem = run.find('.//w:rPr//w:rFonts', namespaces)\n",
    "            vert_align_elem = run.find('.//w:rPr//w:vertAlign', namespaces)\n",
    "            footnote_ref = run.find('.//w:footnoteReference', namespaces)\n",
    "            \n",
    "            # Initialize tags for formatting\n",
    "            font_tag_open = \"\"\n",
    "            font_tag_close = \"\"\n",
    "            vert_align_tag_open = \"\"\n",
    "            vert_align_tag_close = \"\"\n",
    "\n",
    "            # Check for special font and wrap in <specialFont ...> if present\n",
    "            if font_elem is not None:\n",
    "                font = font_elem.get(f'{{{namespaces[\"w\"]}}}ascii')\n",
    "                if font == \"HUBPSigla\":  # Replace with your actual font name if needed\n",
    "                    font_tag_open = \"<specialFont \"\n",
    "                    font_tag_close = \">\"\n",
    "\n",
    "            # Check for superscript or subscript\n",
    "            if vert_align_elem is not None:\n",
    "                align_val = vert_align_elem.get(f'{{{namespaces[\"w\"]}}}val')\n",
    "                if align_val == \"superscript\":\n",
    "                    vert_align_tag_open = \"<superscript \"\n",
    "                    vert_align_tag_close = \">\"\n",
    "                elif align_val == \"subscript\":\n",
    "                    vert_align_tag_open = \"<subscript \"\n",
    "                    vert_align_tag_close = \">\"\n",
    "\n",
    "            # Process text and footnote references\n",
    "            if text_elem is not None:\n",
    "                # Wrap the text according to font, superscript, or subscript tags\n",
    "                text_content = f\"{font_tag_open}{vert_align_tag_open}{text_elem.text or ''}{vert_align_tag_close}{font_tag_close}\"\n",
    "                paragraph_text += text_content\n",
    "            \n",
    "            elif footnote_ref is not None:\n",
    "                # Get the ID of the footnote reference and wrap it in <ref ...> tags without content\n",
    "                footnote_id = footnote_ref.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "                paragraph_text += f\"<ref {footnote_id}>\"\n",
    "\n",
    "        # Close the <app> tag for the paragraph\n",
    "#         paragraph_text += \"</app>\"\n",
    "\n",
    "        # Store the formatted paragraph in the dictionary\n",
    "        main_text_dict[app_id] = paragraph_text\n",
    "\n",
    "# Print the formatted dictionary\n",
    "print(\"Main Text Dictionary with Formatting:\")\n",
    "for key, value in main_text_dict.items():\n",
    "    print(f\"{key}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### untill here both the footnotes info and the main text info are stored (fonts, subscript, footnote ref)\n",
    "# now move to processing each entry of the main text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ae9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = []\n",
    "for val in main_text_dict.values():\n",
    "    apps.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec392aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 ויאמר] <specialFont ]h> + κύριος (αὐτῷ)<subscript II><ref 20> = <specialFont T><specialFont h> <specialFont +> <specialFont [>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca89de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_full_entry(text):\n",
    "    sliced_entry = text.split(sep=']', maxsplit=1)\n",
    "    lemma, entry = sliced_entry\n",
    "#         print(f\"lemma: {lemma}\")\n",
    "#         print(f\"entry: {entry}\")\n",
    "    return lemma, entry    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c8b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Entries: [{'classification': 'variant', 'witnesses': ['<specialFont ]h>'], 'reading': {'sigla': '+', 'cleaned_reading': 'κύριος (αὐτῷ)<ref 20>'}, 'cross_references': ['II']}, {'classification': 'synonymous_variant', 'witnesses': ['<specialFont T>', '<specialFont h>'], 'reading': {'sigla': '', 'cleaned_reading': ''}, 'cross_references': []}, {'classification': 'similar_variant', 'witnesses': ['<specialFont [>'], 'reading': {'sigla': '', 'cleaned_reading': ''}, 'cross_references': []}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_initial_sigla(reading):\n",
    "       \n",
    "    # Pattern to match one or more sigla at the start of the reading\n",
    "    sigla_pattern = re.compile(r'^[\\+\\>\\~]+')\n",
    "    \n",
    "    # Dictionary to store extracted sigla and cleaned reading\n",
    "    result = {\n",
    "        'sigla': \"\",\n",
    "        'cleaned_reading': reading.strip()  # Initialize cleaned reading as the full reading\n",
    "    }\n",
    "    \n",
    "    # Find initial sigla if present\n",
    "    match = sigla_pattern.match(reading)\n",
    "    if match:\n",
    "        # Extract sigla and set them in the result dictionary\n",
    "        result['sigla'] = match.group(0)\n",
    "        \n",
    "        # Remove the matched sigla from the beginning of the reading\n",
    "        result['cleaned_reading'] = reading[len(result['sigla']):].strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_cross_references(reading):\n",
    "    # Pattern to find all <subscript ...> tags\n",
    "    subscript_pattern = re.compile(r'<subscript\\s*([^>]+)>')\n",
    "    \n",
    "    # List to store cross-references\n",
    "    cross_references = []\n",
    "    \n",
    "    # Find all matches and extract their contents\n",
    "    matches = subscript_pattern.findall(reading)\n",
    "    for match in matches:\n",
    "        # Split the content by whitespace to handle multiple items in a single tag (e.g., \"II III\")\n",
    "        items = match.split()\n",
    "        cross_references.extend(items)\n",
    "\n",
    "    # Remove duplicates and sort for consistent output\n",
    "    unique_references = sorted(set(cross_references), key=cross_references.index)\n",
    "    \n",
    "    # Clean the reading by removing <subscript ...> tags\n",
    "    cleaned_reading = subscript_pattern.sub('', reading).strip()\n",
    "    \n",
    "    return {\n",
    "        'cross_references': unique_references,\n",
    "        'reading': cleaned_reading\n",
    "    }\n",
    "\n",
    "def parse_and_classify_entry(entry):\n",
    "    # Define splitting characters with classifications\n",
    "    splitters = {\n",
    "        '|': 'additional_variant',\n",
    "        '=': 'synonymous_variant',\n",
    "        ',': 'related_variant',\n",
    "        '<specialFont +>': 'similar_variant'\n",
    "    }\n",
    "    \n",
    "    # Compile regex to split by any of the splitters\n",
    "    splitter_pattern = re.compile(r'(\\||=|<specialFont\\s\\+>)')\n",
    "    \n",
    "    # List to store parsed entries with classifications\n",
    "    parsed_entries = []\n",
    "    \n",
    "    # Split the entry by the main split characters, keeping split characters separate\n",
    "    parts = splitter_pattern.split(entry)\n",
    "    \n",
    "    # Initialize a default classification for the first part\n",
    "    current_classification = \"variant\"\n",
    "\n",
    "    # Process each part separately\n",
    "    for part in parts:\n",
    "        part = part.strip()  # Remove leading/trailing whitespace\n",
    "        \n",
    "        # Skip if the part is a splitter, set classification for the next part\n",
    "        if part in splitters:\n",
    "            current_classification = splitters[part]\n",
    "            continue  # Skip to the next part\n",
    "\n",
    "        # Initialize dictionaries to store witnesses, reading, classification, and cross-references\n",
    "        entry_data = {\n",
    "            'classification': current_classification,\n",
    "            'witnesses': [],\n",
    "            'reading': \"\",\n",
    "            'cross_references': []\n",
    "        }\n",
    "        \n",
    "        # Reset the classification to \"variant\" after using it\n",
    "        current_classification = \"variant\"\n",
    "\n",
    "        # Regex pattern to match <specialFont ...> tags as witnesses\n",
    "        special_font_pattern = re.compile(r'<specialFont\\s*([^>]+)>')\n",
    "        \n",
    "        # Extract initial <specialFont ...> tags as witnesses\n",
    "        i = 0\n",
    "        while i < len(part):\n",
    "            match = special_font_pattern.match(part, i)\n",
    "            if match:\n",
    "                # Add matched <specialFont ...> tag to witnesses\n",
    "                witness = match.group(0)\n",
    "                entry_data['witnesses'].append(witness)\n",
    "                i = match.end()  # Move past the matched tag\n",
    "            else:\n",
    "                # Anything after initial witnesses becomes the reading\n",
    "                entry_data['reading'] = part[i:].strip()\n",
    "                break\n",
    "\n",
    "        # Extract <subscript ...> as cross-references\n",
    "        result = extract_cross_references(entry_data['reading'])\n",
    "\n",
    "#         subscript_pattern = re.compile(r'<subscript\\s*([^>]+)>')\n",
    "#         cross_references = subscript_pattern.findall(entry_data['reading'])\n",
    "        entry_data['cross_references'] = result['cross_references']  # Store cross-references\n",
    "\n",
    "        # Clean the reading text by removing <subscript ...> tags\n",
    "        entry_data['reading'] = result['reading']#subscript_pattern.sub('', entry_data['reading']).strip()\n",
    "        \n",
    "        entry_data['reading'] = extract_initial_sigla(entry_data['reading'])\n",
    "        \n",
    "        # Add entry data to the parsed entries list\n",
    "        parsed_entries.append(entry_data)\n",
    "\n",
    "    return parsed_entries\n",
    "\n",
    "lemma, entry = split_full_entry(apps[-3])\n",
    "parsed_entries = parse_and_classify_entry(entry)\n",
    "\n",
    "# Display results\n",
    "print(\"Parsed Entries:\", parsed_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ab911f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 1,\n",
       " 'verses': 5,\n",
       " 'lemmas': [{'lemma': 'והיה'}, {'lemma': '(ביום'}, {'lemma': 'ההוא)'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now process lemma\\verse\\range\n",
    "lemma, entry = split_full_entry(apps[-16])\n",
    "lemma_dict = lemma_verse_processor(lemma, 1)\n",
    "lemma_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b635d584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verse': 6, 'lemma': 'עוד', 'number': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_lemma_with_superscript(lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8032cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Lemma: {'verse': 6, 'lemma': 'עוד', 'number': 1}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def process_lemma_with_superscript(lemma_text):\n",
    "    # Regex to match verse, lemma, and superscript number\n",
    "    pattern = r'^(\\d+)\\s+([^\\s<]+)(?:<superscript\\s*(\\d+)>)?'\n",
    "    \n",
    "    # Match the pattern\n",
    "    match = re.match(pattern, lemma_text)\n",
    "    if not match:\n",
    "        return None  # Return None if the pattern doesn't match\n",
    "    \n",
    "    # Extract verse, lemma, and superscript number\n",
    "    verse = int(match.group(1))\n",
    "    lemma = match.group(2)\n",
    "    number = int(match.group(3)) if match.group(3) else None\n",
    "    \n",
    "    # Return structured data\n",
    "    return {\n",
    "        'verse': verse,\n",
    "        'lemma': lemma,\n",
    "        'number': number\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "example_lemma = '6 עוד<superscript 1>'\n",
    "processed_data = process_lemma_with_superscript(example_lemma)\n",
    "\n",
    "# Display the result\n",
    "print(\"Processed Lemma:\", processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0404f945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 עוד<superscript 1>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98dab9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_verse_processor(text, chapter):\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    if verses_match:\n",
    "        verse_range = verses_match.group(1).split('–')\n",
    "        if len(verse_range) == 2 and verse_range[0] != verse_range[1]:\n",
    "            verses = {'from': int(verse_range[0]), 'to': int(verse_range[1])}\n",
    "        else:\n",
    "            verses = int(verse_range[0])\n",
    "    else:\n",
    "        verses = None\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    return {\n",
    "        'chapter': chapter,\n",
    "        'verses': verses,\n",
    "        'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(k|q)?\\s*([^\\d\\s]+)(\\d?\\,?\\d?)'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "\n",
    "    # Split lemma if there are separate lemmas with \"/\"\n",
    "    split_lemmas = re.split(r'\\s*/\\s*', lemma) if '/' in lemma else [lemma]\n",
    "    \n",
    "    processed_lemmas = []\n",
    "    for split_lemma in split_lemmas:\n",
    "        processed = process_individual_lemma(split_lemma)\n",
    "        processed_lemmas.extend(processed)\n",
    "    \n",
    "    return processed_lemmas\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "    for match in matches:\n",
    "        prefix, word, number = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if prefix: lemma_dict[prefix] = True\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d6c6730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6 עוד<superscript 1>',\n",
       " ' <specialFont *><specialFont hT><specialFont -> ><subscript II><subscript  III IV>')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_full_entry(apps[-13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2dc7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing functions, including chapter information\n",
    "def process_full_entry(text, chapter, previous_verse=None):\n",
    "    lemma, part_entry = split_full_entry(text)\n",
    "    lemma_dict = lemma_verse_processor(lemma, chapter)\n",
    "\n",
    "#     return lemma_dict, decoded_entries, lemma_dict['verses']\n",
    "    return part_entry\n",
    "\n",
    "def split_on_comma_not_in_parentheses(part):\n",
    "    \"\"\"\n",
    "    Splits the string on ',' not inside parentheses.\n",
    "    \"\"\"\n",
    "    sub_parts = []\n",
    "    current_part = []\n",
    "    paren_depth = 0  # Track depth of parentheses\n",
    "\n",
    "    for char in part:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0:\n",
    "            # At a top-level comma, split here\n",
    "            sub_parts.append(''.join(current_part))\n",
    "            current_part = []\n",
    "            continue\n",
    "\n",
    "        current_part.append(char)\n",
    "\n",
    "    # Add the last part if there's any\n",
    "    if current_part:\n",
    "        sub_parts.append(''.join(current_part))\n",
    "\n",
    "    return sub_parts\n",
    "\n",
    "def split_full_entry(text):\n",
    "    sliced_entry = text.split(sep=']', maxsplit=1)\n",
    "    lemma, entry = sliced_entry\n",
    "#         print(f\"lemma: {lemma}\")\n",
    "#         print(f\"entry: {entry}\")\n",
    "    return lemma, entry    \n",
    "\n",
    "# def lemma_verse_processor(text, chapter):\n",
    "#     # Simplified approach: first split into digits and lemmas\n",
    "#     # Regex to match the verse numbers at the beginning\n",
    "#     verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "#     # Extract verses\n",
    "#     verses_match = re.match(verse_regex, text)\n",
    "#     verses = list(map(int, verses_match.group(1).split('–'))) if verses_match else []\n",
    "    \n",
    "#     # Isolate lemmas part by removing the verses\n",
    "#     lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "#     return {\n",
    "#         'chapter': chapter,\n",
    "#         'verses': verses,\n",
    "#         'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "#     }\n",
    "\n",
    "def lemma_verse_processor(text, chapter):\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    if verses_match:\n",
    "        verse_range = verses_match.group(1).split('–')\n",
    "        if len(verse_range) == 2 and verse_range[0] != verse_range[1]:\n",
    "            verses = {'from': int(verse_range[0]), 'to': int(verse_range[1])}\n",
    "        else:\n",
    "            verses = int(verse_range[0])\n",
    "    else:\n",
    "        verses = None\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    return {\n",
    "        'chapter': chapter,\n",
    "        'verses': verses,\n",
    "        'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(k|q)?\\s*([^\\d\\s]+)(\\d?\\,?\\d?)'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "\n",
    "    # Split lemma if there are separate lemmas with \"/\"\n",
    "    split_lemmas = re.split(r'\\s*/\\s*', lemma) if '/' in lemma else [lemma]\n",
    "    \n",
    "    processed_lemmas = []\n",
    "    for split_lemma in split_lemmas:\n",
    "        processed = process_individual_lemma(split_lemma)\n",
    "        processed_lemmas.extend(processed)\n",
    "    \n",
    "    return processed_lemmas\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "    for match in matches:\n",
    "        prefix, word, number = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if prefix: lemma_dict[prefix] = True\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas\n",
    "\n",
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def extract_cross_references(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def parse_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d.]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def post_process_witnesses(witnesses):\n",
    "    # Define the set of specific values for \"x\"\n",
    "    specific_values = {\"G-B Eb \", \"G-B Kb \", \"G-B Msr \"}  # Replace with the actual values\n",
    "\n",
    "    # Iterate over the witnesses, except for the last one\n",
    "    for i in range(len(witnesses) - 1):\n",
    "        z, y, x = witnesses[i]\n",
    "\n",
    "        # Check if \"x\" is one of the specific values\n",
    "        if x in specific_values:\n",
    "            # Remove \"x\" from the current tuple and prepend it to the \"z\" of the next witness\n",
    "            witnesses[i] = (z, y, '')\n",
    "            next_z, next_y, next_x = witnesses[i + 1]\n",
    "            witnesses[i + 1] = (x + next_z, next_y, next_x)\n",
    "\n",
    "    # Remove the first tuple if it becomes empty\n",
    "    if witnesses and witnesses[0] == ('', '', ''):\n",
    "        witnesses.pop(0)\n",
    "\n",
    "    return witnesses\n",
    "\n",
    "def parse_comma_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d*)?\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~\\.]*)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]*\\s?)[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        \\s*\n",
    "        (?P<GeneralComment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def witness_reading_splitter(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>~.]*\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>~])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Rdg\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n",
    "\n",
    "def process_comma_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Rdg\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac67dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8240bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample structure of doc_content.body_runs:\n",
      "[[[[['\\t', 'Hosea 1'], [], ['1 יותם אחז יחזקיה] ][ &'], ['מלכי] ]h numII', '----footnote1----'], ['2 דִּבֶּר] ] λόγου', '----footnote2----', ' = [T'], ['ב(הושע)] ]h πρός', '----footnote3----', ' + [ܕܗܘܐ ܥܠ', '----footnote4----'], ['ו(יאמר)] ]h[ >'], ['לֵךְ] ]h >II'], ['3 ויקח] [ + ܠܗ', '----footnote5----'], ['לו] ]h*- >II III IV', '----footnote6----'], ['4 יהוא] ]h Ιουδα', '----footnote7----'], ['(ו)הִשְׁבַּתִּי] ]- ἀποστρέψω', '----footnote8----'], ['בית2] ]h*hT- + prep', '----footnote9----'], ['5 והיה (ביום ההוא)] [ >', '----footnote10----'], ['(ו)היה] * >'], ['ההוא] ]h + dicit dominus', '----footnote11----'], ['6 עוד1] *hT- >II III IV'], ['לו] ]h + κύριοςII', '----footnote12----', ' = [| [ pron', '----footnote13----'], ['נשׂא אשׂא] ] ἀντιτασσόμενος ἀντιτάξομαι', '----footnote14----', ' | * oblivione obliviscar', '----footnote15----', ' + ~'], ['7 בית] ] υἱούς', '----footnote16----'], ['יהודה] ]h >'], ['ולא] ][ rep'], ['(ו)במלחמה] ]- + (οὐδὲ) ἐν ἅρμασιν', '----footnote17----'], ['בסוסים] ]*[ &III IV'], ['8 ותהר] ]- + ἔτιII', '----footnote18----', ' = ['], ['ותלד] ]h + αὐτῷIV', '----footnote19----', ' = *h'], ['9 ויאמר] ]h + κύριος (αὐτῷ)II', '----footnote20----', ' = Th + ['], ['\\t', 'כי – עמי ~ ואנכי – לכם] 9 ~'], ['לכם] ]h + θεός', '----footnote21----', ' = *h + [h']]]]]\n"
     ]
    }
   ],
   "source": [
    "from docx2python import docx2python\n",
    "\n",
    "# Path to the .docx file\n",
    "docx_path = 'Hosea.1.App I.Full.docx'\n",
    "\n",
    "# Load the document using docx2python\n",
    "doc_content = docx2python(docx_path)\n",
    "\n",
    "# Print a portion of the structure to examine it\n",
    "print(\"Sample structure of doc_content.body_runs:\")\n",
    "print(doc_content.body_runs[:5])  # Print the first few elements for inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0c8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Document with Footnote References:\n",
      "<p>Hosea 1</p>\n",
      "<p></p>\n",
      "<p>1 יותם אחז יחזקיה] ][ &</p>\n",
      "<p>מלכי] ]h numII<ref 1> cf app Mic 11</ref></p>\n",
      "<p>2 דִּבֶּר] ] λόγου<ref 2> (a) voc דְּבַר (יהוה), formula, cf v1 41 et al; cf app 131; cf תחלת דִּבְרֵי Qoh 1013; note seq; (b) noun דִּבֵּר, cf app Jer 513 and Rabb Heb; cf gerund in * loquendi “of speaking”</ref> = [T</p>\n",
      "<p>ב(הושע)] ]h πρός<ref 3> “to”; main evid, cf v1</ref> + [ܕܗܘܐ ܥܠ<ref 4> “which was to”, ex v1</ref></p>\n",
      "<p>ו(יאמר)] ]h[ ></p>\n",
      "<p>לֵךְ] ]h >II</p>\n",
      "<p>3 ויקח] [ + ܠܗ<ref 5> “for himself”, cf v2</ref></p>\n",
      "<p>לו] ]h*- >II III IV<ref 6> cf vv6,8; contrast Hier 10154</ref></p>\n",
      "<p>4 יהוא] ]h Ιουδα<ref 7> main evid; inner-Grk (בית יהודה common collocation), cf Hier 12208−211</ref></p>\n",
      "<p>(ו)הִשְׁבַּתִּי] ]- ἀποστρέψω<ref 8> voc הֲשִׁבֹתִי, similarly app 213 Ezek 724; for parall השיב//פקד cf 49 123; main evid ]h καταπαύσω (=x)</ref></p>\n",
      "<p>בית2] ]h*hT- + prep<ref 9> common formula השבית מן, cf e.g. Lev 266 Jer 734</ref></p>\n",
      "<p>5 והיה (ביום ההוא)] [ ><ref 10> formulaic change, cf app Joel 418 Mic 59 et al</ref></p>\n",
      "<p>(ו)היה] * ></p>\n",
      "<p>ההוא] ]h + dicit dominus<ref 11> “says the Lord”, formula (נאם יהוה), cf 218,23 et al</ref></p>\n",
      "<p>6 עוד1] *hT- >II III IV</p>\n",
      "<p>לו] ]h + κύριοςII<ref 12> “the Lord”, cf v4, app v9 (ויאמר)</ref> = [| [ pron<ref 13> 1sg, cf 31</ref></p>\n",
      "<p>נשׂא אשׂא] ] ἀντιτασσόμενος ἀντιτάξομαι<ref 14> “opposing I shall oppose” (= ] 1Kgs 1134); p etym \\ נשׁא“oppress, set against” (cf Ps 8923), cf Obad 7 הִשִּׁיאוּךָ J ] ἀντέστησάν σοι “they opposed you” (for interchange of ἀντιτάσσεσθαι “to oppose” / ἀνθίστασθαι “to stand against” cf ]i 4Macc 1623); cf also Jer 4916 הִשִּׁיא = ] [2917] ἐνεχείρησε “(it) attacked” (contrast etym \\נשׂא ~9 and pObad 3 ]) </ref> | * oblivione obliviscar<ref 15> “by forgetfulness I shall forget”, etym \\נשׁה, contrast app Jer 2339</ref> + ~</p>\n",
      "<p>7 בית] ] υἱούς<ref 16> “sons (of)”, for בני/בית cf app Amos 15 31 Zeph 18  </ref></p>\n",
      "<p>יהודה] ]h ></p>\n",
      "<p>ולא] ][ rep</p>\n",
      "<p>(ו)במלחמה] ]- + (οὐδὲ) ἐν ἅρμασιν<ref 17> p (ו)ברכב; common collocation, cf e.g. Ezek 267 בסוס וברכב ובפרשים</ref></p>\n",
      "<p>בסוסים] ]*[ &III IV</p>\n",
      "<p>8 ותהר] ]- + ἔτιII<ref 18> “again”, cf v6</ref> = [</p>\n",
      "<p>ותלד] ]h + αὐτῷIV<ref 19> “(to) him”, cf v3</ref> = *h</p>\n",
      "<p>9 ויאמר] ]h + κύριος (αὐτῷ)II<ref 20> “the Lord (to him)”, cf app v6 (לו); for [ pron cf n14</ref> = Th + [</p>\n",
      "<p>כי – עמי ~ ואנכי – לכם] 9 ~</p>\n",
      "<p>לכם] ]h + θεός<ref 21> “God”, cf e.g. Exod 67 Lev 2612 Zech 88; note diverse word-order in ]h</ref> = *h + [h</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Path to your .docx file\n",
    "docx_path = 'Hosea.1.App I.Full.docx'\n",
    "\n",
    "# Temporary storage for extracted XML content\n",
    "document_xml = None\n",
    "footnotes_xml = None\n",
    "\n",
    "# Step 1: Extract `document.xml` and `footnotes.xml` from the .docx file\n",
    "with zipfile.ZipFile(docx_path, 'r') as docx:\n",
    "    if 'word/document.xml' in docx.namelist():\n",
    "        document_xml = docx.read('word/document.xml').decode('utf-8')\n",
    "    if 'word/footnotes.xml' in docx.namelist():\n",
    "        footnotes_xml = docx.read('word/footnotes.xml').decode('utf-8')\n",
    "\n",
    "# Step 2: Parse `footnotes.xml` to create a dictionary of footnote content\n",
    "footnotes_dict = {}\n",
    "if footnotes_xml:\n",
    "    footnotes_root = ET.fromstring(footnotes_xml)\n",
    "    namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "\n",
    "    for footnote in footnotes_root.findall('w:footnote', namespaces):\n",
    "        footnote_id = footnote.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "        footnote_text = ''.join(node.text or '' for node in footnote.findall('.//w:t', namespaces))\n",
    "        footnotes_dict[footnote_id] = footnote_text\n",
    "\n",
    "# Step 3: Parse `document.xml` to identify and tag footnote references\n",
    "formatted_text = \"\"\n",
    "if document_xml:\n",
    "    document_root = ET.fromstring(document_xml)\n",
    "    for paragraph in document_root.findall('.//w:p', namespaces):\n",
    "        paragraph_text = \"\"\n",
    "        \n",
    "        # Process each run in the paragraph\n",
    "        for run in paragraph.findall('.//w:r', namespaces):\n",
    "            text_elem = run.find('w:t', namespaces)\n",
    "            footnote_ref = run.find('.//w:footnoteReference', namespaces)\n",
    "            \n",
    "            if text_elem is not None:\n",
    "                paragraph_text += text_elem.text or ''\n",
    "            elif footnote_ref is not None:\n",
    "                # Get the ID of the footnote reference and wrap it in <ref ...> tags\n",
    "                footnote_id = footnote_ref.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "                footnote_content = footnotes_dict.get(footnote_id, \"\")\n",
    "                paragraph_text += f\"<ref {footnote_id}>{footnote_content}</ref>\"\n",
    "\n",
    "        # Add formatted paragraph text to the main text\n",
    "        formatted_text += f\"<p>{paragraph_text}</p>\\n\"\n",
    "\n",
    "print(\"Formatted Document with Footnote References:\")\n",
    "print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b2df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified document saved as Hosea.1.App I.Modified.docx\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from docx import Document\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Paths for input and output files\n",
    "docx_path = 'Hosea.1.App I.Full.docx'  # Original document path\n",
    "output_docx_path = 'Hosea.1.App I.Modified.docx'  # Output document with modified content\n",
    "special_font_name = 'HUBPSigla'  # Replace with actual font name for special characters\n",
    "replacement_font_name = 'Times New Roman'  # Font to replace special font\n",
    "\n",
    "# Temporary directory to modify the .docx content\n",
    "temp_dir = \"temp_docx\"\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "\n",
    "# Step 1: Extract .docx contents to a temporary directory\n",
    "with zipfile.ZipFile(docx_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "# Step 2: Access and modify footnotes.xml in the extracted content\n",
    "footnotes_path = os.path.join(temp_dir, \"word\", \"footnotes.xml\")\n",
    "if os.path.exists(footnotes_path):\n",
    "    tree = ET.parse(footnotes_path)\n",
    "    root = tree.getroot()\n",
    "    namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "\n",
    "    # Modify each footnote element\n",
    "    for footnote in root.findall('w:footnote', namespaces):\n",
    "        footnote_id = footnote.get(f'{{{namespaces[\"w\"]}}}id')\n",
    "        wrapped_text = f\"<footnote ID='{footnote_id}'>\"\n",
    "\n",
    "        # Append each run's text with special font tags and close the footnote tag\n",
    "        for run in footnote.findall('.//w:r', namespaces):\n",
    "            text_elem = run.find('w:t', namespaces)\n",
    "            font_elem = run.find('.//w:rPr//w:rFonts', namespaces)\n",
    "            \n",
    "            if text_elem is not None:\n",
    "                text = text_elem.text or \"\"\n",
    "                font = font_elem.get(f'{{{namespaces[\"w\"]}}}ascii') if font_elem is not None else \"Unknown\"\n",
    "                \n",
    "                # Wrap text in <specialFont ...> if in special font, otherwise add it normally\n",
    "                if font == special_font_name:\n",
    "                    wrapped_text += f\"<specialFont {text} >\"\n",
    "                else:\n",
    "                    wrapped_text += text\n",
    "                \n",
    "        wrapped_text += \"</footnote>\"\n",
    "\n",
    "        # Replace the original footnote text with wrapped text in the first <w:t> element\n",
    "        for elem in footnote.findall('.//w:t', namespaces):\n",
    "            elem.text = wrapped_text  # Replace with modified wrapped text\n",
    "            break  # Only replace the first <w:t> element to avoid duplicating\n",
    "\n",
    "    # Save the modified footnotes.xml\n",
    "    tree.write(footnotes_path, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "# Step 3: Modify main text with python-docx to add <specialFont ...> tags\n",
    "document = Document(docx_path)\n",
    "\n",
    "for para in document.paragraphs:\n",
    "    for run in para.runs:\n",
    "        font_name = run.font.name if run.font else \"Unknown\"\n",
    "        \n",
    "        # Wrap text in <specialFont ...> tags if it is in the special font\n",
    "        if font_name == special_font_name:\n",
    "            modified_text = ''.join(f\"<specialFont {char} >\" for char in run.text)\n",
    "            run.text = modified_text\n",
    "            run.font.name = replacement_font_name\n",
    "\n",
    "# Save the modified main text as a new temporary .docx file\n",
    "temp_main_docx_path = os.path.join(temp_dir, \"modified_main.docx\")\n",
    "document.save(temp_main_docx_path)\n",
    "\n",
    "# Step 4: Repackage the modified contents into a new .docx file\n",
    "# Replace the main document (document.xml) from the modified_main.docx in the temp directory\n",
    "with zipfile.ZipFile(temp_main_docx_path, 'r') as temp_main_zip:\n",
    "    temp_main_zip.extract('word/document.xml', temp_dir)\n",
    "\n",
    "# Create the final modified .docx by repackaging\n",
    "with zipfile.ZipFile(output_docx_path, 'w') as zip_out:\n",
    "    for foldername, subfolders, filenames in os.walk(temp_dir):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(foldername, filename)\n",
    "            arcname = os.path.relpath(file_path, temp_dir)\n",
    "            zip_out.write(file_path, arcname)\n",
    "\n",
    "# Cleanup temporary directory\n",
    "shutil.rmtree(temp_dir)\n",
    "\n",
    "print(f\"Modified document saved as {output_docx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e7309e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[['\\t', 'Hosea 1'],\n",
       "    [],\n",
       "    ['1 יותם אחז יחזקיה] ][ &'],\n",
       "    ['מלכי] ]h numII', '----footnote1----'],\n",
       "    ['2 דִּבֶּר] ] λόγου', '----footnote2----', ' = [T'],\n",
       "    ['ב(הושע)] ]h πρός',\n",
       "     '----footnote3----',\n",
       "     ' + [ܕܗܘܐ ܥܠ',\n",
       "     '----footnote4----'],\n",
       "    ['ו(יאמר)] ]h[ >'],\n",
       "    ['לֵךְ] ]h >II'],\n",
       "    ['3 ויקח] [ + ܠܗ', '----footnote5----'],\n",
       "    ['לו] ]h*- >II III IV', '----footnote6----'],\n",
       "    ['4 יהוא] ]h Ιουδα', '----footnote7----'],\n",
       "    ['(ו)הִשְׁבַּתִּי] ]- ἀποστρέψω', '----footnote8----'],\n",
       "    ['בית2] ]h*hT- + prep', '----footnote9----'],\n",
       "    ['5 והיה (ביום ההוא)] [ >', '----footnote10----'],\n",
       "    ['(ו)היה] * >'],\n",
       "    ['ההוא] ]h + dicit dominus', '----footnote11----'],\n",
       "    ['6 עוד1] *hT- >II III IV'],\n",
       "    ['לו] ]h + κύριοςII',\n",
       "     '----footnote12----',\n",
       "     ' = [| [ pron',\n",
       "     '----footnote13----'],\n",
       "    ['נשׂא אשׂא] ] ἀντιτασσόμενος ἀντιτάξομαι',\n",
       "     '----footnote14----',\n",
       "     ' | * oblivione obliviscar',\n",
       "     '----footnote15----',\n",
       "     ' + ~'],\n",
       "    ['7 בית] ] υἱούς', '----footnote16----'],\n",
       "    ['יהודה] ]h >'],\n",
       "    ['ולא] ][ rep'],\n",
       "    ['(ו)במלחמה] ]- + (οὐδὲ) ἐν ἅρμασιν', '----footnote17----'],\n",
       "    ['בסוסים] ]*[ &III IV'],\n",
       "    ['8 ותהר] ]- + ἔτιII', '----footnote18----', ' = ['],\n",
       "    ['ותלד] ]h + αὐτῷIV', '----footnote19----', ' = *h'],\n",
       "    ['9 ויאמר] ]h + κύριος (αὐτῷ)II', '----footnote20----', ' = Th + ['],\n",
       "    ['\\t', 'כי – עמי ~ ואנכי – לכם] 9 ~'],\n",
       "    ['לכם] ]h + θεός', '----footnote21----', ' = *h + [h']]]]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_content.body_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a62e21f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'Hos' - Font: Unknown\n",
      "Word: 'ea' - Font: Unknown\n",
      "Word: '1' - Font: Unknown\n",
      "Word: '1' - Font: Unknown\n",
      "Word: 'יותם' - Font: Unknown\n",
      "Word: 'אחז' - Font: Unknown\n",
      "Word: 'יחזקיה' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '&' - Font: HUBPSigla\n",
      "Word: 'מלכי' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: 'h' - Font: HUBPSigla\n",
      "Word: 'num' - Font: Unknown\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: '2' - Font: Unknown\n",
      "Word: 'דִּבֶּר' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: 'λόγου' - Font: GFS Porson\n",
      "Word: '=' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: 'T' - Font: HUBPSigla\n",
      "Word: 'ב' - Font: Unknown\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'הושע' - Font: Unknown\n",
      "Word: ')' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: 'πρός' - Font: GFS Porson\n",
      "Word: '+' - Font: HUBPSigla\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: 'ܕܗܘܐ' - Font: Unknown\n",
      "Word: 'ܥܠ' - Font: Unknown\n",
      "Word: 'ו' - Font: Unknown\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'יאמר' - Font: Unknown\n",
      "Word: ')' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'לֵךְ' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: '3' - Font: Unknown\n",
      "Word: 'ויקח' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'ܠܗ' - Font: Unknown\n",
      "Word: 'לו' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '*' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: 'III' - Font: Unknown\n",
      "Word: 'IV' - Font: Unknown\n",
      "Word: '4' - Font: Unknown\n",
      "Word: 'יהוא' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: 'Ιουδα' - Font: GFS Porson\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'ו' - Font: Unknown\n",
      "Word: ')' - Font: Unknown\n",
      "Word: 'הִ' - Font: Unknown\n",
      "Word: 'שְׁ' - Font: Unknown\n",
      "Word: 'בַּתִּי' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: 'ἀποστρέψω' - Font: GFS Porson\n",
      "Word: 'בית' - Font: Unknown\n",
      "Word: '2' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h*' - Font: HUBPSigla\n",
      "Word: 'h' - Font: HUBPSigla\n",
      "Word: 'T' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'prep' - Font: Unknown\n",
      "Word: '5' - Font: Unknown\n",
      "Word: 'והיה' - Font: Unknown\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'ביום' - Font: Unknown\n",
      "Word: 'ההוא' - Font: Unknown\n",
      "Word: ')' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'ו)היה' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '*' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'ההוא' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'dicit' - Font: Unknown\n",
      "Word: 'dominu' - Font: Unknown\n",
      "Word: 's' - Font: Unknown\n",
      "Word: '6' - Font: Unknown\n",
      "Word: 'עוד' - Font: Unknown\n",
      "Word: '1' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '*' - Font: HUBPSigla\n",
      "Word: 'hT' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: 'III' - Font: Unknown\n",
      "Word: 'IV' - Font: Unknown\n",
      "Word: 'לו' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'κύριος' - Font: GFS Porson\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: '=' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '|' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: 'pron' - Font: Unknown\n",
      "Word: 'נש' - Font: Unknown\n",
      "Word: 'ׂ' - Font: Unknown\n",
      "Word: 'א' - Font: Unknown\n",
      "Word: 'אש' - Font: Unknown\n",
      "Word: 'ׂ' - Font: Unknown\n",
      "Word: 'א' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: 'ἀντιτασσόμενος' - Font: GFS Porson\n",
      "Word: 'ἀντιτάξομαι' - Font: GFS Porson\n",
      "Word: '|' - Font: Unknown\n",
      "Word: '*' - Font: HUBPSigla\n",
      "Word: 'oblivione' - Font: Unknown\n",
      "Word: 'oblivisca' - Font: Unknown\n",
      "Word: 'r' - Font: Unknown\n",
      "Word: '+' - Font: HUBPSigla\n",
      "Word: '~' - Font: HUBPSigla\n",
      "Word: '7' - Font: Unknown\n",
      "Word: 'בית' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: 'υἱο' - Font: GFS Porson\n",
      "Word: 'ύ' - Font: GFS Porson\n",
      "Word: 'ς' - Font: GFS Porson\n",
      "Word: 'י' - Font: Unknown\n",
      "Word: 'הודה' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '>' - Font: Unknown\n",
      "Word: 'ולא' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '][' - Font: HUBPSigla\n",
      "Word: 'rep' - Font: Unknown\n",
      "Word: '(' - Font: Unknown\n",
      "Word: 'ו' - Font: Unknown\n",
      "Word: ')' - Font: Unknown\n",
      "Word: 'במלחמה' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: '(' - Font: GFS Porson\n",
      "Word: 'οὐδὲ' - Font: GFS Porson\n",
      "Word: ')' - Font: GFS Porson\n",
      "Word: 'ἐν' - Font: GFS Porson\n",
      "Word: 'ἅρμασιν' - Font: GFS Porson\n",
      "Word: 'בסוסים' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: '*' - Font: HUBPSigla\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: '&' - Font: HUBPSigla\n",
      "Word: 'III' - Font: Unknown\n",
      "Word: 'IV' - Font: Unknown\n",
      "Word: '8' - Font: Unknown\n",
      "Word: 'ותהר' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']' - Font: HUBPSigla\n",
      "Word: '-' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'ἔτι' - Font: GFS Porson\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: '=' - Font: Unknown\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: 'ותלד' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'α' - Font: GFS Porson\n",
      "Word: 'ὐτῷ' - Font: GFS Porson\n",
      "Word: 'IV' - Font: Unknown\n",
      "Word: '=' - Font: Unknown\n",
      "Word: '*h' - Font: HUBPSigla\n",
      "Word: '9' - Font: Unknown\n",
      "Word: 'ויאמר' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'κύριος' - Font: GFS Porson\n",
      "Word: '(' - Font: GFS Porson\n",
      "Word: 'α' - Font: GFS Porson\n",
      "Word: 'ὐτῷ' - Font: GFS Porson\n",
      "Word: ')' - Font: GFS Porson\n",
      "Word: 'II' - Font: Unknown\n",
      "Word: '=' - Font: Unknown\n",
      "Word: 'T' - Font: HUBPSigla\n",
      "Word: 'h' - Font: HUBPSigla\n",
      "Word: '+' - Font: HUBPSigla\n",
      "Word: '[' - Font: HUBPSigla\n",
      "Word: 'כי' - Font: Unknown\n",
      "Word: '–' - Font: Unknown\n",
      "Word: 'עמי' - Font: Unknown\n",
      "Word: '~' - Font: Unknown\n",
      "Word: 'ואנכי' - Font: Unknown\n",
      "Word: '–' - Font: Unknown\n",
      "Word: 'ל' - Font: Unknown\n",
      "Word: 'כ' - Font: Unknown\n",
      "Word: 'ם' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: '9' - Font: HUBPSigla\n",
      "Word: '~' - Font: Unknown\n",
      "Word: 'לכם' - Font: Unknown\n",
      "Word: ']' - Font: Unknown\n",
      "Word: ']h' - Font: HUBPSigla\n",
      "Word: '+' - Font: Unknown\n",
      "Word: 'θεός' - Font: GFS Porson\n",
      "Word: '=' - Font: Unknown\n",
      "Word: '*h' - Font: HUBPSigla\n",
      "Word: '+' - Font: HUBPSigla\n",
      "Word: '[h' - Font: HUBPSigla\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Load the document\n",
    "docx_path = 'Hosea.1.App I.Full.docx'  # Replace with the actual file path\n",
    "document = Document(docx_path)\n",
    "\n",
    "# Function to get font name from a run\n",
    "def get_font_name(run):\n",
    "    try:\n",
    "        if run.font and run.font.name:\n",
    "            return run.font.name\n",
    "        else:\n",
    "            # If the font is not set explicitly, it might be inherited from the style\n",
    "            if run.style and run.style.font and run.style.font.name:\n",
    "                return run.style.font.name\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Iterate over paragraphs and runs to print the font of each word\n",
    "for para in document.paragraphs:\n",
    "    for run in para.runs:\n",
    "        font_name = get_font_name(run)\n",
    "        words = run.text.split()  # Split run text into individual words\n",
    "        for word in words:\n",
    "            print(f\"Word: '{word}' - Font: {font_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64d4f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML file with differentiated font encoding saved at: Hosea1_AppI_Full_withFonts.xml\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import xml.etree.ElementTree as ET\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "# Load the custom HUBPSigla font to access glyph mappings\n",
    "hubps_font_path = 'HUBPS_.ttf'\n",
    "hubps_font = TTFont(hubps_font_path)\n",
    "\n",
    "# Load mappings from the HUBPSigla font\n",
    "hubps_glyph_map = {code: glyph_name for cmap in hubps_font['cmap'].tables for code, glyph_name in cmap.cmap.items()}\n",
    "\n",
    "# Load the .docx file\n",
    "docx_path = 'Hosea.1.App I.Full.docx'\n",
    "document = Document(docx_path)\n",
    "\n",
    "# Function to get font name from a run\n",
    "def get_font_name(run):\n",
    "    try:\n",
    "        if run.font and run.font.name:\n",
    "            return run.font.name\n",
    "        elif run.style and run.style.font and run.style.font.name:\n",
    "            return run.style.font.name\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Check if a character is a special HUBPSigla glyph\n",
    "def is_hubps_special(char):\n",
    "    codepoint = ord(char)\n",
    "    return codepoint in hubps_glyph_map\n",
    "\n",
    "# Create the root element for the XML\n",
    "root = ET.Element(\"document\")\n",
    "\n",
    "# Process each paragraph in the Word document\n",
    "for para in document.paragraphs:\n",
    "    para_elem = ET.SubElement(root, \"paragraph\")\n",
    "    \n",
    "    # Process each run in the paragraph\n",
    "    for run in para.runs:\n",
    "        font_name = get_font_name(run)\n",
    "        run_elem = ET.SubElement(para_elem, \"run\")\n",
    "        run_elem.set(\"font\", font_name)\n",
    "\n",
    "        run_text = \"\"\n",
    "        for char in run.text:\n",
    "            if font_name == \"HUBPSigla\" and is_hubps_special(char):\n",
    "                # If it's a HUBPSigla special character, output it as a unique element\n",
    "                special_char_elem = ET.SubElement(run_elem, \"special_char\")\n",
    "                special_char_elem.set(\"unicode\", f\"U+{ord(char):04X}\")\n",
    "                special_char_elem.set(\"font\", \"HUBPSigla\")\n",
    "                special_char_elem.text = char\n",
    "            else:\n",
    "                # Otherwise, treat it as normal text\n",
    "                run_text += char\n",
    "        \n",
    "        # Add normal text to the run element\n",
    "        if run_text:\n",
    "            run_elem.text = run_text\n",
    "\n",
    "# Save the XML to a file\n",
    "xml_path = 'Hosea1_AppI_Full_withFonts.xml'\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(xml_path, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "print(f\"XML file with differentiated font encoding saved at: {xml_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98ff417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted successfully and saved as 'App1-output1.txt'\n"
     ]
    }
   ],
   "source": [
    "def convert_docx_to_txt(docx_file_path, txt_file_path):\n",
    "    # Load the .docx file\n",
    "    doc = Document(docx_file_path)\n",
    "\n",
    "    # Extract text from each paragraph in the document\n",
    "    text_content = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "    # Write the extracted text to a .txt file\n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text_content)\n",
    "\n",
    "    print(f\"File converted successfully and saved as '{txt_file_path}'\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "convert_docx_to_txt('Hosea.1.App I.Full.docx', 'App1-output1.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3320fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at 'Hosea.1.App I.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHosea.1.App I.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m doc_text \u001b[38;5;241m=\u001b[39m \u001b[43mread_docx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc_text)\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mread_docx\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_docx\u001b[39m(file_path):\n\u001b[1;32m----> 4\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m paragraph \u001b[38;5;129;01min\u001b[39;00m document\u001b[38;5;241m.\u001b[39mparagraphs:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\docx\\api.py:23\u001b[0m, in \u001b[0;36mDocument\u001b[1;34m(docx)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a |Document| object loaded from `docx`, where `docx` can be either a path\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mto a ``.docx`` file (a string) or a file-like object.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mIf `docx` is missing or ``None``, the built-in default document \"template\" is\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mloaded.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m docx \u001b[38;5;241m=\u001b[39m _default_docx_path() \u001b[38;5;28;01mif\u001b[39;00m docx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m docx\n\u001b[1;32m---> 23\u001b[0m document_part \u001b[38;5;241m=\u001b[39m \u001b[43mPackage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmain_document_part\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m document_part\u001b[38;5;241m.\u001b[39mcontent_type \u001b[38;5;241m!=\u001b[39m CT\u001b[38;5;241m.\u001b[39mWML_DOCUMENT_MAIN:\n\u001b[0;32m     25\u001b[0m     tmpl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a Word file, content type is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\docx\\opc\\package.py:116\u001b[0m, in \u001b[0;36mOpcPackage.open\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pkg_file):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an |OpcPackage| instance loaded with the contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     pkg_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPackageReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     package \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m    118\u001b[0m     Unmarshaller\u001b[38;5;241m.\u001b[39munmarshal(pkg_reader, package, PartFactory)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\docx\\opc\\pkgreader.py:22\u001b[0m, in \u001b[0;36mPackageReader.from_file\u001b[1;34m(pkg_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_file\u001b[39m(pkg_file):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a |PackageReader| instance loaded with contents of `pkg_file`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     phys_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPhysPkgReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     content_types \u001b[38;5;241m=\u001b[39m _ContentTypeMap\u001b[38;5;241m.\u001b[39mfrom_xml(phys_reader\u001b[38;5;241m.\u001b[39mcontent_types_xml)\n\u001b[0;32m     24\u001b[0m     pkg_srels \u001b[38;5;241m=\u001b[39m PackageReader\u001b[38;5;241m.\u001b[39m_srels_for(phys_reader, PACKAGE_URI)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\docx\\opc\\phys_pkg.py:21\u001b[0m, in \u001b[0;36mPhysPkgReader.__new__\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m         reader_cls \u001b[38;5;241m=\u001b[39m _ZipPkgReader\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPackage not found at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m pkg_file)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume it's a stream and pass it to Zip reader to sort out\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reader_cls \u001b[38;5;241m=\u001b[39m _ZipPkgReader\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: Package not found at 'Hosea.1.App I.txt'"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "def read_docx(file_path):\n",
    "    document = Document(file_path)\n",
    "    text = []\n",
    "    for paragraph in document.paragraphs:\n",
    "        text.append(paragraph.text)\n",
    "    return '\\n'.join(text)\n",
    "\n",
    "# Example usage\n",
    "file_path = open('Hosea.1.App I.txt'\n",
    "doc_text = read_docx(file_path)\n",
    "print(doc_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ac348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffHosea 1\\n\\n1 יותם אחז יחזקיה] ][ &\\nמלכי] ]h numII1\\n2 דִּבֶּר] ] λόγου2 = [T\\nב(הושע)] ]h πρός3 + [ܕܗܘܐ ܥܠ4\\nו(יאמר)] ]h[ >\\nלֵךְ] ]h >II\\n3 ויקח] [ + ܠܗ5\\nלו] ]h*- >II III IV6\\n4 יהוא] ]h Ιουδα7\\n(ו)הִשְׁבַּתִּי] ]- ἀποστρέψω8\\nבית2] ]h*hT- + prep9\\n5 והיה (ביום ההוא)] [ >10\\n(ו)היה] * >\\nההוא] ]h + dicit dominus11\\n6 עוד1] *hT- >II III IV\\nלו] ]h + κύριοςII12 = [| [ pron13\\nנשׂא אשׂא] ] ἀντιτασσόμενος ἀντιτάξομαι14 | * oblivione obliviscar15 + ~\\n7 בית] ] υἱούς16\\nיהודה] ]h >\\nולא] ][ rep\\n(ו)במלחמה] ]- + (οὐδὲ) ἐν ἅρμασιν17\\nבסוסים] ]*[ &III IV\\n8 ותהר] ]- + ἔτιII18 = [\\nותלד] ]h + αὐτῷIV19 = *h\\n9 ויאמר] ]h + κύριος (αὐτῷ)II20 = Th + [\\nכי – עמי ~ ואנכי – לכם] 9 ~\\nלכם] ]h + θεός21 = *h + [h\\n1 cf app Mic 11\\n2 (a) voc דְּבַר (יהוה), formula, cf v1 41 et al; cf app 131; cf תחלת דִּבְרֵי Qoh 1013; note seq; (b) noun דִּבֵּר, cf app Jer 513 and Rabb Heb; cf gerund in * loquendi “of speaking”\\n3 “to”; main evid, cf v1\\n4 “which was to”, ex v1\\n5 “for himself”, cf v2\\n6 cf vv6,8; contrast Hier 10154\\n7 main evid; inner-Grk (בית יהודה common collocation), cf Hier 12208−211\\n8 voc הֲשִׁבֹתִי, similarly app 213 Ezek 724; for parall השיב//פקד cf 49 123; main evid ]h καταπαύσω (=x)\\n9 common formula השבית מן, cf e.g. Lev 266 Jer 734\\n10 formulaic change, cf app Joel 418 Mic 59 et al\\n11 “says the Lord”, formula (נאם יהוה), cf 218,23 et al\\n12 “the Lord”, cf v4, app v9 (ויאמר)\\n13 1sg, cf 31\\n14 “opposing I shall oppose” (= ] 1Kgs 1134); p etym \\\\ נשׁא“oppress, set against” (cf Ps 8923), cf Obad 7 הִשִּׁיאוּךָ J ] ἀντέστησάν σοι “they opposed you” (for interchange of ἀντιτάσσεσθαι “to oppose” / ἀνθίστασθαι “to stand against” cf ]i 4Macc 1623); cf also Jer 4916 הִשִּׁיא = ] [2917] ἐνεχείρησε “(it) attacked” (contrast etym \\\\נשׂא ~9 and pObad 3 ]) \\n15 “by forgetfulness I shall forget”, etym \\\\נשׁה, contrast app Jer 2339\\n16 “sons (of)”, for בני/בית cf app Amos 15 31 Zeph 18  \\n17 p (ו)ברכב; common collocation, cf e.g. Ezek 267 בסוס וברכב ובפרשים\\n18 “again”, cf v6\\n19 “(to) him”, cf v3\\n20 “the Lord (to him)”, cf app v6 (לו); for [ pron cf n14\\n21 “God”, cf e.g. Exod 67 Lev 2612 Zech 88; note diverse word-order in ]h\\n---------------\\n\\n------------------------------------------------------------\\n\\n---------------\\n\\n------------------------------------------------------------\\n\\n\\u200f06/11/2024 הושע א, אפ' א + ה (הערות באנגלית)\\n\\n2\\n\\n\\n1\\n\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('Hosea.1.App I.txt', mode='r', encoding ='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79577e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 יותם אחז יחזקיה] ][ &\n"
     ]
    }
   ],
   "source": [
    "lines = open('Hosea.1.App I.txt', mode='r', encoding ='utf8').read().split(sep=\"\\n\")\n",
    "print(lines[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc98698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## render apparatus 4 ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7452534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lines(lines):\n",
    "    # Initialize variables\n",
    "    chapter = None\n",
    "    data = []\n",
    "\n",
    "    # Process each line\n",
    "    for line in lines:\n",
    "        if line == '':\n",
    "            # Skip empty lines\n",
    "            continue\n",
    "        elif len(line.split()) == 2:\n",
    "            # If the line has only two words, save it as the chapter\n",
    "            chapter = line\n",
    "        else:\n",
    "            # If the line is text, couple it with the chapter\n",
    "            if chapter is not None:\n",
    "                data.append([chapter, line])\n",
    "                chapter = None  # Reset the chapter after coupling\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Chapter', 'Line'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_entries(df):\n",
    "    # Define the regular expression pattern to split on\n",
    "    pattern = r'\\xa0+\\'\\xa0+|\\xa0+(?=\\s?\\d+)'\n",
    "    \n",
    "    # Split each line into entries based on the pattern\n",
    "    df['Entries'] = df['Line'].apply(lambda x: re.split(pattern, x))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b00593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Line</th>\n",
       "      <th>Entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>הושע א</td>\n",
       "      <td>1 (בספר החילופים וברשימת הסדרים שבכ\"י ל מצוין ...</td>\n",
       "      <td>[1 (בספר החילופים וברשימת הסדרים שבכ\"י ל מצוין...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>הושע ב</td>\n",
       "      <td>1 (פ)] ל ל18 פ ר מ: (ס)   '   וְהיה(1)] ר': וַ...</td>\n",
       "      <td>[1 (פ)] ל ל18 פ ר מ: (ס) ,  וְהיה(1)] ר': וַ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>הושע ג</td>\n",
       "      <td>1 (פ)] ל29 פ: (ס)   '   אֱהב־] נ: אֶ  '   אהבת...</td>\n",
       "      <td>[1 (פ)] ל29 פ: (ס) ,  אֱהב־] נ: אֶ,  אהבת] ר: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>הושע ד</td>\n",
       "      <td>1 (פ)] ל29 37 פ מ: (ס) ; ר: (&gt;) ; ר־מ\"ק: \"פרשׄ...</td>\n",
       "      <td>[1 (פ)] ל29 37 פ מ: (ס) ; ר: (&gt;) ; ר־מ\"ק: \"פרש...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>הושע ה</td>\n",
       "      <td>1 (פ)] ל ל18 פ ק ש מ: (ס) ; נ: (&gt;)  '   והקש֣י...</td>\n",
       "      <td>[1 (פ)] ל ל18 פ ק ש מ: (ס) ; נ: (&gt;),  והקש֣יבו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>זכריה יג</td>\n",
       "      <td>1 (&gt;)] ל מ: (ס)   '   דויד] פ ר: דוד     2 נאם...</td>\n",
       "      <td>[1 (&gt;)] ל מ: (ס) ,  דויד] פ ר: דוד ,  2 נאם ׀ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>זכריה יד</td>\n",
       "      <td>1 (פ)] ל ל10 18 פ מ: (ס)     2 הגויִ֥ם ׀ ] ק: ...</td>\n",
       "      <td>[1 (פ)] ל ל10 18 פ מ: (ס) ,  2 הגויִ֥ם ׀ ] ק: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>מלאכי א</td>\n",
       "      <td>1 &gt;] ל: יט (התוספת \"יט\" מיד שנייה)     2 הלוֹא־...</td>\n",
       "      <td>[1 &gt;] ל: יט (התוספת \"יט\" מיד שנייה) ,  2 הלוֹא־...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>מלאכי ב</td>\n",
       "      <td>1 אליכם] ל20 ק־מ\"ק: \"דׄ מטעׄ\" ; ל20־מ\"ג: \"אליכ...</td>\n",
       "      <td>[1 אליכם] ל20 ק־מ\"ק: \"דׄ מטעׄ\" ; ל20־מ\"ג: \"אלי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>מלאכי ג</td>\n",
       "      <td>1 שלח֙] ל28 30 ק: של֙ח֙  '   ופתאֹם] ר: ופתאוֹם...</td>\n",
       "      <td>[1 שלח֙] ל28 30 ק: של֙ח֙,  ופתאֹם] ר: ופתאוֹם, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chapter                                               Line  \\\n",
       "0     הושע א  1 (בספר החילופים וברשימת הסדרים שבכ\"י ל מצוין ...   \n",
       "1     הושע ב  1 (פ)] ל ל18 פ ר מ: (ס)   '   וְהיה(1)] ר': וַ...   \n",
       "2     הושע ג  1 (פ)] ל29 פ: (ס)   '   אֱהב־] נ: אֶ  '   אהבת...   \n",
       "3     הושע ד  1 (פ)] ל29 37 פ מ: (ס) ; ר: (>) ; ר־מ\"ק: \"פרשׄ...   \n",
       "4     הושע ה  1 (פ)] ל ל18 פ ק ש מ: (ס) ; נ: (>)  '   והקש֣י...   \n",
       "..       ...                                                ...   \n",
       "62  זכריה יג  1 (>)] ל מ: (ס)   '   דויד] פ ר: דוד     2 נאם...   \n",
       "63  זכריה יד  1 (פ)] ל ל10 18 פ מ: (ס)     2 הגויִ֥ם ׀ ] ק: ...   \n",
       "64   מלאכי א  1 >] ל: יט (התוספת \"יט\" מיד שנייה)     2 הלוֹא־...   \n",
       "65   מלאכי ב  1 אליכם] ל20 ק־מ\"ק: \"דׄ מטעׄ\" ; ל20־מ\"ג: \"אליכ...   \n",
       "66   מלאכי ג  1 שלח֙] ל28 30 ק: של֙ח֙  '   ופתאֹם] ר: ופתאוֹם...   \n",
       "\n",
       "                                              Entries  \n",
       "0   [1 (בספר החילופים וברשימת הסדרים שבכ\"י ל מצוין...  \n",
       "1   [1 (פ)] ל ל18 פ ר מ: (ס) ,  וְהיה(1)] ר': וַ, ...  \n",
       "2   [1 (פ)] ל29 פ: (ס) ,  אֱהב־] נ: אֶ,  אהבת] ר: ...  \n",
       "3   [1 (פ)] ל29 37 פ מ: (ס) ; ר: (>) ; ר־מ\"ק: \"פרש...  \n",
       "4   [1 (פ)] ל ל18 פ ק ש מ: (ס) ; נ: (>),  והקש֣יבו...  \n",
       "..                                                ...  \n",
       "62  [1 (>)] ל מ: (ס) ,  דויד] פ ר: דוד ,  2 נאם ׀ ...  \n",
       "63  [1 (פ)] ל ל10 18 פ מ: (ס) ,  2 הגויִ֥ם ׀ ] ק: ...  \n",
       "64  [1 >] ל: יט (התוספת \"יט\" מיד שנייה) ,  2 הלוֹא־...  \n",
       "65  [1 אליכם] ל20 ק־מ\"ק: \"דׄ מטעׄ\" ; ל20־מ\"ג: \"אלי...  \n",
       "66  [1 שלח֙] ל28 30 ק: של֙ח֙,  ופתאֹם] ר: ופתאוֹם, ...  \n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_lines(lines)\n",
    "df = split_entries(df)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be98a2a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 (פ)] ל29 37 פ מ: (ס) ; ר: (>) ; ר־מ\"ק: \"פרשׄ\"',\n",
       " \" יושבי] פ ק1' ר: ישבי\",\n",
       " ' ואֵֽין־דַּ֥עת] ל20\\': ואֵ֥ין דַּעת־ ; ב\"א: ואֵֽין־דַּ֥עת, ב\"נ: ואֵ֥ין דַּֽעת־ ',\n",
       " '2 אלֹה] נ־מ\"ק: \"לו קׄ\" ; ר־מ\"ק: \"וׄ קׄ\"',\n",
       " \" ורצח] פ': רצח II; ר: רצוח\",\n",
       " ' וגנב] ר: וגנוב ',\n",
       " '3 כ֣ן ׀ ] ל18־מ\"ק: \"ל֣גׄ ׀\" ; נ ר־מ\"ק: \"לגׄ\"',\n",
       " ' יושב] ל29\\' פ: ישב ; ק1\\' ר: ישבי ; ר־מ\"ק: \"יתׄ יׄ\"III II I',\n",
       " ' בחית] ר: בחיית ',\n",
       " '4 (>)] מ: (פ) ',\n",
       " \" איש(2)] ל': אמש\",\n",
       " ' כִּמְרִיבי] ש!: כמִרְ ',\n",
       " '6 מאסת] ר: מאסתה',\n",
       " ' וְאמאסאך] מ: וָֽ ; ל18 פ ר\\': ואמאסך ; א ל ל29 ק1 מ־מ\"ק: \"יתיר אׄ\" ; ק־מ\"ק: \"ן לׄ ויתׄ אׄ\" ; ל30־מ\"ק: \"ןׄ ואמאסך קרי\" ; ר־מ\"ק: \"לׄ ויתיר אׄ\" ; ל20־מ\"ק: \"לׄ וכתׄ כן\" ; ל37־מ\"ק: \"יתי א\" ; פ־מ\"ק: \"ואמאסאך כך כתׄ ולא ק א תלתא\" ',\n",
       " '8 נפשוֹ] ר: נפשֹם ; ר־מ\"ק: \"נפשו קׄ <...>פשם כתׄ וחד מן <...>לין דכתבין <...>וׄ תיבוׄ ק וׄ\"  ; ל־מ\"ק: \"דׄ מטעׄ\" ; ל20 נ־מ\"ק: \"גׄ מטע\" ; ל29־מ\"ק: \"גׄ דמטעׄ\" ; ל29־מ\"ג: \"נפשו גׄ דמטעׄ...\" ; ל30־מ\"ג: \"נפשוֹ גׄ מטעיין וסימנהׄ...\" ; ש־מ\"ק: \"גׄ מטׄ\" ; מ־מ\"ק: \"ג\\' מטעי\\' בהון\" ; ל20־מ\"ג: \"נפשו ג מטעׄ וסימנהון ואל עונם ישאו נפשו להושיע משפטי נפשו ולא נתתי לחטא חכי לשאול באלה נפשו\" ; נ־מ\"ג: \"נפשו גׄ מטעין וסימנהון ואל עונם להושיע משפטי ולא נתתי לחטא\" ; מ־מ\"ג: \"נפשו ג\\' מטעי\\' בהון וסי\\' ואל עונם ישא נפשו. להושיע משפטי נפשו. ולא נתתי\"III I ',\n",
       " \"9 עליו] פ': >\",\n",
       " \" דרכיו ומעלליו] ק1'' = א \",\n",
       " \"10 ולא(2)] ל18': לא\",\n",
       " ' לשמר] ל18: לשמור ',\n",
       " '11 ותירוש] ר: ותירש ',\n",
       " '12 (>)] מ: (ס) ',\n",
       " \" ישאל] ל20': שאל\",\n",
       " ' ומקלו] א\\': ומקולו ; מעׄ: ומקלו, מדׄ: ומקולו ; ל20־מ\"ק: \"למדנׄ ומקולו כתׄ ופלגׄ\" ; פ־מ\"ק: \"ומקולו כת ופולׄ\" ',\n",
       " \"13 בנותיכם] ל29' ר: בנתיכם\",\n",
       " ' וכלותיכם] ל18 ר: וכלתיכם ',\n",
       " '14 אפקוד] ל18 ר: אפקד',\n",
       " \" בנותיכם] ר ש: בנתיכם ; נ': בניכם\",\n",
       " ' כלותיכם] ר: כלתיכם',\n",
       " ' כי(2)] ל18: >',\n",
       " ' יְפָרדו] פ: יִפָּ',\n",
       " ' הקְּדשות] ל20 ש: קְ ',\n",
       " '15 ואל־(1)] ל20\\' נ\\' פ\\': אל ; נ־מ\"ק: \"לבבלאי ואל\"III I ',\n",
       " '16 כְּפרה] ל20! ש!: כְ ',\n",
       " \"17–18 סר – צרר] ק'' = א \",\n",
       " \"18 אהבו הבו] ר': >\",\n",
       " ' מגניה] ר: מגיניה ',\n",
       " \"19 אותה] ל29' נ פ ר: אתה\",\n",
       " \" מזִּבְחותם] מ: מזבחתם ; ל18': זְבְּIII I\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Entries\"][3]#[5]#.strip()\n",
    "#22 וארשתיך – יהוה] ר!: כל הפסוק אינו מנוקד  '   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def lemma_verse_processor(text, chapter):\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    if verses_match:\n",
    "        verse_range = verses_match.group(1).split('–')\n",
    "        if len(verse_range) == 2 and verse_range[0] != verse_range[1]:\n",
    "            verses = {'from': int(verse_range[0]), 'to': int(verse_range[1])}\n",
    "        else:\n",
    "            verses = int(verse_range[0])\n",
    "    else:\n",
    "        verses = None\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    \n",
    "    return chapter, verses, process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~\\.]*)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>[^\\(\\)]*)                           # Captures reading (excluding parentheses)\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                            # Captures comments\n",
    "    \"\"\"\n",
    "\n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v.strip() for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    # Special handling for comments containing specific markers\n",
    "    if \"Comment\" in parsed_entry and any(marker in parsed_entry['Comment'] for marker in [\"(ס)\", \"(פ)\", \"(>)\"]):\n",
    "        parsed_entry['Reading'] = parsed_entry.pop('Comment')\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "    if len(lemma.strip().split(' '))>1:#add lemma for a two word lemma separated by a space\n",
    "        return{'lemma1':process_individual_lemma(lemma.strip().split(' ')[0]),\n",
    "              'lemma2':process_individual_lemma(lemma.strip().split(' ')[1])}\n",
    "    else:\n",
    "        return process_individual_lemma(lemma.strip())\n",
    "\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(\\(?[^\\d\\(\\)]+\\)?)([\\(\\d\\)]*)?(.+?׀)?'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "#     for match in matches[:1]:\n",
    "#         word, number = match\n",
    "#         lemma_dict = {'lemma': word}\n",
    "#         if number: lemma_dict['number'] = (number)\n",
    "#         processed_lemmas.append(lemma_dict)\n",
    "\n",
    "    for match in matches[:1]:\n",
    "        word, number, paseq = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        if paseq: lemma_dict['paseq'] = (paseq)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas\n",
    "\n",
    "def extract_cross_references(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "#split the string of the witnesses into each ms and if there is a pm\\sm\\tm as if there is a מ\"ק\\מ\"ג also\n",
    "def split_into_witnesses(text):\n",
    "    witnesses = text.split()\n",
    "    result = []\n",
    "    mgk = None\n",
    "    for witness in witnesses:\n",
    "        # Splitting the witness based on the special character ־\n",
    "        parts = witness.split('־')\n",
    "        base_witness = parts[0]\n",
    "        if len(parts)>1:\n",
    "            mgk = parts[1]\n",
    "        # Handling the ' character\n",
    "        if base_witness.endswith(\"'\") or base_witness.endswith(\"''\") or base_witness.endswith(\"'''\") or base_witness.endswith(\"!\"):\n",
    "            base_witness = base_witness.rstrip(\"'\").rstrip(\"!\")\n",
    "            annotations = witness[len(base_witness):]\n",
    "            result.append([base_witness, annotations])\n",
    "        else:\n",
    "            result.append([base_witness])\n",
    "    if mgk:\n",
    "        for ms in result:\n",
    "            ms.append(mgk)\n",
    "    return result\n",
    "\n",
    "def process_input(input_str):\n",
    "    if \"=\" in input_str and '(' in input_str:\n",
    "        # Remove the '=' and return as \"affirming variants\"\n",
    "        input_str = input_str.replace('(','').replace(')','')\n",
    "        key, value = input_str.strip().split(\"=\")\n",
    "        return {\"affirming variants\": {key.strip(): value.strip()}}\n",
    "    else:\n",
    "        if \"=\" in input_str:\n",
    "            # Return as \"affirming and unidentified\"\n",
    "            key, value = input_str.split(\"=\")\n",
    "            return {\"affirming and unidentified\": {key.strip(): value.strip()}}\n",
    "        else:\n",
    "            # Return as comment\"\n",
    "            return {\"comment\": input_str.strip()}\n",
    "\n",
    "def process_entry_variants(entry):\n",
    "    variants = entry.split(';')\n",
    "    split_variants = []\n",
    "    for variant in variants:\n",
    "        if ',' in variant:\n",
    "            var, related_var = variant.split(',')#\n",
    "            split_variants.append({'Type':'Variant','Info':var})\n",
    "            split_variants.append({'Type':'Related Variant','Info':related_var})\n",
    "        else:\n",
    "            split_variants.append({'Type':'Variant','Info':variant})          \n",
    "            \n",
    "    processed_variants = []\n",
    "    \n",
    "    for variant_dict in split_variants:\n",
    "        variant = variant_dict['Info']\n",
    "#         print(type(variant['Info']))\n",
    "        variant_type = variant_dict['Type']\n",
    "        \n",
    "        # Extract cross-references from the variant\n",
    "        clean_variant, cross_reference = extract_cross_references(variant)\n",
    "\n",
    "        if ':' in clean_variant:\n",
    "            witnesses, reading = clean_variant.split(':', 1)\n",
    "            #print(witnesses)\n",
    "            if '=' in witnesses:\n",
    "                witnesses = witnesses.replace('=', ' ') #if = in structured witnesses separated by :\n",
    "                #print(witnesses)\n",
    "            processed_variants.append({\n",
    "                'Type': variant_type,\n",
    "                'Witnesses': split_into_witnesses(witnesses),\n",
    "                'Reading Info': parse_reading_entry(reading.strip()), #need to handle + and < as well as \n",
    "                'CrossReference': cross_reference\n",
    "            })\n",
    "        else: # this means that either there is a comment here in parenthesis, or a \"= א\" format in parenthesis.\n",
    "            decoded_input = process_input(clean_variant)\n",
    "            #if 'comment' in \n",
    "            if 'comment' in list(decoded_input.keys()):\n",
    "                processed_variants.append({\n",
    "                    'Comment': decoded_input['comment'],\n",
    "                    'CrossReference': cross_reference\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                if \"affirming variants\" in list(decoded_input.keys()):\n",
    "                    processed_variants.append({\n",
    "                        'Type': 'Affirming Variant',\n",
    "                        'Witnesses': split_into_witnesses(list(decoded_input['affirming variants'].keys())[0]),\n",
    "                        'CrossReference': cross_reference\n",
    "                    })\n",
    "                else: #its a \"affirming and unidentified\" type, which means there are two variants here\n",
    "                    witnesses = split_into_witnesses(list(decoded_input['affirming and unidentified'].keys())[0])\n",
    "                    processed_variants.append({\n",
    "                        'Type': 'Affirming Variant',\n",
    "                        'Witnesses': witnesses,\n",
    "                        'CrossReference': cross_reference\n",
    "                    })\n",
    "                    processed_variants.append({\n",
    "                        'Type': 'Unidentified Variant',\n",
    "                        'Witnesses': (witnesses[0][0],\"'\"),\n",
    "                        'CrossReference': cross_reference\n",
    "                    })\n",
    "                    \n",
    "\n",
    "    return processed_variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_apparatus_entries(entries, chapter):\n",
    "    processed_entries = []\n",
    "    current_verse = 1\n",
    "    for entry in entries:\n",
    "        if ']' in entry:\n",
    "            verse_lemma, entry_content = entry.split(']', 1)\n",
    "            #if digits, so there are verse numbers, if not, take the previous verse number\n",
    "            match = re.match(r'^(\\d+)(.*)', verse_lemma)\n",
    "            if match:\n",
    "                chapter, verses, lemmas = lemma_verse_processor(verse_lemma, chapter)\n",
    "                processed_entries.append({'Verse': verses, 'Lemma Info': lemmas, 'Entry': process_entry_variants(entry_content.strip())})\n",
    "                if type(verses)=='list':\n",
    "                    current_verse = verses[-1]\n",
    "                else:\n",
    "                    current_verse = verses\n",
    "            else: # no verse number, so take previous verse and process lemma separately\n",
    "                processed_entries.append({'Verse': current_verse, 'Lemma Info': process_lemma_with_range_and_diacritics(verse_lemma), 'Entry': process_entry_variants(entry_content.strip())})\n",
    "    \n",
    "        else:# no lemma, but still maybe verse number\n",
    "            match = re.match(r'^(\\d+)(.*)', entry)\n",
    "            if match:\n",
    "                verse, clean_entry = match.group(1), match.group(2)\n",
    "                processed_entries.append({'Verse': verse, 'Entry': process_entry_variants(clean_entry.strip())})\n",
    "                current_verse = verse\n",
    "            else: #no verse, use previous\n",
    "                processed_entries.append({'Verse': current_verse, 'Entry': process_entry_variants(entry.strip())})       \n",
    "\n",
    "    return processed_entries\n",
    "\n",
    "\n",
    "processed_entries = process_apparatus_entries(df[\"Entries\"][1], 'five')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6625a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22 וארשתיך – יהוה] ר!: כל הפסוק אינו מנוקד'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Entries\"][1][-6]#.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cadbc465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Verse': 5,\n",
       " 'Lemma Info': [{'lemma': 'ושתה֙'}],\n",
       " 'Entry': [{'Type': 'Variant',\n",
       "   'Witnesses': [['ל18'],\n",
       "    ['20', \"'\"],\n",
       "    ['29', \"'\"],\n",
       "    ['נ', \"'\"],\n",
       "    ['פ'],\n",
       "    ['ר'],\n",
       "    ['ק1', \"'\"]],\n",
       "   'Reading Info': {'Reading': 'ושתיה'},\n",
       "   'CrossReference': []},\n",
       "  {'Type': 'Variant',\n",
       "   'Witnesses': [['ל'],\n",
       "    ['ל18'],\n",
       "    ['20', \"'\"],\n",
       "    ['29'],\n",
       "    ['30'],\n",
       "    ['37'],\n",
       "    ['נ'],\n",
       "    ['ק'],\n",
       "    ['מ']],\n",
       "   'Reading Info': {'Reading': 'ושת֙', 'Comment': '(י)'},\n",
       "   'CrossReference': []},\n",
       "  {'Type': 'Affirming Variant',\n",
       "   'Witnesses': [['ל20', \"''\"], ['ק1', \"''\"], ['ש']],\n",
       "   'CrossReference': []}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_entries[12]#[\"Entry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bec1541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Verse': 1,\n",
       "  'Lemma Info': [{'lemma': '(פ)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל'], ['ל18'], ['פ'], ['ר'], ['מ']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 1,\n",
       "  'Lemma Info': [{'lemma': 'וְהיה', 'number': '(1)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'וַ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 1,\n",
       "  'Lemma Info': {'lemma1': [{'lemma': 'מספ֤ר'}],\n",
       "   'lemma2': [{'lemma': 'בני־ישראל֙'}]},\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'מספ֞ר בנ֤י ישראל֙'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 2,\n",
       "  'Lemma Info': [{'lemma': 'י֥ום'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'י֖'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 3,\n",
       "  'Lemma Info': [{'lemma': '(>)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 3,\n",
       "  'Lemma Info': [{'lemma': 'ולאחותיכם'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'], ['ר']],\n",
       "    'Reading Info': {'Reading': 'ולאחתיכם'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 4,\n",
       "  'Lemma Info': [{'lemma': 'הִיא'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['פ']],\n",
       "    'Reading Info': {'Reading': 'הִוא'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 4,\n",
       "  'Lemma Info': [{'lemma': 'זנונ֙יה֙'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ש']],\n",
       "    'Reading Info': {'Reading': 'זנוניה֙'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 4,\n",
       "  'Lemma Info': [{'lemma': 'מפניהָ'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל', '!']],\n",
       "    'Reading Info': {'Reading': 'ה', 'Comment': '(לא מנוקדת)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 5,\n",
       "  'Lemma Info': [{'lemma': 'ערמה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['נ'], ['פ', \"'\"], ['ר']],\n",
       "    'Reading Info': {'Reading': 'ערומה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 5,\n",
       "  'Lemma Info': [{'lemma': 'וה֨צגת֔יה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'], ['ש']],\n",
       "    'Reading Info': {'Reading': 'והצגת֔יה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 5,\n",
       "  'Lemma Info': [{'lemma': 'הולדהּ'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'הֿ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 5,\n",
       "  'Lemma Info': [{'lemma': 'ושתה֙'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'],\n",
       "     ['20', \"'\"],\n",
       "     ['29', \"'\"],\n",
       "     ['נ', \"'\"],\n",
       "     ['פ'],\n",
       "     ['ר'],\n",
       "     ['ק1', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'ושתיה'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ל'],\n",
       "     ['ל18'],\n",
       "     ['20', \"'\"],\n",
       "     ['29'],\n",
       "     ['30'],\n",
       "     ['37'],\n",
       "     ['נ'],\n",
       "     ['ק'],\n",
       "     ['מ']],\n",
       "    'Reading Info': {'Reading': 'ושת֙', 'Comment': '(י)'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Affirming Variant',\n",
       "    'Witnesses': [['ל20', \"''\"], ['ק1', \"''\"], ['ש']],\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 7,\n",
       "  'Lemma Info': [{'lemma': '(>)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 7,\n",
       "  'Lemma Info': [{'lemma': 'הבישה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'], ['29'], ['פ'], ['ק', \"'\"], ['ר']],\n",
       "    'Reading Info': {'Reading': 'הובישה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 7,\n",
       "  'Lemma Info': [{'lemma': 'מאהבי'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18']],\n",
       "    'Reading Info': {'Reading': 'מאהבו'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ל18', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"מְאַהבַי֙ קׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 8,\n",
       "  'Lemma Info': [{'lemma': '(>)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 8,\n",
       "  'Lemma Info': [{'lemma': 'שָׂך'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', 'מ\"ג']],\n",
       "    'Reading Info': {'Reading': '\"נׄאׄ מילין דחזי להון למכתב סמך וכתׄ שין...\"'},\n",
       "    'CrossReference': ['III', 'II']}]},\n",
       " {'Verse': 8,\n",
       "  'Lemma Info': [{'lemma': 'גדרהּ'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': 'ה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 8,\n",
       "  'Lemma Info': [{'lemma': 'ונתיבותיה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל29', \"'\"], ['ק1', \"'\"], ['ר']],\n",
       "    'Reading Info': {'Reading': 'ונתיבתיה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 9,\n",
       "  'Lemma Info': [{'lemma': 'אתם'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'], ['ק1', \"'\"], ['פ']],\n",
       "    'Reading Info': {'Reading': 'אותם'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 9,\n",
       "  'Lemma Info': [{'lemma': 'ואש֙ובה֙'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ש']],\n",
       "    'Reading Info': {'Reading': 'ואשובה֙'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 10,\n",
       "  'Lemma Info': [{'lemma': 'והתירוש'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['א', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'ותירוש'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'והתירש'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 10,\n",
       "  'Lemma Info': [{'lemma': 'וכ֨סף'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': 'וכ֙סף֙'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 10, 'Entry': [{'Comment': '', 'CrossReference': []}]},\n",
       " {'Verse': 11,\n",
       "  'Lemma Info': [{'lemma': 'אשוב'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['פ', \"'\"]],\n",
       "    'Reading Info': {'Sigla': '>', 'Reading': \"ותירושי] ק1' ר: ותירשי\"},\n",
       "    'CrossReference': ['III']}]},\n",
       " {'Verse': 11,\n",
       "  'Lemma Info': [{'lemma': 'במועדו'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'במעדו'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 11,\n",
       "  'Lemma Info': [{'lemma': 'והשמת֗י'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': 'ת֤'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 12,\n",
       "  'Lemma Info': [{'lemma': 'נבלתה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר'], ['ש', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'נבלותה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 13,\n",
       "  'Lemma Info': [{'lemma': 'משושהּ'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ש', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"גׄ פסוקׄ למערׄ כל מליהון מפק הׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 14,\n",
       "  'Lemma Info': [{'lemma': 'ה֙מה֙'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ש']],\n",
       "    'Reading Info': {'Reading': 'המה֙'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 14,\n",
       "  'Lemma Info': [{'lemma': 'הבְּעלים'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל37', '!']],\n",
       "    'Reading Info': {'Reading': 'בֳּ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 15,\n",
       "  'Lemma Info': [{'lemma': 'ותַּעד'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': 'תָּ'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['נ', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"פלג וַתָ֤עַד\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 15,\n",
       "  'Lemma Info': [{'lemma': 'וחליתהּ'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'וחלייתהֿ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 16,\n",
       "  'Lemma Info': [{'lemma': '(ס)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל'], ['ל18'], ['ש']],\n",
       "    'Reading Info': {'Reading': '(פ)'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ק1'], ['מ']],\n",
       "    'Reading Info': {'Reading': '(>)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 16,\n",
       "  'Lemma Info': [{'lemma': 'והלכתיה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18'], ['ק1', \"'\"], ['ר'], ['ש', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'והולכתיה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 16,\n",
       "  'Lemma Info': [{'lemma': 'על־'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל', '!']],\n",
       "    'Reading Info': {'Reading': 'על'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 17,\n",
       "  'Lemma Info': {'lemma1': [{'lemma': 'וכי֖ום'}],\n",
       "   'lemma2': [{'lemma': 'עלות֥ה'}]},\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'וכי֥ום עלות֖ה מא֥רץ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 17,\n",
       "  'Lemma Info': [{'lemma': 'עלותה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל'], ['ל29', \"'\"], ['ר']],\n",
       "    'Reading Info': {'Reading': 'עלתה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 18,\n",
       "  'Lemma Info': [{'lemma': '(>)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['נ']],\n",
       "    'Reading Info': {'Reading': '(פ)'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ל'], ['פ'], ['ק'], ['ק1'], ['ר'], ['ש'], ['מ']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Affirming Variant',\n",
       "    'Witnesses': [['ל18'], ['20'], ['29'], ['30']],\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 18,\n",
       "  'Lemma Info': [{'lemma': 'תקראי', 'number': '(1)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'תיקראי'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['ר', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"יתׄ יׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 18,\n",
       "  'Lemma Info': [{'lemma': 'ולא־'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"מוגׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 18,\n",
       "  'Lemma Info': [{'lemma': 'לי'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"מוגׄ\"'},\n",
       "    'CrossReference': ['II']},\n",
       "   {'Comment': 'אך היא שייכת לכאן)', 'CrossReference': []}]},\n",
       " {'Verse': 18,\n",
       "  'Lemma Info': [{'lemma': 'בעְלי'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['מ']],\n",
       "    'Reading Info': {'Reading': 'עֲ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 19,\n",
       "  'Lemma Info': [{'lemma': 'והסרתי'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20']],\n",
       "    'Reading Info': {'Reading': 'והסירתי'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 19,\n",
       "  'Lemma Info': [{'lemma': 'ולא־'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל20', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"מוגׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 20,\n",
       "  'Lemma Info': [{'lemma': 'ומלחמה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'מלחמה'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 20,\n",
       "  'Lemma Info': [{'lemma': 'אשבור'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'אשבר'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 20,\n",
       "  'Lemma Info': [{'lemma': 'לעולם'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'לעלם'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 21,\n",
       "  'Lemma Info': [{'lemma': 'ובחסד'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['פ', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'בחסד'},\n",
       "    'CrossReference': []},\n",
       "   {'Type': 'Variant',\n",
       "    'Witnesses': [['פ', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"לׄ ובסיפׄ מוגׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 22,\n",
       "  'Lemma Info': {'from': [{'lemma': 'וארשתיך'}], 'to': [{'lemma': 'יהוה'}]},\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר', '!']],\n",
       "    'Reading Info': {'Reading': 'כל הפסוק אינו מנוקד'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 22,\n",
       "  'Lemma Info': [{'lemma': 'באֱמונה'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18']],\n",
       "    'Reading Info': {'Reading': 'אְ'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 22,\n",
       "  'Lemma Info': [{'lemma': 'את־'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['פ', \"'\"]],\n",
       "    'Reading Info': {'Reading': 'כי אני'},\n",
       "    'CrossReference': ['III', 'II', 'I']}]},\n",
       " {'Verse': 23,\n",
       "  'Lemma Info': [{'lemma': '(פ)'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל'], ['ל29'], ['נ'], ['פ'], ['ק1'], ['ר'], ['מ']],\n",
       "    'Reading Info': {'Reading': '(ס)'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 23,\n",
       "  'Lemma Info': {'lemma1': [{'lemma': 'והי֣ה'}], 'lemma2': [{'lemma': '׀'}]},\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ל18', 'מ\"ק'], ['נ', 'מ\"ק'], ['ר', 'מ\"ק']],\n",
       "    'Reading Info': {'Reading': '\"לגׄ\"'},\n",
       "    'CrossReference': []}]},\n",
       " {'Verse': 24,\n",
       "  'Lemma Info': [{'lemma': 'התירוש'}],\n",
       "  'Entry': [{'Type': 'Variant',\n",
       "    'Witnesses': [['ר']],\n",
       "    'Reading Info': {'Reading': 'התירש'},\n",
       "    'CrossReference': []}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_entries#[0]#[\"Entry\"]#[16]['Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "0488ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(>)'"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_entries[0][\"Entry\"][1]['Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "6dc8ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"נפשוֹ גׄ מטעיין וסימנהׄ...\"'"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_entries[14][\"Entry\"][-6]['Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a1dc1d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"<...>שו קׄ\" + \"נפשו קׄ <...>פשם כתׄ וחד מן <...>לין דכתבין <...>וׄ תיבוׄ ק וׄ\"'"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_entries[14][\"Entry\"][1]['Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc94c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now need to process the reading, including sigla [+< <...>] and comments\n",
    "#also catch special marks in witnesses, like !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# old functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cadb22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_entry(text, previous_verse=None):\n",
    "    lemma, part_entry = split_full_entry(text)\n",
    "    lemma_dict = lemma_verse_processor(lemma)\n",
    "\n",
    "    # Use the previous verse if the current verse list is empty\n",
    "    if not lemma_dict['verses'] and previous_verse is not None:\n",
    "        lemma_dict['verses'] = previous_verse\n",
    "\n",
    "    # Split part_entry by '|'\n",
    "    if '|' in part_entry:\n",
    "        entry_parts = part_entry.split('|')\n",
    "    else:\n",
    "        entry_parts = [part_entry]\n",
    "\n",
    "    # Initialize a list to hold all processed parts\n",
    "    processed_parts = []\n",
    "\n",
    "    # Process each part separately\n",
    "    for part in entry_parts:\n",
    "        # Split part by ',' not inside parentheses\n",
    "        sub_parts = split_on_comma_not_in_parentheses(part)\n",
    "\n",
    "        # Process each sub-part using process_comma_entry\n",
    "        processed_sub_parts = [process_comma_entry(sub_part) for sub_part in sub_parts]\n",
    "\n",
    "        # Concatenate processed sub-parts for each part\n",
    "        processed_parts.append(processed_sub_parts)\n",
    "\n",
    "    # Combine processed parts. Assuming you want them as a nested list\n",
    "    decoded_entries = processed_parts\n",
    "\n",
    "    # Return the lemma_dict and decoded_entries, along with the verses used for this entry\n",
    "    return lemma_dict, decoded_entries, lemma_dict['verses']\n",
    "\n",
    "def split_on_comma_not_in_parentheses(part):\n",
    "    \"\"\"\n",
    "    Splits the string on ',' not inside parentheses.\n",
    "    \"\"\"\n",
    "    sub_parts = []\n",
    "    current_part = []\n",
    "    paren_depth = 0  # Track depth of parentheses\n",
    "\n",
    "    for char in part:\n",
    "        if char == '(':\n",
    "            paren_depth += 1\n",
    "        elif char == ')':\n",
    "            paren_depth -= 1\n",
    "        elif char == ',' and paren_depth == 0:\n",
    "            # At a top-level comma, split here\n",
    "            sub_parts.append(''.join(current_part))\n",
    "            current_part = []\n",
    "            continue\n",
    "\n",
    "        current_part.append(char)\n",
    "\n",
    "    # Add the last part if there's any\n",
    "    if current_part:\n",
    "        sub_parts.append(''.join(current_part))\n",
    "\n",
    "    return sub_parts\n",
    "\n",
    "def split_full_entry(text):\n",
    "    sliced_entry = text.split(sep=']')\n",
    "    lemma, entry = sliced_entry\n",
    "#         print(f\"lemma: {lemma}\")\n",
    "#         print(f\"entry: {entry}\")\n",
    "    return lemma, entry    \n",
    "\n",
    "def lemma_verse_processor(text):\n",
    "    # Simplified approach: first split into digits and lemmas\n",
    "    # Regex to match the verse numbers at the beginning\n",
    "    verse_regex = r'^(\\d+(?:–\\d+)?)\\s'\n",
    "    \n",
    "    # Extract verses\n",
    "    verses_match = re.match(verse_regex, text)\n",
    "    verses = list(map(int, verses_match.group(1).split('–'))) if verses_match else []\n",
    "    \n",
    "    # Isolate lemmas part by removing the verses\n",
    "    lemmas_part = text[len(verses_match.group(0)):].strip() if verses_match else text\n",
    "    return {\n",
    "        'verses': verses,\n",
    "        'lemmas': process_lemma_with_range_and_diacritics(lemmas_part)\n",
    "    }\n",
    "\n",
    "# Function to process individual lemmas or ranges, after the split,\n",
    "lemma_regex = r'(k|q)?\\s*([^\\d\\s]+)(\\d?\\,?\\d?)'#(\\d+(?:–\\d+)?)\\s\n",
    "\n",
    "def process_lemma_with_range_and_diacritics(lemma):\n",
    "    # Adjust regex to include diacritical marks and punctuation within Hebrew words\n",
    "    \n",
    "    \n",
    "    # Check for range indicated by \"–\" and process accordingly\n",
    "    if \"–\" in lemma:\n",
    "        from_lemma, to_lemma = lemma.split(\"–\")\n",
    "        return {\n",
    "            'from': process_individual_lemma(from_lemma.strip()),\n",
    "            'to': process_individual_lemma(to_lemma.strip())\n",
    "        }\n",
    "\n",
    "    # Split lemma if there are separate lemmas with \"/\"\n",
    "    split_lemmas = re.split(r'\\s*/\\s*', lemma) if '/' in lemma else [lemma]\n",
    "    \n",
    "    processed_lemmas = []\n",
    "    for split_lemma in split_lemmas:\n",
    "        processed = process_individual_lemma(split_lemma)\n",
    "        processed_lemmas.extend(processed)\n",
    "    \n",
    "    return processed_lemmas\n",
    "\n",
    "def process_individual_lemma(individual_lemma):\n",
    "    matches = re.findall(lemma_regex, individual_lemma)\n",
    "    processed_lemmas = []\n",
    "    for match in matches:\n",
    "        prefix, word, number = match\n",
    "        lemma_dict = {'lemma': word}\n",
    "        if prefix: lemma_dict[prefix] = True\n",
    "        if number: lemma_dict['number'] = (number)\n",
    "        processed_lemmas.append(lemma_dict)\n",
    "    return processed_lemmas\n",
    "\n",
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def extract_cross_references(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def parse_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d.]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_comma_witnesses(text):\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d*)?\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL | re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    # Filter out empty tuples\n",
    "    return [part for part in parts if any(part)]\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~\\.]*)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]*\\s?)[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def witness_reading_splitter(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>~.]*\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>~])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Reading\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n",
    "\n",
    "def process_comma_entry(entry):\n",
    "    clean_entry, cross_references = extract_cross_references(entry)\n",
    "    split_entry = witness_reading_splitter(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry[0])}\n",
    "        if len(split_entry) == 2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else:  # there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1] + split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': parse_comma_witnesses(split_entry)}\n",
    "        reading = ''\n",
    "    # Include \"Cross References\" only if the list is not empty\n",
    "    result = [witnesses, {\"Reading\": reading}]\n",
    "    if cross_references:\n",
    "        result.append({\"Cross References\": cross_references})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over full entries. get verse number from previous if needed. also get reading from lemma. and split on | ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "715948c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process lemma:\n",
    "#split into digits and lemmas. then process each separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "b18607da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'verses': [10], 'lemmas': [{'lemma': 'ואסרם'}]},\n",
       " [[({'Witnesses': [('', '96', 'pm')]},\n",
       "    {'Reading': {'Reading': 'יאשרם '}},\n",
       "    {'Cross References': []})],\n",
       "  [({'Witnesses': [('', '150', '')]},\n",
       "    {'Reading': {'Reading': 'על'}},\n",
       "    {'Cross References': []})]])"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[process_full_entry(example) for example in full_entries][-1]#[0]['verses']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "b8c31720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old function, didnt take the splitting into commas consideration\n",
    "# def process_full_entry(text):\n",
    "#     lemma, part_entry = split_full_entry(text)\n",
    "#     lemma_dict = lemma_verse_processor(lemma)\n",
    "# #     if len(lemma_dict['verses'])==0: #get verse from previous entry\n",
    "# #         lemma_dict['verses'] = \n",
    "        \n",
    "#     #entry_units = split_entry_units # splits on | and ,\n",
    "#     #for entry in entry_units:\n",
    "#     decoded_entry = process_entry(part_entry)\n",
    "#     return lemma_dict, decoded_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "4b9188ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing functions for sub-units of app_entry, for which there is matching lemma and verse data processed above\n",
    "\n",
    "def remove_and_list_roman_numerals(text): #extract cross-references\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "#splitting entry into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "\n",
    "def process_entry(entry):\n",
    "    clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "    split_entry = split_string(clean_entry)\n",
    "    if type(split_entry) is tuple:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "        if len(split_entry)==2:\n",
    "            reading = parse_reading_entry(split_entry[1])\n",
    "        else: #there are 3 groups:\n",
    "            reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "    else:\n",
    "        witnesses = {'Witnesses': custom_split_string(split_entry)}\n",
    "        reading = ''\n",
    "    return witnesses, {\"Reading\":reading}, {\"Cross References\":cross_references}\n",
    "\n",
    "\n",
    "# for entry in sample_texts:\n",
    "#     print(f\"entry: {entry}\")\n",
    "#     clean_entry, cross_references = remove_and_list_roman_numerals(entry)\n",
    "#     split_entry = split_string(clean_entry)\n",
    "#     if type(split_entry) is tuple:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry[0])}\n",
    "#         reading = parse_reading_entry(split_entry[1])\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#         print(f\"reading: {reading}\")\n",
    "#     else:\n",
    "#         witnesses = {'witnesses': custom_split_string(split_entry)}\n",
    "#         print(f\"witnesses: {witnesses}\")\n",
    "#     print(f\"references: {cross_references}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "cd41862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"96 (non voc)\",\n",
    "    \"30 (pm) 93 (pm) 150 (pm) + סךII IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))\",\n",
    "    \"93 (non voc) 96 150 (non voc) + את\",\n",
    "    \"30 (pm) >\",\n",
    "    \"30 + לי (non voc)I II\",\n",
    "    \"30 (pm) >I II IV (similarly b. Pesaḥim 87bmss)\",\n",
    "    \"93 (pm) ביהושעIV (similarly PesiqtaR 33 (153b))\",\n",
    "    \"96 >I II IV\",\n",
    "    \"130 k\",\n",
    "    \"G-B Msr 34 k ממני / q ממנוIV\",\n",
    "    \"93 כד..\",\n",
    "    \"150 ..דברים\",\n",
    "    \"G-B Eb 94 ותָעָד (understood as \\עוד (rather than \\עדי))\",\n",
    "    \"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "a0ae7422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Witnesses': [('', '93', 'pm')]},\n",
       " {'Reading': {'Reading': 'ביהושע ',\n",
       "   'Comment': '(similarly PesiqtaR 33 (153b))'}},\n",
       " {'Cross References': ['IV']})"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_entry(sample_texts[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "2a94af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'}"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_entry, cross_references = remove_and_list_roman_numerals(sample_texts[6])\n",
    "split_entry = split_string(clean_entry)\n",
    "if type(split_entry) is tuple:\n",
    "    witnesses = {'Witnesses': custom_split_string(split_entry[0])}\n",
    "    if len(split_entry)==2:\n",
    "        reading = parse_reading_entry(split_entry[1])\n",
    "    else: #there are 3 groups:\n",
    "        reading = parse_reading_entry(split_entry[1]+split_entry[2])\n",
    "\n",
    "reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "08fa1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', '30', 'pm'), ('', '93', ''), ('', '150', 'pm')]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_split_string(text): #process witnesses\n",
    "    pattern = re.compile(r'\\s?([^\\d]*?)?(\\d+)\\s?\\(?([^\\)\\d]+)?\\)?', re.DOTALL|re.UNICODE)    \n",
    "    #pattern = r'([^,\\d]*?)?(\\d+)\\s?(\\(([^\\)]+)?\\)?)?([\\skq]?)+'\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "# \"96 (non voc)\",\n",
    "# \"30 (pm) 93 (pm) 150 (pm)\n",
    "test_witness = \"30 (pm) 93 150 (pm)\"\n",
    "custom_split_string(test_witness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "fbefcdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['96 (non voc)', ('30 (pm) 93 (pm) 150 (pm) ', '+ סך', 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'), ('93 (non voc) 96 150 (non voc) ', '+ את', ''), ('30 (pm) ', '>', ''), ('30 ', '+ לי', ' (non voc)I II'), ('30 (pm) ', '>', 'I II IV (similarly b. Pesaḥim 87bmss)'), ('93 (pm)', ' ביהושע', 'IV (similarly PesiqtaR 33 (153b))'), ('96 ', '>', 'I II IV'), ('130', ' k', ''), ('G-B Msr 34', ' k', ' ממני / q ממנוIV'), ('93', ' כד', '..'), ('150 ..', 'דברים', ''), ('G-B Eb 94', ' ותָעָד', ' (understood as \\\\עוד (rather than \\\\עדי))'), ('30 89 (sm) 93 (pm) 150 (non voc) ', '+ כי', 'I II IV')]\n"
     ]
    }
   ],
   "source": [
    "#try parsing single entry app, splitting into witnesses and reading (if only one group assign to witnesses)\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'(.*?)?([\\+<>]?\\s?[kq\\u0590-\\u05FF]+)(.*)?', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        pattern = re.compile(r'(.*?)([\\+<>])(.*)?', re.DOTALL)\n",
    "        match = pattern.match(text)\n",
    "        if match:\n",
    "            return match.groups()  # Returns a tuple with the three parts\n",
    "        else:\n",
    "            return text\n",
    "        return text  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "processed_sample = [split_string(text) for text in sample_texts]\n",
    "\n",
    "print(processed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "473068c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Reading': 'סך ',\n",
       "  'Comment': '(See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'},\n",
       " {'Sigla': '+', 'Reading': 'את'},\n",
       " {'Sigla': '>'},\n",
       " {'Sigla': '+', 'Reading': 'לי ', 'Comment': '(non voc)'},\n",
       " {'Sigla': '>', 'Comment': '(similarly b. Pesaḥim 87bmss)'},\n",
       " {'Reading': 'ביהושע ', 'Comment': '(similarly PesiqtaR 33 (153b))'},\n",
       " {},\n",
       " {'Reading': 'k'},\n",
       " {'Reading': 'k ממני / q ממנו'},\n",
       " {'Reading': 'כד..'},\n",
       " {'Reading': '..דברים'},\n",
       " {'Reading': 'נַחֵם ',\n",
       "  'Comment': '(taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)'},\n",
       " {'Reading': 'חכֵם ', 'Comment': '(!)'}]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for parsing the reading+comment (assumes witnesses and cross references have been removed)\n",
    "def parse_reading_entry(entry):\n",
    "    # Refined regex pattern\n",
    "    pattern = r\"\"\"\n",
    "        \\s?(?P<Sigla>[+<>~]?)                         # Captures special sigla\n",
    "        \\s*\n",
    "        (?P<Reading>(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*    # Hebrew reading, including 'k', 'q'\n",
    "                   (?:/\\s(?:[kq]?\\s?)?[\\u0590-\\u05FF\\uFB1D-\\uFB4F\\s.]*)?)  # Allows for 'k'/'q' followed by Hebrew, separated by '/'\n",
    "        \\s*\n",
    "        (?P<Comment>\\(.*\\))?                     # Captures comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compiling regex with VERBOSE flag for better readability and explanation\n",
    "    compiled_pattern = re.compile(pattern, re.VERBOSE)\n",
    "    match = compiled_pattern.match(entry)\n",
    "\n",
    "    if not match:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "    # Extracting groups into a dictionary\n",
    "    parsed_entry = {k: v for k, v in match.groupdict().items() if v}\n",
    "\n",
    "    return parsed_entry\n",
    "\n",
    "# Process the sample reading texts with the refined function\n",
    "parse_reading_entry = [parse_reading_entry(text) for text in sample_reading_texts]\n",
    "\n",
    "parse_reading_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "94a5de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [{'witnesses': '30 (pm) 93 (pm) 150 (pm)', 'reading': '+ סך', 'comments': 'II IV (See b. R.HaŠanamss 23b, (LamR) Buber 1:16 (40b))'}], [{'witnesses': '93 (non voc) 96 150 (non voc)', 'reading': '+ את', 'comments': ''}], [], [{'witnesses': '30', 'reading': '+ לי', 'comments': '(non voc)I II'}], [], [{'witnesses': '93 (pm)', 'reading': 'ביהושע', 'comments': 'IV (similarly PesiqtaR 33 (153b))'}], [], [], [{'witnesses': 'G-B Msr 34 k', 'reading': 'ממני', 'comments': '/ q ממנוIV'}], [{'witnesses': '93', 'reading': 'כד', 'comments': '..'}], [{'witnesses': '150 ..', 'reading': 'דברים', 'comments': ''}], [{'witnesses': 'G-B Eb 94', 'reading': 'ותָעָד', 'comments': '(understood as \\\\עוד (rather than \\\\עדי))'}], [{'witnesses': '30 89 (sm) 93 (pm) 150 (non voc)', 'reading': '+ כי', 'comments': 'I II IV'}]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_string_processor(input_string, regex_pattern):\n",
    "    # Helper function to apply regex and extract groups\n",
    "    def apply_regex_and_extract(text):\n",
    "        matches = re.finditer(regex_pattern, text)\n",
    "        results = []\n",
    "        for match in matches:\n",
    "            results.append({\n",
    "                'witnesses': match.group(1).strip(),\n",
    "                'reading': match.group(2).strip(),\n",
    "                'comments': match.group(3).strip() if match.group(3) else ''\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    # Process splits with \"|\", then \",\"\n",
    "    def process_splits(text, delimiter):\n",
    "        parts = text.split(delimiter)\n",
    "        processed_parts = []\n",
    "        for part in parts:\n",
    "            # Apply regex to each part\n",
    "            processed = apply_regex_and_extract(part)\n",
    "            if processed:\n",
    "                processed_parts.extend(processed)\n",
    "        return processed_parts\n",
    "\n",
    "    # Start processing\n",
    "    processed_result = process_splits(input_string, '|')  # Start with the highest level of split\n",
    "\n",
    "    return processed_result\n",
    "\n",
    "# Custom regex pattern as provided\n",
    "custom_regex = r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$'\n",
    "\n",
    "# Test with the provided sample input\n",
    "sample_input = \"G-B msr. 30 (pm) G-A 89 (sm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) + שערורהIV II (bla bla (f)) | 150 >\"\n",
    "processed_sample = [custom_string_processor(text, custom_regex) for text in sample_texts]\n",
    "\n",
    "\n",
    "print(processed_sample)\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "# text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "# split_parts = split_string(text)\n",
    "# if split_parts:\n",
    "#     print(\"witnesses:\", split_parts[0])\n",
    "#     print(\"reading:\", split_parts[1])\n",
    "#     print(\"After dividers:\", split_parts[2])\n",
    "# else:\n",
    "#     print(\"No dividers found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5b4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_apparatus_entry(entry):\n",
    "    \"\"\"Parse an apparatus entry into lemma(s) and content.\"\"\"\n",
    "    parts = entry.split(']')\n",
    "    lemmas_contents = []\n",
    "    for part in parts:\n",
    "        if part.strip():\n",
    "            lemma, content = part.split('[', 1) if '[' in part else (part, '')\n",
    "            lemmas_contents.append((lemma.strip(), content.strip()))\n",
    "    return lemmas_contents\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    \"\"\"Create a TEI document from apparatus lines.\"\"\"\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    NSMAP = {\"tei\": TEI_NAMESPACE}\n",
    "    \n",
    "    tei_root = ET.Element(TEI+\"TEI\", nsmap=NSMAP)\n",
    "    tei_header = ET.SubElement(tei_root, TEI+\"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI+\"text\")\n",
    "    body = ET.SubElement(text, TEI+\"body\")\n",
    "    current_chapter = None\n",
    "    last_verse = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1]\n",
    "            current_chapter = ET.SubElement(body, TEI+\"div\", type=\"chapter\", n=chapter_number)\n",
    "            last_verse = None\n",
    "            continue\n",
    "        # Use regex to check if the line starts with a verse number and capture it\n",
    "        match = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "        if match:\n",
    "            verse_number, entry = match.groups()\n",
    "            last_verse = verse_number\n",
    "        else:\n",
    "            entry = line\n",
    "            verse_number = last_verse\n",
    "        \n",
    "        if current_chapter is not None and verse_number:\n",
    "            lemmas_contents = parse_apparatus_entry(entry)\n",
    "            for lemma, content in lemmas_contents:\n",
    "                app = ET.SubElement(current_chapter, TEI+\"app\")\n",
    "                lem = ET.SubElement(app, TEI+\"lem\", n=verse_number)\n",
    "                lem.text = lemma\n",
    "                if content:\n",
    "                    rdg = ET.SubElement(app, TEI+\"rdg\")\n",
    "                    rdg.text = content\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    \"\"\"Save the TEI XML tree to a file.\"\"\"\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caaa3e86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line does not conform to expected format: ﻿App III: Hosea\n",
      "Line does not conform to expected format: יחזקיה] 30 93 (pm) 96 יחזקיהו\n",
      "Line does not conform to expected format: ירבעם בן] 30 + נבט (non voc)\n",
      "Line does not conform to expected format: לו] 96 >I  II IV\n",
      "Line does not conform to expected format: ממלכוּת] 96 ממלכוֹת\n",
      "Line does not conform to expected format: יזרעאל] 150 ישראל (parall; but 150-Tg: יזרעאל)\n",
      "Line does not conform to expected format: כי] 93 (pm) + את\n",
      "Line does not conform to expected format: אוסיף] 150 (pm) >\n",
      "Line does not conform to expected format: את] 93 (pm) >\n",
      "Line does not conform to expected format: בסוסים] 96 ובסוסיםI IV\n",
      "Line does not conform to expected format: אשר2] 96 + לא\n",
      "Line does not conform to expected format: אחד] 30 (pm) 150 (pm) >\n",
      "Line does not conform to expected format: והצגתיה] 93 (pm) + כיום ערומה והצגתיה\n",
      "Line does not conform to expected format: ושתִּה] 150 (pm) ושמתיה\n",
      "Line does not conform to expected format: כי] 150 (non voc) + כי\n",
      "Line does not conform to expected format: שכְחה] 150 (pm) שכחת\n",
      "Line does not conform to expected format: מפתיה] 89 מְפַּתֶיהָ\n",
      "Line does not conform to expected format: המדבר] 96 המדברה (similarly SifreDeut 313 (356:6), RuthR 5:6)\n",
      "Line does not conform to expected format: תקראי1] 150 (pm) תקראו | 30 + לי (non voc)I II\n",
      "Line does not conform to expected format: לי] G-B Eb 54 (pm) >II\n",
      "Line does not conform to expected format: עוד] 30 (pm?) >\n",
      "Line does not conform to expected format: את] 30 89 (sm) 93 (pm) אניI II IV\n",
      "Line does not conform to expected format: לא] 96 ולאI\n",
      "Line does not conform to expected format: תזני] 93 (pm) תתי (Caused by ligature ז+נ)\n",
      "Line does not conform to expected format: אליך] 93 (pm) אלהיך\n",
      "Line does not conform to expected format: וגם] 30 (pm) וכל\n",
      "Line does not conform to expected format: אתה] 96 (pm) את\n",
      "Line does not conform to expected format: k ואמאסאך / q ואמאסך] 30 93 (sm) 96 150 (pm) q IV | 93 (pm) אמסך\n",
      "Line does not conform to expected format: ותשכח] 150 (pm) תשכחי\n",
      "Line does not conform to expected format: נפשו] 89 (pm) 96 (pm) 150 (pm) נפשםI IV\n",
      "Line does not conform to expected format: עליו] 96 + ודמו (non voc)\n",
      "Line does not conform to expected format: דרכיו] 30 (pm) כדרכיו\n",
      "Line does not conform to expected format: הזנו] 150 (pm) והזנו\n",
      "Line does not conform to expected format: כי] 96 >\n",
      "Line does not conform to expected format: צלה] 93 (pm) יגלה\n",
      "Line does not conform to expected format: וכלותיכם] 150 (pm) + כי\n",
      "Line does not conform to expected format: הזֹנות] 93 (pm) זנות\n",
      "Line does not conform to expected format: יְפָרדו] 93 96 יִפָּרדו\n",
      "Line does not conform to expected format: ואל1] 150 (pm) אלI IV\n",
      "Line does not conform to expected format: ואַל3] 30 ואֵל\n",
      "Line does not conform to expected format: אהבו] 93 (pm) אתם\n",
      "Line does not conform to expected format: קלון] 150 (pm) קלו\n",
      "Line does not conform to expected format: מגניה] 96 (pm) מקלון\n",
      "Line does not conform to expected format: מִזִּבְחותם] 30 93 150 מִזְבְּחתםI IV | 96 מִזְבְחותם\n",
      "Line does not conform to expected format: אל] 93 (pm) + אלI IV\n",
      "Line does not conform to expected format: בקרבם] 96 (pm) בקרבכם\n",
      "Line does not conform to expected format: עמם] 93 (pm) עמכם\n",
      "Line does not conform to expected format: את] 93 + דבר (non voc)II IV\n",
      "Line does not conform to expected format: עתה] 93 (pm) ועתה\n",
      "Line does not conform to expected format: את] 30 (pm) >\n",
      "Line does not conform to expected format: בית] 150 בין (similarly b. R.HaŠanams 32b)\n",
      "Line does not conform to expected format: אחריך] 93 (pm) >\n",
      "Line does not conform to expected format: גבול] 93 + עולם (non voc) (cf גבול עולם Prov 2228 2310)\n",
      "Line does not conform to expected format: וְכָרקב] 93 96 וּכְרקב\n",
      "Line does not conform to expected format: וישלח] 93 מ..\n",
      "Line does not conform to expected format: מיֹמים] 30 (pm?) >\n",
      "Line does not conform to expected format: כמלקוש] 150 (pm) ומלקושI II IV\n",
      "Line does not conform to expected format: מה2] 30 93 150 (pm) ומהI\n",
      "Line does not conform to expected format: לְךָ2] 96 לָךְ | 30 (pm) + אפרים\n",
      "Line does not conform to expected format: וחסדכם] 93 150 חסדכםI\n",
      "Line does not conform to expected format: הֹלך] 96 והולךI\n",
      "Line does not conform to expected format: חבר] 93 (pm) וחבר\n",
      "Line does not conform to expected format: שׁם] 96 שׂם\n",
      "Line does not conform to expected format: וגנב] 30 וכגנב\n",
      "Line does not conform to expected format: פשט] 93 (pm) ופשטI (similarly S.Eli.R 22 (125))\n",
      "Line does not conform to expected format: בחוץ] 96 (pm) בחרץ\n",
      "Line does not conform to expected format: מעיר] 96 (sm) עיר\n",
      "Line does not conform to expected format: מלוש] 150 (pm) בלוש\n",
      "Line does not conform to expected format: שרים] 30 (pm) >\n",
      "Line does not conform to expected format: ידו את] 30 ~\n",
      "Line does not conform to expected format: אֹפֵהֶם] 93 (pm) אפריםI\n",
      "Line does not conform to expected format: לב] 89 (pm) לבי\n",
      "Line does not conform to expected format: איסירם] 30 89 איסרם | 96 (pm) אייסרם, (sm) אייסירים | 150 (pm) אסירים\n",
      "Line does not conform to expected format: פשעוּ] 96 פשעִי\n",
      "Line does not conform to expected format: ואנכי] 150 (pm) ואניIV\n",
      "Line does not conform to expected format: דברו] 93 (pm) >\n",
      "Line does not conform to expected format: בלבם] 93 (pm) בלבבםIV\n",
      "Line does not conform to expected format: יתגוררו] 93 (pm) >\n",
      "Line does not conform to expected format: על היו] 150 (pm) ~\n",
      "Line does not conform to expected format: זוֹ] 96 זוּ\n",
      "Line does not conform to expected format: עברו] 96 (pm) עבר\n",
      "Line does not conform to expected format: תורָתי] 89 (pm) תורֹתי\n",
      "Line does not conform to expected format: בו] 96 בֹה\n",
      "Line does not conform to expected format: שרים] 96 150 ושריםI II IV\n",
      "Line does not conform to expected format: אפרים] 30 (pm) ישראל\n",
      "Line does not conform to expected format: לו] 93 (pm) לי\n",
      "Line does not conform to expected format: k רבו / q רבי] 30 89 93 96 q, 150 (pm) רובו\n",
      "Line does not conform to expected format: יהוה] 150 (pm) ויהוהI IV\n",
      "Line does not conform to expected format: עתה] 150 (pm) ועתה\n",
      "Line does not conform to expected format: חטֹאותם] 89 93 96 150 (pm) חטאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: המה] 150 (pm) והמהIV\n",
      "Line does not conform to expected format: הרבה] 30 (pm) + מזבחות\n",
      "Line does not conform to expected format: ואכלה] 150 (pm) + כל\n",
      "Line does not conform to expected format: ארמנתיה] 93 (pm) ארמנותיו\n",
      "Line does not conform to expected format: בית] 93 (pm) >\n",
      "Line does not conform to expected format: לכספם] 150 לנפשם\n",
      "Line does not conform to expected format: אויל] 96 (pm) >\n",
      "Line does not conform to expected format: רֹב] 96 רַב\n",
      "Line does not conform to expected format: עונְךָ] 96 עונֵךְ\n",
      "Line does not conform to expected format: ורבה] 150 (pm) רבהIV\n",
      "Line does not conform to expected format: נביא] 96 (pm) הנביא\n",
      "Line does not conform to expected format: יקוֹש] 93 96 יקוּש\n",
      "Line does not conform to expected format: חטאותם] 89 93 150 (pm) חטֹאתם, 30 חטָאתם\n",
      "Line does not conform to expected format: וַינזרו] 30 וְינזרו\n",
      "Line does not conform to expected format: ויהיו] 96 (pm) ויהי\n",
      "Line does not conform to expected format: רחם] 96 (pm) מרחם\n",
      "Line does not conform to expected format: מביתי] 93 (pm) מביתIV\n",
      "Line does not conform to expected format: ילדון] 93 (pm) ילזון\n",
      "Line does not conform to expected format: לו] 150 >\n",
      "Line does not conform to expected format: למזבחות] 93 (pm) למזבח\n",
      "Line does not conform to expected format: יָרֵאנו] 30 יַרְאֵנו\n",
      "Line does not conform to expected format: כרֹת] 96 (pm) וכרותI\n",
      "Line does not conform to expected format: ופרח] 150 (pm) ופתח\n",
      "Line does not conform to expected format: וכְמריו] G-B Msr 34 כֹ\n",
      "Line does not conform to expected format: יגילו] 150 (sm) יגלו\n",
      "Line does not conform to expected format: על] 93 (pm) ועל\n",
      "Line does not conform to expected format: ממנו] 96 (pm) ממני\n",
      "Line does not conform to expected format: מלכהּ] 93 (pm) מלכם\n",
      "Line does not conform to expected format: מים] 93 (pm) המים\n",
      "Line does not conform to expected format: כַּסונו] 89 כִּסונו (?)\n",
      "Line does not conform to expected format: חטאתָ] 93 (sm) 96 (sm) חטא (ת non voc)\n",
      "Line does not conform to expected format: עלוה] 89 (sm) עולהI\n",
      "Line does not conform to expected format: k עינתם / q עונֹתם] 30 k, 89 G-B Eb 16 q, 93 96 150 (pm) עונותם\n",
      "Line does not conform to expected format: ועת] 150 (pm) עת\n",
      "Line does not conform to expected format: לדרוש] 96 >\n",
      "Line does not conform to expected format: את] 30 (pm) >, 96 (non voc)\n",
      "Line does not conform to expected format: יהוה] 93 (pm) יהודה\n",
      "Line does not conform to expected format: ויֹרה] 93 (pm) G-B Eb 16 יורה\n",
      "Line does not conform to expected format: שלמן] 96 שלומך\n",
      "Line does not conform to expected format: ארבֵאל] 93 ארבְּאֵל\n",
      "Line does not conform to expected format: ולפסִלים] 96 לפסילים\n",
      "Line does not conform to expected format: רפאתים] 96 (pm) רפאתיו\n",
      "Line does not conform to expected format: לחֵיהם] 30 93 לחָיֵיהם\n",
      "Line does not conform to expected format: ממֹעצותיהם] 96 (pm) ממעֲוצותיהם\n",
      "Line does not conform to expected format: למשובתי] 30 (pm) למשבתוI\n",
      "Line does not conform to expected format: ולא2] 93 (sm) 150 (pm) לאII IV\n",
      "Line does not conform to expected format: ושֹׁד] 93 (pm) >\n",
      "Line does not conform to expected format: וברית] 96 (pm) ובריית\n",
      "Line does not conform to expected format: ישיב] 30 (pm) 150 (pm) אשיבI\n",
      "Line does not conform to expected format: בגלגל] 150 (pm) ובגלגל\n",
      "Line does not conform to expected format: זבחו] 93 (pm) >\n",
      "Line does not conform to expected format: גם מזבחותם] 96 >\n",
      "Line does not conform to expected format: ויושיעֲך] 96 (pm) ויושיעוך\n",
      "Line does not conform to expected format: לי] 96 לנו\n",
      "Line does not conform to expected format: הוא] 93 (pm) 150 (pm) והואIV\n",
      "Line does not conform to expected format: לא1] 93 ולא\n",
      "Line does not conform to expected format: דבריך] 30 93 (pm) 96 דברךI II IV\n",
      "Line does not conform to expected format: נֹחם] G-B Msr 34 נַחֵם (taken as infinitive, see Yeivin, Babylonian Vocalization, 1:542)\n",
      "Line does not conform to expected format: ויבוש] 93 (pm) תיבש\n",
      "Line does not conform to expected format: הוא2] 93 (pm) 96 150 (pm) והואI II\n",
      "Line does not conform to expected format: אמרו] 30 (pm) 93 (pm) 96 150 (pm) ואמרוII IV\n",
      "Line does not conform to expected format: כל] 89 (pm) בלI\n",
      "Line does not conform to expected format: וצדקים] 96 צדיקים\n",
      "Line does not conform to expected format: ‏App III: Hosea\n",
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    \n",
    "    tei_root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    tei_header = ET.SubElement(tei_root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(tei_root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    current_chapter = None\n",
    "    last_verse_number = None\n",
    "    \n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('Chapter'):\n",
    "            chapter_number = line.split(' ')[1].strip()\n",
    "            current_chapter = ET.SubElement(body, TEI + \"div\", type=\"chapter\", n=chapter_number)\n",
    "        else:\n",
    "            # Attempt to extract verse number and lemma content\n",
    "            parts = re.match(r\"^(\\d+)\\s*(.*)\", line)\n",
    "            if parts:\n",
    "                verse_number, remainder = parts.groups()\n",
    "                last_verse_number = verse_number  # Update last verse number with current\n",
    "                \n",
    "                # Further split to separate lemma from variants, if present\n",
    "                lemma_section, variants_section = remainder.split(']', 1) if ']' in remainder else (remainder, \"\")\n",
    "                lemma_section = lemma_section.strip()\n",
    "                variants_section = variants_section.strip()\n",
    "\n",
    "                if current_chapter is not None and verse_number:\n",
    "                    # Create an apparatus entry for the lemma\n",
    "                    app = ET.SubElement(current_chapter, TEI + \"app\")\n",
    "                    lem = ET.SubElement(app, TEI + \"lem\", n=verse_number)\n",
    "                    lem.text = lemma_section\n",
    "                    \n",
    "                    # Add variant readings if present\n",
    "                    if variants_section:\n",
    "                        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "                        rdg.text = variants_section\n",
    "            else:\n",
    "                print(f\"Line does not conform to expected format: {line}\")\n",
    "\n",
    "    return ET.ElementTree(tei_root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\", short_empty_elements=True)\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808c9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    app = ET.Element(TEI + \"app\")\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, TEI + \"lem\")\n",
    "    lem.text = lemma_text.strip()\n",
    "    \n",
    "    # Extract comments\n",
    "    comments = re.findall(r'\\((.*?)\\)', rest)\n",
    "    for comment in comments:\n",
    "        note = ET.SubElement(app, TEI + \"note\")\n",
    "        note.text = comment\n",
    "    \n",
    "    # Remove comments from rest for further processing\n",
    "    rest = re.sub(r'\\(.*?\\)', '', rest).strip()\n",
    "    \n",
    "    # Extract and process witnesses and cross-references\n",
    "    if rest:\n",
    "        rdg = ET.SubElement(app, TEI + \"rdg\")\n",
    "        witnesses, _, variant_reading = rest.partition(' ')\n",
    "        if witnesses:\n",
    "            rdg.set('wit', witnesses.strip())\n",
    "        if variant_reading:\n",
    "            rdg.text = variant_reading.strip()\n",
    "        \n",
    "        # Extract cross-references, assuming they are indicated by Roman numerals at the start\n",
    "        cross_refs = re.findall(r'\\bI{1,3}V?|\\bIV', rest)\n",
    "        for ref in cross_refs:\n",
    "            ref_element = ET.SubElement(rdg, TEI + \"ref\")\n",
    "            ref_element.set('target', '#' + ref)  # Assuming target IDs are prefixed with '#'\n",
    "            ref_element.text = \"See apparatus entry \" + ref\n",
    "    \n",
    "    return app\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    TEI = \"{%s}\" % TEI_NAMESPACE\n",
    "    root = ET.Element(TEI + \"TEI\", xmlns=TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, TEI + \"teiHeader\")\n",
    "    text = ET.SubElement(root, TEI + \"text\")\n",
    "    body = ET.SubElement(text, TEI + \"body\")\n",
    "    div = ET.SubElement(body, TEI + \"div\")\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI)\n",
    "            div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a6244acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "witnesses: G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) \n",
      "reading: > שערורה\n",
      "After dividers: IV (bla bla (f))\n"
     ]
    }
   ],
   "source": [
    "#split entry into witnesses, reading, and comments \n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()  # Returns a tuple with the three parts\n",
    "    else:\n",
    "        return None  # No divider matching the pattern was found\n",
    "\n",
    "# Example usage\n",
    "text = \"G-B msr. 30 (pm) G-A 89 (pm?) 150 (sm) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV (bla bla (f))\"#\"30 89 (sm) 93 (pm) 150 (non voc) + כיI II IV\"#\"93 (pm) < ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "split_parts = split_string(text)\n",
    "if split_parts:\n",
    "    print(\"witnesses:\", split_parts[0])\n",
    "    print(\"reading:\", split_parts[1])\n",
    "    print(\"After dividers:\", split_parts[2])\n",
    "else:\n",
    "    print(\"No dividers found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "70cc4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('G-B msr. ', '30', 'pm'), ('G-A ', '89', 'pm?'), ('', '150', 'non voc'), ('', '30', 'sm'), ('', '89', 'sm'), ('', '93', 'sm'), ('MS-G ', '150', 'pm')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "25936b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified text: (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\n",
      "Numerals found: ['II', 'IV']\n"
     ]
    }
   ],
   "source": [
    "#parse comments\n",
    "import re\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    # Regex to match some Roman numerals: sequences of \"I\"s followed by an optional \"V\"\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    # Find all occurrences of the pattern\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    # Remove empty matches from the list\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    # Replace found Roman numerals with an empty string\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# Example usage\n",
    "text = \"II IV (See b. R.HaŠanamss 23b, LamR Buber 1:16 (40b))\"\n",
    "result_text, numerals_found = remove_and_list_roman_numerals(text)\n",
    "print(\"Modified text:\", result_text.strip())\n",
    "print(\"Numerals found:\", numerals_found)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d33f9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entry(entry):\n",
    "    split_parts = split_string(entry)\n",
    "    if split_parts is None:\n",
    "        return None\n",
    "    \n",
    "    witnesses, reading, comments = split_parts\n",
    "\n",
    "    structured_entry = {\n",
    "        'witnesses': [],\n",
    "        'reading': reading,\n",
    "        'comments': '',\n",
    "        'cross_references': []\n",
    "    }\n",
    "\n",
    "    for part in custom_split_string(witnesses):\n",
    "        # Assuming part[1] contains the witness number and part[0], part[2], part[3] contain additional info\n",
    "        witness_info = {\n",
    "            'n': part[1],\n",
    "            'text': f\"{part[0]}{part[1]} {part[2].strip()}{part[3]}\"\n",
    "        }\n",
    "        structured_entry['witnesses'].append(witness_info)\n",
    "\n",
    "    comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "    structured_entry['comments'] = comments_text\n",
    "    structured_entry['cross_references'] = numerals_found\n",
    "\n",
    "    return structured_entry\n",
    "\n",
    "def create_apparatus_entry(verse_number, content, TEI):\n",
    "    \"\"\"Create TEI element for an apparatus entry.\"\"\"\n",
    "    TEI_ns = {'tei': TEI}  # Define the namespace dictionary if needed\n",
    "    app = ET.Element(f\"{{{TEI}}}app\")  # Using namespace in the tag\n",
    "    \n",
    "    # Extract lemma text and the rest (witnesses, variant reading, and comments)\n",
    "    lemma_text, _, rest = content.partition(']')\n",
    "    lem = ET.SubElement(app, f\"{{{TEI}}}lem\")\n",
    "    lem.text = lemma_text.strip('[] ')\n",
    "\n",
    "    structured_entry = process_entry(rest)\n",
    "    if not structured_entry:\n",
    "        return None\n",
    "\n",
    "    for witness in structured_entry['witnesses']:\n",
    "        wit_element = ET.SubElement(app, f\"{{{TEI}}}wit\", {'n': witness['n']})\n",
    "        wit_element.text = witness['text']\n",
    "    \n",
    "    rdg_element = ET.SubElement(app, f\"{{{TEI}}}rdg\")\n",
    "    rdg_element.text = structured_entry['reading']\n",
    "\n",
    "    if structured_entry['comments']:\n",
    "        comment_element = ET.SubElement(app, f\"{{{TEI}}}note\")\n",
    "        comment_element.text = structured_entry['comments']\n",
    "\n",
    "    for ref in structured_entry['cross_references']:\n",
    "        ref_element = ET.SubElement(app, f\"{{{TEI}}}ref\")\n",
    "        ref_element.text = ref\n",
    "\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8e18d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI document has been saved to apparatus_tei.xml.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "def create_tei_document(apparatus_lines):\n",
    "    TEI_NAMESPACE = \"http://www.tei-c.org/ns/1.0\"\n",
    "    ET.register_namespace('', TEI_NAMESPACE)  # Register the default namespace\n",
    "\n",
    "    # Create the root element without redundantly specifying the xmlns attribute\n",
    "    root = ET.Element(\"{%s}TEI\" % TEI_NAMESPACE)\n",
    "    header = ET.SubElement(root, \"{%s}teiHeader\" % TEI_NAMESPACE)\n",
    "    text = ET.SubElement(root, \"{%s}text\" % TEI_NAMESPACE)\n",
    "    body = ET.SubElement(text, \"{%s}body\" % TEI_NAMESPACE)\n",
    "    div = ET.SubElement(body, \"{%s}div\" % TEI_NAMESPACE)\n",
    "    \n",
    "    last_verse_number = None\n",
    "    for line in apparatus_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Determine if the line starts with a verse number\n",
    "        match = re.match(r'^(\\d+)', line)\n",
    "        if match:\n",
    "            last_verse_number = match.group(1)\n",
    "            content = line[len(last_verse_number):].strip()\n",
    "        else:\n",
    "            content = line\n",
    "        \n",
    "        if last_verse_number:\n",
    "            entry = create_apparatus_entry(last_verse_number, content, TEI_NAMESPACE)\n",
    "            if entry is not None:  # Ensure entry creation was successful\n",
    "                div.append(entry)\n",
    "    \n",
    "    return ET.ElementTree(root)\n",
    "\n",
    "def save_tei_file(tree, filename):\n",
    "    tree.write(filename, encoding=\"UTF-8\", xml_declaration=True, method=\"xml\")\n",
    "\n",
    "\n",
    "# Replace 'your_input_file.txt' with the path to your actual input file\n",
    "input_file = '01 Hosea App III - מתוקן.txt'\n",
    "output_file = 'apparatus_tei.xml'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "tei_tree = create_tei_document(lines)\n",
    "save_tei_file(tei_tree, output_file)\n",
    "\n",
    "print(f\"TEI document has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a4a220d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'witnesses': [{'n': '30', 'text': 'G-B msr. 30 (pm) '}, {'n': '89', 'text': 'G-A 89 (pm?) '}, {'n': '150', 'text': '150 (non voc) k'}, {'n': '30', 'text': ' 30 (sm) '}, {'n': '89', 'text': '89 (sm) '}, {'n': '93', 'text': '93 (sm) '}, {'n': '96', 'text': '96 '}, {'n': '150', 'text': '150 (pm) q'}, {'n': '93', 'text': ' 93 (pm) '}], 'reading': '> שערורה', 'comments': '  (bla bla (f))', 'cross_references': ['IV', 'II']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_string(text):\n",
    "    pattern = re.compile(r'^(.*?)([\\+<~>]?\\s?[\\u0590-\\u05FF]+.*?)(.*)$', re.DOTALL)\n",
    "    match = pattern.match(text)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def custom_split_string(text):\n",
    "    pattern = re.compile(r'([^,\\d]*?)?(\\d+)\\s?(\\([^\\)]+\\)?)?([\\skq]*)?', re.DOTALL|re.UNICODE)\n",
    "    parts = re.findall(pattern, text)\n",
    "    return parts\n",
    "\n",
    "def remove_and_list_roman_numerals(text):\n",
    "    pattern = r'([I]*[V]?)'\n",
    "    found_numerals = re.findall(pattern, text)\n",
    "    found_numerals = [numeral for numeral in found_numerals if numeral]\n",
    "    result_text = re.sub(pattern, '', text)\n",
    "    return result_text, found_numerals\n",
    "\n",
    "# def process_entry(entry):\n",
    "#     split_parts = split_string(entry)\n",
    "#     if split_parts is None:\n",
    "#         return \"Unable to process entry: No valid dividers found.\"\n",
    "    \n",
    "#     witnesses, reading, comments = split_parts\n",
    "\n",
    "#     witness_entries = []\n",
    "#     for part in custom_split_string(witnesses):\n",
    "#         witness_entry = f'<witness n=\"{part[1]}\">{part[0]}{part[1]} {part[2].strip()}{part[3]}</witness>'\n",
    "#         witness_entries.append(witness_entry)\n",
    "#     witnesses_tagged = \"\\n\".join(witness_entries)\n",
    "\n",
    "#     reading_tagged = f'<reading>{reading}</reading>'\n",
    "\n",
    "#     comments_text, numerals_found = remove_and_list_roman_numerals(comments)\n",
    "#     comments_tagged = f'<comment>{comments_text}</comment>'\n",
    "#     cross_references = \"\\n\".join([f'<ref>{numeral}</ref>' for numeral in numerals_found])\n",
    "\n",
    "#     # Combine all parts, placing cross_references outside the comment\n",
    "#     tei_entry = f\"{witnesses_tagged}\\n{reading_tagged}\\n{comments_tagged}\\n{cross_references}\"\n",
    "#     return tei_entry\n",
    "\n",
    "# Example usage\n",
    "entry =\"G-B msr. 30 (pm) G-A 89 (pm?) 150 (non voc) k, 30 (sm) 89 (sm) 93 (sm) 96 150 (pm) q, 93 (pm) > שערורהIV II (bla bla (f))\"\n",
    "processed_entry = process_entry(entry)\n",
    "print(processed_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12325297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93 (pm) + ביהושעIV (similarly PesiqtaR 33 (153b))'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = \"93 (pm) + ביהושעIV (similarly PesiqtaR 33 (153b))\"\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caa1d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tei_hebrew_output_enhanced.xml'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def strip_non_hebrew(word):\n",
    "    normalized_word = unicodedata.normalize('NFD', word)\n",
    "    stripped_word = ''.join(re.findall(r'[\\u05D0-\\u05EA]', normalized_word))\n",
    "    return unicodedata.normalize('NFC', stripped_word)\n",
    "\n",
    "def process_word(token, verse_id, word_id, parent_element):\n",
    "    parts = token.split('־')\n",
    "    pe_count = 1  # Counter for 'פ' tags\n",
    "\n",
    "    for part in parts:\n",
    "        w = ET.SubElement(parent_element, 'w', id=f'verse{verse_id}_word{word_id}')\n",
    "\n",
    "        alphabetic = strip_non_hebrew(part)\n",
    "        non_alphabetic = ''.join(re.findall(r'[^\\u05D0-\\u05EA]', part))\n",
    "\n",
    "        original = ET.SubElement(w, 'original')\n",
    "        original.text = part\n",
    "        stripped = ET.SubElement(w, 'stripped')\n",
    "        stripped.text = alphabetic\n",
    "        punctuation = ET.SubElement(w, 'punctuation')\n",
    "        punctuation.text = non_alphabetic\n",
    "\n",
    "        if \"פ\" in part:\n",
    "            pe_tag = ET.SubElement(w, 'pe', id=f'verse{verse_id}_pe{pe_count}')\n",
    "            pe_tag.text = \"פ\"\n",
    "            pe_count += 1\n",
    "        \n",
    "        word_id += 1\n",
    "    return word_id\n",
    "\n",
    "def encode_tei_hebrew_word_details_enhanced(file_path, output_file):\n",
    "    text = read_text_from_file(file_path)\n",
    "    TEI = ET.Element('TEI', xmlns='http://www.tei-c.org/ns/1.0')\n",
    "    text_element = ET.SubElement(TEI, 'text')\n",
    "    body = ET.SubElement(text_element, 'body')\n",
    "\n",
    "    chapter_id = 1\n",
    "    verse_id = 1\n",
    "\n",
    "    chapters = text.split('פרק')\n",
    "    for chapter in chapters[1:]:\n",
    "        div = ET.SubElement(body, 'div', type='chapter', id=f'chapter{chapter_id}')\n",
    "        chapter_id += 1\n",
    "\n",
    "        verses = re.split(r'(\\[\\פ\\]|:)', chapter)\n",
    "        for verse in verses:\n",
    "            if verse.strip() and verse not in ['[פ]', ':']:\n",
    "                p = ET.SubElement(div, 'p', type='verse', id=f'verse{verse_id}')\n",
    "                word_id = 1\n",
    "\n",
    "                tokens = verse.strip().split()\n",
    "                for token in tokens:\n",
    "                    word_id = process_word(token, verse_id, word_id, p)\n",
    "\n",
    "                verse_id += 1\n",
    "\n",
    "    tree = ET.ElementTree(TEI)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        tree.write(f, encoding=\"unicode\")\n",
    "\n",
    "# Specify the file paths\n",
    "file_path = 'file.txt'  # Replace with your input file path\n",
    "output_file = 'tei_hebrew_output_enhanced.xml'  # Replace with your output file path\n",
    "\n",
    "# Run the function\n",
    "encode_tei_hebrew_word_details_enhanced(file_path, output_file)\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[' ', '\"', '$', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', 'E', 'I', 'T', '_', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', '֑', '֔', '֕', '֖', '֗', '֙', '֛', '֜', '֞', '֣', '֤', '֥', '֨', '֩', 'ְ', 'ֱ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ֽ', '׀', 'ׁ', 'ׂ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3cf327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '$', '$1', '$2', '$4', '2', ':', '[', ']', '֑', '֔', '֕', '֖', '֗', '֙', '֜', '֣', '֤', '֥', '֥$', '֨', '֩', 'ְ', 'ְ$', 'ְ֙', 'ְּ', 'ְׁ', 'ְׂ', 'ֱ', 'ֲ', 'ִ', 'ִ$', 'ִ֔', 'ִ֖', 'ִ֜', 'ִ֨', 'ִּ', 'ִֽ', 'ִׁ', 'ֵ', 'ֵ$', 'ֵ֔', 'ֵ֖', 'ֵ֗', 'ֵ֛', 'ֵ֣', 'ֵ֤', 'ֵ֨', 'ֵּ', 'ֵֽ', 'ֵׁ', 'ֶ', 'ֶ֑', 'ֶ֙', 'ֶ֣', 'ֶ֤', 'ֶ֥', 'ֶּ', 'ֶֽ', 'ֶׁ', 'ַ', 'ַ֗', 'ַ֙', 'ַּ', 'ַׁ', 'ָ', 'ָ֑', 'ָ֔', 'ָ֖', 'ָ֗', 'ָ֛', 'ָ֜', 'ָ֞', 'ָ֣', 'ָ֥', 'ָ֨', 'ָּ', 'ָֽ', 'ֹ', 'ֹ֖', 'ֹ֣', 'ֹ֤', 'ֹ֨', 'ֹּ', 'ֹׂ', 'ֻ', 'ּ', 'ּ֣', 'ֽ', '־', '־$', '׀', 'ׁ', 'ׂ֖', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "def extract_consecutive_non_hebrew_groups(file_path):\n",
    "    text = read_text_from_file(file_path)\n",
    "    non_hebrew_groups = set()\n",
    "\n",
    "    # Using a regular expression to find sequences of non-Hebrew characters\n",
    "    pattern = re.compile(r'([^\\u05D0-\\u05EA]{,2})')\n",
    "    matches = pattern.findall(unicodedata.normalize('NFD', text))\n",
    "\n",
    "    for match in matches:\n",
    "        non_hebrew_groups.add(match.strip())\n",
    "\n",
    "    return non_hebrew_groups\n",
    "\n",
    "# Extract and print groups of consecutive non-Hebrew characters\n",
    "file_path = 'file.txt'\n",
    "\n",
    "consecutive_non_hebrew_groups = extract_consecutive_non_hebrew_groups(file_path)\n",
    "print(sorted(consecutive_non_hebrew_groups))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
