{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caa1d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tei_hebrew_output_enhanced.xml'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def strip_non_hebrew(word):\n",
    "    normalized_word = unicodedata.normalize('NFD', word)\n",
    "    stripped_word = ''.join(re.findall(r'[\\u05D0-\\u05EA]', normalized_word))\n",
    "    return unicodedata.normalize('NFC', stripped_word)\n",
    "\n",
    "def process_word(token, verse_id, word_id, parent_element):\n",
    "    parts = token.split('־')\n",
    "    pe_count = 1  # Counter for 'פ' tags\n",
    "\n",
    "    for part in parts:\n",
    "        w = ET.SubElement(parent_element, 'w', id=f'verse{verse_id}_word{word_id}')\n",
    "\n",
    "        alphabetic = strip_non_hebrew(part)\n",
    "        non_alphabetic = ''.join(re.findall(r'[^\\u05D0-\\u05EA]', part))\n",
    "\n",
    "        original = ET.SubElement(w, 'original')\n",
    "        original.text = part\n",
    "        stripped = ET.SubElement(w, 'stripped')\n",
    "        stripped.text = alphabetic\n",
    "        punctuation = ET.SubElement(w, 'punctuation')\n",
    "        punctuation.text = non_alphabetic\n",
    "\n",
    "        if \"פ\" in part:\n",
    "            pe_tag = ET.SubElement(w, 'pe', id=f'verse{verse_id}_pe{pe_count}')\n",
    "            pe_tag.text = \"פ\"\n",
    "            pe_count += 1\n",
    "        \n",
    "        word_id += 1\n",
    "    return word_id\n",
    "\n",
    "def encode_tei_hebrew_word_details_enhanced(file_path, output_file):\n",
    "    text = read_text_from_file(file_path)\n",
    "    TEI = ET.Element('TEI', xmlns='http://www.tei-c.org/ns/1.0')\n",
    "    text_element = ET.SubElement(TEI, 'text')\n",
    "    body = ET.SubElement(text_element, 'body')\n",
    "\n",
    "    chapter_id = 1\n",
    "    verse_id = 1\n",
    "\n",
    "    chapters = text.split('פרק')\n",
    "    for chapter in chapters[1:]:\n",
    "        div = ET.SubElement(body, 'div', type='chapter', id=f'chapter{chapter_id}')\n",
    "        chapter_id += 1\n",
    "\n",
    "        verses = re.split(r'(\\[\\פ\\]|:)', chapter)\n",
    "        for verse in verses:\n",
    "            if verse.strip() and verse not in ['[פ]', ':']:\n",
    "                p = ET.SubElement(div, 'p', type='verse', id=f'verse{verse_id}')\n",
    "                word_id = 1\n",
    "\n",
    "                tokens = verse.strip().split()\n",
    "                for token in tokens:\n",
    "                    word_id = process_word(token, verse_id, word_id, p)\n",
    "\n",
    "                verse_id += 1\n",
    "\n",
    "    tree = ET.ElementTree(TEI)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        tree.write(f, encoding=\"unicode\")\n",
    "\n",
    "# Specify the file paths\n",
    "file_path = 'file.txt'  # Replace with your input file path\n",
    "output_file = 'tei_hebrew_output_enhanced.xml'  # Replace with your output file path\n",
    "\n",
    "# Run the function\n",
    "encode_tei_hebrew_word_details_enhanced(file_path, output_file)\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[' ', '\"', '$', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', 'E', 'I', 'T', '_', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', '֑', '֔', '֕', '֖', '֗', '֙', '֛', '֜', '֞', '֣', '֤', '֥', '֨', '֩', 'ְ', 'ֱ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ֽ', '׀', 'ׁ', 'ׂ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3cf327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '$', '$1', '$2', '$4', '2', ':', '[', ']', '֑', '֔', '֕', '֖', '֗', '֙', '֜', '֣', '֤', '֥', '֥$', '֨', '֩', 'ְ', 'ְ$', 'ְ֙', 'ְּ', 'ְׁ', 'ְׂ', 'ֱ', 'ֲ', 'ִ', 'ִ$', 'ִ֔', 'ִ֖', 'ִ֜', 'ִ֨', 'ִּ', 'ִֽ', 'ִׁ', 'ֵ', 'ֵ$', 'ֵ֔', 'ֵ֖', 'ֵ֗', 'ֵ֛', 'ֵ֣', 'ֵ֤', 'ֵ֨', 'ֵּ', 'ֵֽ', 'ֵׁ', 'ֶ', 'ֶ֑', 'ֶ֙', 'ֶ֣', 'ֶ֤', 'ֶ֥', 'ֶּ', 'ֶֽ', 'ֶׁ', 'ַ', 'ַ֗', 'ַ֙', 'ַּ', 'ַׁ', 'ָ', 'ָ֑', 'ָ֔', 'ָ֖', 'ָ֗', 'ָ֛', 'ָ֜', 'ָ֞', 'ָ֣', 'ָ֥', 'ָ֨', 'ָּ', 'ָֽ', 'ֹ', 'ֹ֖', 'ֹ֣', 'ֹ֤', 'ֹ֨', 'ֹּ', 'ֹׂ', 'ֻ', 'ּ', 'ּ֣', 'ֽ', '־', '־$', '׀', 'ׁ', 'ׂ֖', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "def extract_consecutive_non_hebrew_groups(file_path):\n",
    "    text = read_text_from_file(file_path)\n",
    "    non_hebrew_groups = set()\n",
    "\n",
    "    # Using a regular expression to find sequences of non-Hebrew characters\n",
    "    pattern = re.compile(r'([^\\u05D0-\\u05EA]{,2})')\n",
    "    matches = pattern.findall(unicodedata.normalize('NFD', text))\n",
    "\n",
    "    for match in matches:\n",
    "        non_hebrew_groups.add(match.strip())\n",
    "\n",
    "    return non_hebrew_groups\n",
    "\n",
    "# Extract and print groups of consecutive non-Hebrew characters\n",
    "file_path = 'file.txt'\n",
    "\n",
    "consecutive_non_hebrew_groups = extract_consecutive_non_hebrew_groups(file_path)\n",
    "print(sorted(consecutive_non_hebrew_groups))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
